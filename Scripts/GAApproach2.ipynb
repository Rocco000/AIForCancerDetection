{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rocco000/OncoVision/blob/main/Scripts/GAApproach2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utSQBFhb_kI0"
      },
      "source": [
        "Link to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49LQG4ba_jGB"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') #Connect to Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1QLq2ok_2XN"
      },
      "source": [
        "Run the required scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLavubHlAB49"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "#To authenticate the user that run the script in order to use the correct path\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "#Get user information\n",
        "about = drive_service.about().get(fields='user').execute()\n",
        "user_email = about['user']['emailAddress']\n",
        "script_owner = False\n",
        "\n",
        "if user_email ==\"rocco.iul2000@gmail.com\":\n",
        "  script_owner = True\n",
        "  #Run the .ipynb file\n",
        "  %run '/content/drive/MyDrive/SE4AI/Scripts/DatasetLoader.ipynb'\n",
        "  %run '/content/drive/MyDrive/SE4AI/Scripts/ModelArchitecture2.ipynb'\n",
        "  %run '/content/drive/MyDrive/SE4AI/Scripts/TrainModel.ipynb'\n",
        "else:\n",
        "  %run '/content/drive/MyDrive/LinkToOncoVision/SE4AI/Scripts/DatasetLoader.ipynb'\n",
        "  %run '/content/drive/MyDrive/LinkToOncoVision/SE4AI/Scripts/ModelArchitecture2.ipynb'\n",
        "  %run '/content/drive/MyDrive/LinkToOncoVision/SE4AI/Scripts/TrainModel.ipynb'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFTc0QNBJ7ZD"
      },
      "source": [
        "Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-7eHLIeKBiU"
      },
      "outputs": [],
      "source": [
        "!pip install pygad\n",
        "import torch\n",
        "import pandas as pd\n",
        "import pygad\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZTx136CvqDQ"
      },
      "source": [
        "# Genetic Algorithm (2° approach)\n",
        "Our **objective function**:\n",
        "> max w * accuracy+(1-w) * recall where w=0.4\n",
        "\n",
        "Our **valuation function** is equal to objective funtion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I47ZD_7cGEnx"
      },
      "source": [
        "Check validity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQ_Ehr1RGEnx"
      },
      "outputs": [],
      "source": [
        "def check_validity(solution):\n",
        "  #Computing the input size of the first nn.Linear\n",
        "\n",
        "  width_in, height_in, size = size_nn_linear_calculator(layer_type=5, width=600, height=450, channels=None) # first conv2d\n",
        "  i = 0\n",
        "  for element in solution:\n",
        "    if element == 1:\n",
        "      #conv-128\n",
        "      width_in, height_in, size = size_nn_linear_calculator(layer_type=1, width=width_in, height=height_in, channels=None)\n",
        "    elif element == 2:\n",
        "      #conv-64\n",
        "      width_in, height_in, size = size_nn_linear_calculator(layer_type=2, width=width_in, height=height_in, channels=None)\n",
        "    elif element == 3:\n",
        "      #conv-32\n",
        "      width_in, height_in, size = size_nn_linear_calculator(layer_type=3, width=width_in, height=height_in, channels=None)\n",
        "    elif element == 4:\n",
        "      #conv-16\n",
        "      width_in, height_in, size = size_nn_linear_calculator(layer_type=4, width=width_in, height=height_in, channels=None)\n",
        "    elif element == 5:\n",
        "      #conv-8\n",
        "      width_in, height_in, size = size_nn_linear_calculator(layer_type=5, width=width_in, height=height_in, channels=None)\n",
        "    elif element == 6:\n",
        "      #max-3\n",
        "      if solution[i-1]!=12 and solution[i-1]!=13: #if before the pooling layer there isn't a activation layer\n",
        "        return False, 0\n",
        "\n",
        "      #Find the last convolutional layer before the actual layer to define the number of output channels\n",
        "      j = i-1\n",
        "      num_channels = 8 #because our first layer is a conv-8\n",
        "      flag = False\n",
        "      while j>=0 and (not flag):\n",
        "        if solution[j] == 1:\n",
        "          num_channels = 128\n",
        "          flag = True\n",
        "        elif solution[j] == 2:\n",
        "          num_channels = 64\n",
        "          flag = True\n",
        "        elif solution[j] == 3:\n",
        "          num_channels = 32\n",
        "          flag = True\n",
        "        elif solution[j] == 4:\n",
        "          num_channels = 16\n",
        "          flag = True\n",
        "        elif solution[j] == 5:\n",
        "          num_channels = 8\n",
        "          flag = True\n",
        "        j = j-1\n",
        "      width_in, height_in, size = size_nn_linear_calculator(layer_type=6, width=width_in, height=height_in, channels=num_channels)\n",
        "    elif element == 7:\n",
        "      #max-2\n",
        "      if solution[i-1]!=12 and solution[i-1]!=13: #if before the pooling layer there isn't a activation layer\n",
        "        return False, 0\n",
        "\n",
        "      #Find the last convolutional layer before the actual layer to define the number of output channels\n",
        "      j = i-1\n",
        "      num_channels = 8 #because our first layer is a conv-8\n",
        "      flag = False\n",
        "      while j>=0 and (not flag):\n",
        "        if solution[j] == 1:\n",
        "          num_channels = 128\n",
        "          flag = True\n",
        "        elif solution[j] == 2:\n",
        "          num_channels = 64\n",
        "          flag = True\n",
        "        elif solution[j] == 3:\n",
        "          num_channels = 32\n",
        "          flag = True\n",
        "        elif solution[j] == 4:\n",
        "          num_channels = 16\n",
        "          flag = True\n",
        "        elif solution[j] == 5:\n",
        "          num_channels = 8\n",
        "          flag = True\n",
        "        j = j-1\n",
        "      width_in, height_in, size = size_nn_linear_calculator(layer_type=7, width=width_in, height=height_in, channels=num_channels)\n",
        "    elif element == 8:\n",
        "      #avg-3\n",
        "      if solution[i-1]!=12 and solution[i-1]!=13: #if before the pooling layer there isn't a activation layer\n",
        "        return False, 0\n",
        "\n",
        "      #Find the last convolutional layer before the actual layer to define the number of output channels\n",
        "      j = i-1\n",
        "      num_channels = 8 #because our first layer is a conv-8\n",
        "      flag = False\n",
        "      while j>=0 and (not flag):\n",
        "        if solution[j] == 1:\n",
        "          num_channels = 128\n",
        "          flag = True\n",
        "        elif solution[j] == 2:\n",
        "          num_channels = 64\n",
        "          flag = True\n",
        "        elif solution[j] == 3:\n",
        "          num_channels = 32\n",
        "          flag = True\n",
        "        elif solution[j] == 4:\n",
        "          num_channels = 16\n",
        "          flag = True\n",
        "        elif solution[j] == 5:\n",
        "          num_channels = 8\n",
        "          flag = True\n",
        "        j = j-1\n",
        "      width_in, height_in, size = size_nn_linear_calculator(layer_type=8, width=width_in, height=height_in, channels=num_channels)\n",
        "    elif element == 9:\n",
        "      #avg-2\n",
        "      if solution[i-1]!=12 and solution[i-1]!=13: #if before the pooling layer there isn't a activation layer\n",
        "        return False, 0\n",
        "\n",
        "      #Find the last convolutional layer before the actual layer to define the number of output channels\n",
        "      j = i-1\n",
        "      num_channels = 8 #because our first layer is a conv-8\n",
        "      flag = False\n",
        "      while j>=0 and (not flag):\n",
        "        if solution[j] == 1:\n",
        "          num_channels = 128\n",
        "          flag = True\n",
        "        elif solution[j] == 2:\n",
        "          num_channels = 64\n",
        "          flag = True\n",
        "        elif solution[j] == 3:\n",
        "          num_channels = 32\n",
        "          flag = True\n",
        "        elif solution[j] == 4:\n",
        "          num_channels = 16\n",
        "          flag = True\n",
        "        elif solution[j] == 5:\n",
        "          num_channels = 8\n",
        "          flag = True\n",
        "        j = j-1\n",
        "      width_in, height_in, size = size_nn_linear_calculator(layer_type=9, width=width_in, height=height_in, channels=num_channels)\n",
        "    elif element == 10:\n",
        "      #Dropout2d\n",
        "      if solution[i-1]!=6 and solution[i-1]!=7 and solution[i-1]!=8 and solution[i-1]!=9: #If before the dropout layer there isn't a pooling layer.\n",
        "        return False, 0\n",
        "    elif element == 11:\n",
        "      #BatchNorm\n",
        "      if solution[i-1]!=1 and solution[i-1]!=2 and solution[i-1]!=3 and solution[i-1]!=4 and solution[i-1]!=5:\n",
        "        return False, 0\n",
        "    elif element == 12 or element == 13:\n",
        "      #ReLU and LeakyReLU\n",
        "      if solution[i-1]!=1 and solution[i-1]!=2 and solution[i-1]!=3 and solution[i-1]!=4 and solution[i-1]!=5 and solution[i-1]!=11: #if before the activation layer there isn't a convolutional layer\n",
        "        return False, 0\n",
        "\n",
        "    i = i+1\n",
        "\n",
        "  size = int(size)\n",
        "  if size<8 or size>25000:\n",
        "    return False, 0\n",
        "  else:\n",
        "    return True, size\n",
        "\n",
        "def replace_solution(solution):\n",
        "  temp = list()\n",
        "  flag = False\n",
        "  size=0\n",
        "\n",
        "  while not flag:\n",
        "    #Clear the list if the generation solution is not valid\n",
        "    temp.clear()\n",
        "    #Define a new solution in a random manner\n",
        "    for i in range(16):\n",
        "      random_number = random.randint(1, 13)\n",
        "      temp.append(random_number)\n",
        "\n",
        "    flag, size = check_validity(temp)\n",
        "\n",
        "\n",
        "  new_solution = solution[:4]\n",
        "  new_solution.extend(temp)\n",
        "  print(\"Solution replaced! (Validity)\")\n",
        "  print(\"Old solution: \",solution)\n",
        "  print(\"New solution: \",new_solution)\n",
        "  return new_solution, size"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace clones"
      ],
      "metadata": {
        "id": "25aK2DZ2TZTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_clone_presence(population,solution):\n",
        "  occurence = population.count(solution)\n",
        "  if occurence>1:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def replace_clone(population):\n",
        "  flag = True\n",
        "  new_solution = None\n",
        "  while flag:\n",
        "    random_lr = round(random.uniform(0.00100, 0.01001), 5)\n",
        "    random_batch = random.randint(1, 2)\n",
        "    random_epoch = random.randint(1, 3)\n",
        "    random_opt = random.randint(1, 3)\n",
        "    random_l1 = random.randint(1, 13)\n",
        "    random_l2 = random.randint(1, 13)\n",
        "    random_l3 = random.randint(1, 13)\n",
        "    random_l4 = random.randint(1, 13)\n",
        "    random_l5 = random.randint(1, 13)\n",
        "    random_l6 = random.randint(1, 13)\n",
        "    random_l7 = random.randint(1, 13)\n",
        "    random_l8 = random.randint(1, 13)\n",
        "    random_l9 = random.randint(1, 13)\n",
        "    random_l10 = random.randint(1, 13)\n",
        "    random_l11 = random.randint(1, 13)\n",
        "    random_l12 = random.randint(1, 13)\n",
        "    random_l13 = random.randint(1, 13)\n",
        "    random_l14 = random.randint(1, 13)\n",
        "    random_l15 = random.randint(1, 13)\n",
        "    random_l16 = random.randint(1, 13)\n",
        "\n",
        "    new_solution = [random_lr, random_batch, random_epoch, random_opt, random_l1, random_l2, random_l3, random_l4, random_l5, random_l6, random_l7, random_l8, random_l9, random_l10, random_l11, random_l12, random_l13, random_l14, random_l15, random_l16]\n",
        "    flag_validity, _ = check_validity(new_solution[4:])\n",
        "    if flag_validity == False:\n",
        "      new_solution, _ = replace_solution(new_solution)\n",
        "\n",
        "    flag = check_clone_presence(population,new_solution)\n",
        "    if flag:\n",
        "      new_solution.clear()\n",
        "\n",
        "  return new_solution"
      ],
      "metadata": {
        "id": "RkwrsWhOTbtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKJe2jJjGEny"
      },
      "source": [
        "# Assessment of solutions\n",
        "**After the mutation step** we will evalutate the solutions and store their fitness value in a csv file.\n",
        "\n",
        "If we obtain a solution that has the same configuration of another solution stored in \"AllSolutions.csv\", we do not retrain the model as there is a high probability that the solutions have the same performance (in this way we reduce the time consumption)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkiCS8koGEny"
      },
      "outputs": [],
      "source": [
        "max_fitness = 0\n",
        "num_step = None\n",
        "solution_number=0\n",
        "\n",
        "def evaluate_solutions(num_generation, population, ga_instance):\n",
        "  population_list = population.tolist()\n",
        "  global max_fitness\n",
        "  global num_step\n",
        "  step_value = 0\n",
        "  sum = 0\n",
        "\n",
        "  #Make a copy to handle the no valid solutions\n",
        "  population_copy = population_list.copy()\n",
        "  copy_flag = False\n",
        "\n",
        "  if num_step is None:\n",
        "    step_value = num_generation\n",
        "  else:\n",
        "    step_value = num_step + num_generation\n",
        "\n",
        "  print(\"***************************************************************\")\n",
        "  print(\"We are at the \",step_value,\" generation step\")\n",
        "\n",
        "  #Define the files path to check if this solution already exists (less time consumption) and to store the model configuration of the best solution\n",
        "  path_parameters = \"\"\n",
        "  file_path1 = file_path2 = file_path3 = \"\"\n",
        "  if script_owner:\n",
        "    path_parameters = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGASecondApproach/ModelsConfigurations/\"\n",
        "    file_path1 = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGASecondApproach/ActualPopulation.csv\"\n",
        "    file_path2 = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGASecondApproach/AllSolutions.csv\"\n",
        "    file_path3 = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGASecondApproach/Checkpoint.csv\"\n",
        "  else:\n",
        "    path_parameters = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGASecondApproach/ModelsConfigurations/\"\n",
        "    file_path1 = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGASecondApproach/ActualPopulation.csv\"\n",
        "    file_path2 = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGASecondApproach/AllSolutions.csv\"\n",
        "    file_path3 = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGASecondApproach/Checkpoint.csv\"\n",
        "\n",
        "  #Check if the actual population is valid or contains clones\n",
        "  i = 0\n",
        "  for solution in population_list:\n",
        "    solution_app = solution.copy()\n",
        "    layers = solution_app[4:]\n",
        "    flag, layer_size = check_validity(layers) #check if the solution is valid\n",
        "    if not flag:\n",
        "      copy_flag = True\n",
        "      solution_app, layer_size = replace_solution(solution_app)\n",
        "      population_copy[i] = solution_app\n",
        "\n",
        "    if check_clone_presence(population_copy, solution_app): #check if the solution appears more than one time in the actual population\n",
        "      copy_flag = True\n",
        "      new_solution = replace_clone(population_copy)\n",
        "      population_copy[i] = new_solution\n",
        "      print(\"Clone replaced! (Assessment)\")\n",
        "\n",
        "    i+=1\n",
        "\n",
        "  if copy_flag:\n",
        "    ga_instance.population = np.array(population_copy)\n",
        "    population_list = population_copy.copy()\n",
        "    del population_copy\n",
        "\n",
        "  #Deprive the ActualPopulation file\n",
        "  with open(file_path1, \"w\", newline=\"\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"learning_rate\",\"batch_size\",\"num_epoch\",\"optimizer\",\"layer1\",\"layer2\",\"layer3\",\"layer4\",\"layer5\",\"layer6\",\"layer7\",\"layer8\",\"layer9\",\"layer10\",\"layer11\",\"layer12\",\"layer13\",\"layer14\",\"layer15\",\"layer16\",\"fitness_value\",\"accuracy\",\"precision\",\"recall\",\"f1\",\"evaluation\"])\n",
        "\n",
        "    #Store the actual solutions\n",
        "    for solution in population_list:\n",
        "      temp_list = solution.copy()\n",
        "      temp_list.extend([None,None,None,None,None,None])\n",
        "      writer.writerow(temp_list)\n",
        "\n",
        "  #Store the checkpoint\n",
        "  run = mlflow.active_run()\n",
        "  experiment_id = run.info.experiment_id\n",
        "  with open(file_path3, \"w\", newline=\"\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"num_generation_step\",\"mlflow_experiment_id\"])\n",
        "    writer.writerow([step_value, experiment_id])\n",
        "\n",
        "  #To track the new solution\n",
        "  i = 0\n",
        "  for solution in population_list:\n",
        "\n",
        "    flag = False\n",
        "    learning_rate = float(solution[0])\n",
        "    batch_size = int(solution[1])\n",
        "    num_epoch = int(solution[2])\n",
        "    optimizer = int(solution[3])\n",
        "    layer1 = int(solution[4])\n",
        "    layer2 = int(solution[5])\n",
        "    layer3 = int(solution[6])\n",
        "    layer4 = int(solution[7])\n",
        "    layer5 = int(solution[8])\n",
        "    layer6 = int(solution[9])\n",
        "    layer7 = int(solution[10])\n",
        "    layer8 = int(solution[11])\n",
        "    layer9 = int(solution[12])\n",
        "    layer10 = int(solution[13])\n",
        "    layer11 = int(solution[14])\n",
        "    layer12 = int(solution[15])\n",
        "    layer13 = int(solution[16])\n",
        "    layer14 = int(solution[17])\n",
        "    layer15 = int(solution[18])\n",
        "    layer16 = int(solution[19])\n",
        "\n",
        "    evaluation = acc = pre = rec = f1 = 0\n",
        "    position_in_all = 0\n",
        "\n",
        "    #Check if the solution already exists\n",
        "    with open(file_path2, \"r\", newline=\"\") as csvfile:\n",
        "      reader = csv.reader(csvfile)\n",
        "      next(reader) #Jump the first row (contains the file header)\n",
        "      index=0\n",
        "      for row in reader:\n",
        "        #Convert the values in the correct format\n",
        "        lr_row = float(row[0])\n",
        "        batch_row = int(float(row[1]))\n",
        "        epoch_row = int(float(row[2]))\n",
        "        optimizer_row = int(float(row[3]))\n",
        "\n",
        "        layer1_row = int(float(row[4]))\n",
        "        layer2_row = int(float(row[5]))\n",
        "        layer3_row = int(float(row[6]))\n",
        "        layer4_row = int(float(row[7]))\n",
        "        layer5_row = int(float(row[8]))\n",
        "        layer6_row = int(float(row[9]))\n",
        "        layer7_row = int(float(row[10]))\n",
        "        layer8_row = int(float(row[11]))\n",
        "        layer9_row = int(float(row[12]))\n",
        "        layer10_row = int(float(row[13]))\n",
        "        layer11_row = int(float(row[14]))\n",
        "        layer12_row = int(float(row[15]))\n",
        "        layer13_row = int(float(row[16]))\n",
        "        layer14_row = int(float(row[17]))\n",
        "        layer15_row = int(float(row[18]))\n",
        "        layer16_row = int(float(row[19]))\n",
        "\n",
        "        acc = float(row[21])\n",
        "        pre = float(row[22])\n",
        "        rec = float(row[23])\n",
        "        f1 = float(row[24])\n",
        "        evaluation = float(row[25])\n",
        "\n",
        "        condition = learning_rate==lr_row and batch_size==batch_row and num_epoch==epoch_row and optimizer==optimizer_row and layer1==layer1_row and layer2==layer2_row and layer3==layer3_row and layer4==layer4_row and layer5==layer5_row and layer6==layer6_row and layer7==layer7_row and layer8==layer8_row and layer9==layer9_row and layer10==layer10_row and layer11==layer11_row and layer12==layer12_row and layer13==layer13_row and layer14==layer14_row and layer15==layer15_row and layer16==layer16_row\n",
        "        if condition:\n",
        "          print(\"The solution: \",solution,\" acc:\",acc,\" pre:\",pre,\" rec:\",rec,\" f1:\",f1,\" already exists! (it will not train)\")\n",
        "          flag = True\n",
        "          position_in_all = index\n",
        "          break\n",
        "\n",
        "        index+=1\n",
        "\n",
        "    if flag:\n",
        "      #We have already a same solution, therefore we store the configuration in ActualPopulation.csv\n",
        "      sum += evaluation\n",
        "      #Update ActualPopulation\n",
        "      df = pd.read_csv(file_path1)\n",
        "      matching_rows = df.loc[(df[\"learning_rate\"] == learning_rate) & (df[\"batch_size\"] == batch_size) & (df[\"num_epoch\"] == num_epoch) & (df[\"optimizer\"] == optimizer) & (df[\"layer1\"] == layer1) & (df[\"layer2\"] == layer2) & (df[\"layer3\"] == layer3) & (df[\"layer4\"] == layer4) & (df[\"layer5\"] == layer5) & (df[\"layer6\"] == layer6) & (df[\"layer7\"] == layer7) & (df[\"layer8\"] == layer8) & (df[\"layer9\"] == layer9) & (df[\"layer10\"] == layer10) & (df[\"layer11\"] == layer11) & (df[\"layer12\"] == layer12) & (df[\"layer13\"] == layer13) & (df[\"layer14\"] == layer14) & (df[\"layer15\"] == layer15) & (df[\"layer16\"] == layer16)]\n",
        "\n",
        "      if not matching_rows.empty:\n",
        "        #Take the solution index\n",
        "        idx = matching_rows.index[0]\n",
        "        #Update the evaluation metrics\n",
        "        df.at[idx, \"accuracy\"] = acc\n",
        "        df.at[idx, \"precision\"] = pre\n",
        "        df.at[idx, \"recall\"] = rec\n",
        "        df.at[idx, \"f1\"] = f1\n",
        "        df.at[idx, \"evaluation\"] = evaluation\n",
        "\n",
        "        #save the updated ActualPopulation file\n",
        "        df.to_csv(file_path1, index=False)\n",
        "\n",
        "        #Take the solution configuration\n",
        "        individual = position_in_all % 8 #solution position in population\n",
        "        generation = int(position_in_all/8) #num generation where the solution was created\n",
        "\n",
        "        search_path = path_parameters+\"solution_\"+str(individual)+\"_\"+str(generation)+\".pth\"\n",
        "        if os.path.exists(search_path):\n",
        "          model_path = path_parameters+\"solution_\"+str(i)+\"_\"+str(step_value)+\".pth\"\n",
        "          shutil.copy(search_path, model_path)\n",
        "      else:\n",
        "        print(\"Row not found! (assesment solution- flag:True): \",solution)\n",
        "    else:\n",
        "      #It's a new solution, therefore we must define and train a model\n",
        "\n",
        "      #batch_size\n",
        "      size = 0\n",
        "      match batch_size:\n",
        "        case 1:\n",
        "          size = 32\n",
        "        case 2:\n",
        "          size = 64\n",
        "        case _:\n",
        "          size = 32\n",
        "\n",
        "      #num_epoch\n",
        "      epoch = 0\n",
        "      match num_epoch:\n",
        "        case 1:\n",
        "          epoch = 64\n",
        "        case 2:\n",
        "          epoch = 96\n",
        "        case 3:\n",
        "          epoch = 128\n",
        "        case _:\n",
        "          epoch = 64\n",
        "\n",
        "      layers = solution[4:]\n",
        "      flag, layer_size = check_validity(layers)\n",
        "\n",
        "      #Train model\n",
        "      print(\"Evaluating the solution: \",solution)\n",
        "      best_model_configuration, acc, pre, rec, f1 = start_process(model_type=2, architecture=layers, linear_size=layer_size, bool_mlflow=False, learning_rate=learning_rate, batch_size=size, num_epoch=epoch, opt=optimizer)\n",
        "      solution_evaluation = (0.20*acc)+(0.35*pre)+(0.45*rec)\n",
        "      sum += solution_evaluation\n",
        "\n",
        "      #Store its configuration\n",
        "      model_path = path_parameters+\"solution_\"+str(i)+\"_\"+str(step_value)+\".pth\"\n",
        "      torch.save(best_model_configuration, model_path)\n",
        "\n",
        "      #Update ActualPopulation\n",
        "      df = pd.read_csv(file_path1)\n",
        "      matching_rows = df.loc[(df[\"learning_rate\"] == learning_rate) & (df[\"batch_size\"] == batch_size) & (df[\"num_epoch\"] == num_epoch) & (df[\"optimizer\"] == optimizer) & (df[\"layer1\"] == layer1) & (df[\"layer2\"] == layer2) & (df[\"layer3\"] == layer3) & (df[\"layer4\"] == layer4) & (df[\"layer5\"] == layer5) & (df[\"layer6\"] == layer6) & (df[\"layer7\"] == layer7) & (df[\"layer8\"] == layer8) & (df[\"layer9\"] == layer9) & (df[\"layer10\"] == layer10) & (df[\"layer11\"] == layer11) & (df[\"layer12\"] == layer12) & (df[\"layer13\"] == layer13) & (df[\"layer14\"] == layer14) & (df[\"layer15\"] == layer15) & (df[\"layer16\"] == layer16)]\n",
        "\n",
        "      if not matching_rows.empty:\n",
        "        #Take the solution index\n",
        "        idx = matching_rows.index[0]\n",
        "        #Update the evaluation metrics\n",
        "        df.at[idx, \"accuracy\"] = acc\n",
        "        df.at[idx, \"precision\"] = pre\n",
        "        df.at[idx, \"recall\"] = rec\n",
        "        df.at[idx, \"f1\"] = f1\n",
        "        df.at[idx, \"evaluation\"] = solution_evaluation\n",
        "\n",
        "        #save the updated ActualPopulation file\n",
        "        df.to_csv(file_path1, index=False)\n",
        "      else:\n",
        "        print(\"Row not found! (assesment solution- flag:False): \",solution)\n",
        "\n",
        "    i+=1\n",
        "\n",
        "\n",
        "  actual_population = list()\n",
        "  #Compute the fitness_value\n",
        "  with open(file_path1, \"r\", newline=\"\") as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    next(reader)\n",
        "    for row in reader:\n",
        "      evaluation = float(row[25])\n",
        "      row_copy = row.copy()\n",
        "      row_copy[20] = evaluation/(sum-evaluation)\n",
        "      actual_population.append(row_copy)\n",
        "\n",
        "  #Update the max_fitness value with the current fitness value of the last best individual\n",
        "  max_flag=False\n",
        "  for solution in actual_population:\n",
        "    learning_rate = float(solution[0])\n",
        "    batch_size = int(float(solution[1]))\n",
        "    num_epoch = int(float(solution[2]))\n",
        "    optimizer = int(float(solution[3]))\n",
        "\n",
        "    layer1 = int(float(row[4]))\n",
        "    layer2 = int(float(row[5]))\n",
        "    layer3 = int(float(row[6]))\n",
        "    layer4 = int(float(row[7]))\n",
        "    layer5 = int(float(row[8]))\n",
        "    layer6 = int(float(row[9]))\n",
        "    layer7 = int(float(row[10]))\n",
        "    layer8 = int(float(row[11]))\n",
        "    layer9 = int(float(row[12]))\n",
        "    layer10 = int(float(row[13]))\n",
        "    layer11 = int(float(row[14]))\n",
        "    layer12 = int(float(row[15]))\n",
        "    layer13 = int(float(row[16]))\n",
        "    layer14 = int(float(row[17]))\n",
        "    layer15 = int(float(row[18]))\n",
        "    layer16 = int(float(row[19]))\n",
        "\n",
        "    df = pd.read_csv(file_path2)\n",
        "    matching_rows = df.loc[(df[\"learning_rate\"] == learning_rate) & (df[\"batch_size\"] == batch_size) & (df[\"num_epoch\"] == num_epoch) & (df[\"optimizer\"] == optimizer) & (df[\"layer1\"] == layer1) & (df[\"layer2\"] == layer2) & (df[\"layer3\"] == layer3) & (df[\"layer4\"] == layer4) & (df[\"layer5\"] == layer5) & (df[\"layer6\"] == layer6) & (df[\"layer7\"] == layer7) & (df[\"layer8\"] == layer8) & (df[\"layer9\"] == layer9) & (df[\"layer10\"] == layer10) & (df[\"layer11\"] == layer11) & (df[\"layer12\"] == layer12) & (df[\"layer13\"] == layer13) & (df[\"layer14\"] == layer14) & (df[\"layer15\"] == layer15) & (df[\"layer16\"] == layer16)]\n",
        "\n",
        "    if not matching_rows.empty:\n",
        "      position = matching_rows.index[len(matching_rows)-1]\n",
        "      last_occurence = df.loc[position]\n",
        "      fitness = float(last_occurence[\"fitness_value\"])\n",
        "      if max_fitness == fitness:\n",
        "        max_flag=True\n",
        "        max_fitness = float(solution[20])\n",
        "        break\n",
        "\n",
        "  if not max_flag:\n",
        "    max_fitness=0 #Whether in the actual population we have not the best solution of the last population, we have not math in the previous for statement, therefore we have not a max_fitness in this generation\n",
        "\n",
        "  i=0\n",
        "  #Find the actual best solution\n",
        "  for solution in actual_population:\n",
        "\n",
        "    lr = float(solution[0])\n",
        "    batch = int(float(solution[1]))\n",
        "    epoch = int(float(solution[2]))\n",
        "    opt = int(float(solution[3]))\n",
        "    layer1 = int(float(solution[4]))\n",
        "    layer2 = int(float(solution[5]))\n",
        "    layer3 = int(float(solution[6]))\n",
        "    layer4 = int(float(solution[7]))\n",
        "    layer5 = int(float(solution[8]))\n",
        "    layer6 = int(float(solution[9]))\n",
        "    layer7 = int(float(solution[10]))\n",
        "    layer8 = int(float(solution[11]))\n",
        "    layer9 = int(float(solution[12]))\n",
        "    layer10 = int(float(solution[13]))\n",
        "    layer11 = int(float(solution[14]))\n",
        "    layer12 = int(float(solution[15]))\n",
        "    layer13 = int(float(solution[16]))\n",
        "    layer14 = int(float(solution[17]))\n",
        "    layer15 = int(float(solution[18]))\n",
        "    layer16 = int(float(solution[19]))\n",
        "\n",
        "    fitness_value = float(solution[20])\n",
        "    acc = float(solution[21])\n",
        "    pre = float(solution[22])\n",
        "    rec = float(solution[23])\n",
        "    f1 = float(solution[24])\n",
        "\n",
        "    if fitness_value > max_fitness:\n",
        "      max_fitness = fitness_value\n",
        "      mlflow.log_metric(\"GA_learning_rate\", lr, step=step_value)\n",
        "      mlflow.log_metric(\"GA_batch_size\", batch, step=step_value)\n",
        "      mlflow.log_metric(\"GA_num_epoch\", epoch, step=step_value)\n",
        "      mlflow.log_metric(\"GA_optimizer\", opt, step=step_value)\n",
        "      mlflow.log_metric(\"layer1\", layer1, step=step_value)\n",
        "      mlflow.log_metric(\"layer2\", layer2, step=step_value)\n",
        "      mlflow.log_metric(\"layer3\", layer3, step=step_value)\n",
        "      mlflow.log_metric(\"layer4\", layer4, step=step_value)\n",
        "      mlflow.log_metric(\"layer5\", layer5, step=step_value)\n",
        "      mlflow.log_metric(\"layer6\", layer6, step=step_value)\n",
        "      mlflow.log_metric(\"layer7\", layer7, step=step_value)\n",
        "      mlflow.log_metric(\"layer8\", layer8, step=step_value)\n",
        "      mlflow.log_metric(\"layer9\", layer9, step=step_value)\n",
        "      mlflow.log_metric(\"layer10\", layer10, step=step_value)\n",
        "      mlflow.log_metric(\"layer11\", layer11, step=step_value)\n",
        "      mlflow.log_metric(\"layer12\", layer12, step=step_value)\n",
        "      mlflow.log_metric(\"layer13\", layer13, step=step_value)\n",
        "      mlflow.log_metric(\"layer14\", layer14, step=step_value)\n",
        "      mlflow.log_metric(\"layer15\", layer15, step=step_value)\n",
        "      mlflow.log_metric(\"layer16\", layer16, step=step_value)\n",
        "\n",
        "      mlflow.log_metric(\"GA_accuracy\", acc, step=step_value)\n",
        "      mlflow.log_metric(\"GA_precision\", pre, step=step_value)\n",
        "      mlflow.log_metric(\"GA_recall\", rec, step=step_value)\n",
        "      mlflow.log_metric(\"GA_f1\", f1, step=step_value)\n",
        "\n",
        "      #Take its configuration to copy it as the best solution\n",
        "      search_path = path_parameters+\"solution_\"+str(i)+\"_\"+str(step_value)+\".pth\"\n",
        "      if os.path.exists(search_path):\n",
        "        model_path = path_parameters+\"best_solution.pth\"\n",
        "        shutil.copy(search_path, model_path)\n",
        "\n",
        "    i+=1\n",
        "\n",
        "  #Update AllSolutions\n",
        "  with open(file_path2, \"a\", newline=\"\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerows(actual_population)\n",
        "\n",
        "  #Update ActualSolution to write the fitness values\n",
        "  with open(file_path1, \"w\", newline=\"\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"learning_rate\",\"batch_size\",\"num_epoch\",\"optimizer\",\"layer1\",\"layer2\",\"layer3\",\"layer4\",\"layer5\",\"layer6\",\"layer7\",\"layer8\",\"layer9\",\"layer10\",\"layer11\",\"layer12\",\"layer13\",\"layer14\",\"layer15\",\"layer16\",\"fitness_value\",\"accuracy\",\"precision\",\"recall\",\"f1\",\"evaluation\"])\n",
        "    writer.writerows(actual_population)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSYuAD7tiUMZ"
      },
      "source": [
        "# Fitness function\n",
        "Our **fitness function** is:\n",
        "> fitness(x) = f(x)/∑ f(j) where j ∈ P-{x} and P represents the population\n",
        "\n",
        "We get the fitness value from a csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQsj6Xc9irlm"
      },
      "outputs": [],
      "source": [
        "#This parameters are required by PyGAD\n",
        "def fitness_function_calculator(ga_instance, solution, solution_idx):\n",
        "  global solution_number\n",
        "  solution_number+=1\n",
        "\n",
        "  #We call the evaluation function only if we are not in the initial population step\n",
        "  if ga_instance.generations_completed != 0 and solution_number==1:\n",
        "    evaluate_solutions(ga_instance.generations_completed, ga_instance.population, ga_instance)\n",
        "\n",
        "  file_path = \"\"\n",
        "  if script_owner:\n",
        "    file_path = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGASecondApproach/ActualPopulation.csv\"\n",
        "  else:\n",
        "    file_path = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGASecondApproach/ActualPopulation.csv\"\n",
        "\n",
        "  flag = False\n",
        "  fitness_value = 0\n",
        "  learning_rate = float(solution[0])\n",
        "  batch_size = int(solution[1])\n",
        "  num_epoch = int(solution[2])\n",
        "  optimizer = int(solution[3])\n",
        "  layer1 = int(solution[4])\n",
        "  layer2 = int(solution[5])\n",
        "  layer3 = int(solution[6])\n",
        "  layer4 = int(solution[7])\n",
        "  layer5 = int(solution[8])\n",
        "  layer6 = int(solution[9])\n",
        "  layer7 = int(solution[10])\n",
        "  layer8 = int(solution[11])\n",
        "  layer9 = int(solution[12])\n",
        "  layer10 = int(solution[13])\n",
        "  layer11 = int(solution[14])\n",
        "  layer12 = int(solution[15])\n",
        "  layer13 = int(solution[16])\n",
        "  layer14 = int(solution[17])\n",
        "  layer15 = int(solution[18])\n",
        "  layer16 = int(solution[19])\n",
        "\n",
        "  with open(file_path, \"r\", newline=\"\") as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    next(reader) #Jump the first row (contains the file header)\n",
        "    for row in reader:\n",
        "      #Convert the values in the correct format\n",
        "      lr_row = float(row[0])\n",
        "      batch_row = int(float(row[1]))\n",
        "      epoch_row = int(float(row[2]))\n",
        "      optimizer_row = int(float(row[3]))\n",
        "\n",
        "      layer1_row = int(float(row[4]))\n",
        "      layer2_row = int(float(row[5]))\n",
        "      layer3_row = int(float(row[6]))\n",
        "      layer4_row = int(float(row[7]))\n",
        "      layer5_row = int(float(row[8]))\n",
        "      layer6_row = int(float(row[9]))\n",
        "      layer7_row = int(float(row[10]))\n",
        "      layer8_row = int(float(row[11]))\n",
        "      layer9_row = int(float(row[12]))\n",
        "      layer10_row = int(float(row[13]))\n",
        "      layer11_row = int(float(row[14]))\n",
        "      layer12_row = int(float(row[15]))\n",
        "      layer13_row = int(float(row[16]))\n",
        "      layer14_row = int(float(row[17]))\n",
        "      layer15_row = int(float(row[18]))\n",
        "      layer16_row = int(float(row[19]))\n",
        "\n",
        "      value = float(row[20])\n",
        "\n",
        "      condition = learning_rate==lr_row and batch_size==batch_row and num_epoch==epoch_row and optimizer==optimizer_row and layer1==layer1_row and layer2==layer2_row and layer3==layer3_row and layer4==layer4_row and layer5==layer5_row and layer6==layer6_row and layer7==layer7_row and layer8==layer8_row and layer9==layer9_row and layer10==layer10_row and layer11==layer11_row and layer12==layer12_row and layer13==layer13_row and layer14==layer14_row and layer15==layer15_row and layer16==layer16_row\n",
        "      if condition:\n",
        "        flag = True\n",
        "        fitness_value = value\n",
        "        break\n",
        "\n",
        "  #To plot the ga data\n",
        "  if solution_number==8:\n",
        "    solution_number=0\n",
        "    if ga_instance.generations_completed != 0:\n",
        "      step_value=0\n",
        "      global num_step\n",
        "      if num_step is None:\n",
        "        step_value=ga_instance.generations_completed\n",
        "      else:\n",
        "        step_value= ga_instance.generations_completed+num_step\n",
        "\n",
        "      if script_owner:\n",
        "        ga_instance.plot_fitness(save_dir='/content/drive/MyDrive/SE4AI/Model/EvaluationGASecondApproach/PlotFitnessGA2Approach_'+step_value+'.png')\n",
        "        ga_instance.plot_genes(save_dir='/content/drive/MyDrive/SE4AI/Model/EvaluationGASecondApproach/PlotGenesGA2Approach_'+step_value+'.png')\n",
        "        ga_instance.plot_new_solution_rate(save_dir='/content/drive/MyDrive/SE4AI/Model/EvaluationGASecondApproach/PlotExploredSolutionsGA2Approach_'+step_value+'.png')\n",
        "      else:\n",
        "        ga_instance.plot_fitness(save_dir='/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGASecondApproach/PlotFitnessGA2Approach_'+step_value+'.png')\n",
        "        ga_instance.plot_genes(save_dir='/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGASecondApproach/PlotGenesGA2Approach_'+step_value+'.png')\n",
        "        ga_instance.plot_new_solution_rate(save_dir='/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGASecondApproach/PlotExploredSolutionsGA2Approach_'+step_value+'.png')\n",
        "\n",
        "  if flag:\n",
        "    return fitness_value\n",
        "  else:\n",
        "    print(\"Row not found! (fitness function) \",solution)\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye1mBaYYkDni"
      },
      "source": [
        "# Initial population\n",
        "The initial population is composed of 30 random solutions.\n",
        "Each individual has this configuration:\n",
        "\n",
        "[ learning_rate,batch_size,num_epoch,optimizer,layer1,layer2,layer3,layer4,layer5,layer6,layer7,layer8,layer9,layer10 ]\n",
        "\n",
        "We evaluate the initial population and store their fitness value in a csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMhN15VblW_l"
      },
      "outputs": [],
      "source": [
        "def fun_on_start(ga_instance):\n",
        "  print(\"Initialize the population\")\n",
        "  population = ga_instance.population\n",
        "  population_list = population.tolist()\n",
        "\n",
        "  global max_fitness\n",
        "  global num_step\n",
        "  step_value = 0\n",
        "  sum = 0\n",
        "\n",
        "  path_parameters = \"\"\n",
        "  file_path1 = file_path2 = file_path3 = \"\"\n",
        "  if script_owner:\n",
        "    path_parameters = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGASecondApproach/ModelsConfigurations/\"\n",
        "    file_path1 = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGASecondApproach/ActualPopulation.csv\"\n",
        "    file_path2 = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGASecondApproach/AllSolutions.csv\"\n",
        "    file_path3 = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGASecondApproach/Checkpoint.csv\"\n",
        "  else:\n",
        "    path_parameters = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGASecondApproach/ModelsConfigurations/\"\n",
        "    file_path1 = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGASecondApproach/ActualPopulation.csv\"\n",
        "    file_path2 = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGASecondApproach/AllSolutions.csv\"\n",
        "    file_path3 = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGASecondApproach/Checkpoint.csv\"\n",
        "\n",
        "\n",
        "  #Make a copy to handle the no valid solutions\n",
        "  population_copy = population_list.copy()\n",
        "  copy_flag = False\n",
        "\n",
        "  if num_step is None:\n",
        "    #Check if the actual population is valid or contains clones\n",
        "    i = 0\n",
        "    for solution in population_list:\n",
        "      solution_app = solution.copy()\n",
        "      layers = solution_app[4:]\n",
        "      flag, layer_size = check_validity(layers) #check if the solution is valid\n",
        "      if not flag:\n",
        "        copy_flag = True\n",
        "        solution_app, layer_size = replace_solution(solution_app)\n",
        "        population_copy[i] = solution_app\n",
        "\n",
        "      if check_clone_presence(population_copy, solution_app): #check if the solution appears more than one time in the actual population\n",
        "        copy_flag = True\n",
        "        new_solution = replace_clone(population_copy)\n",
        "        population_copy[i] = new_solution\n",
        "\n",
        "      i+=1\n",
        "\n",
        "    if copy_flag:\n",
        "      ga_instance.population = np.array(population_copy)\n",
        "      population_list = population_copy.copy()\n",
        "      del population_copy\n",
        "\n",
        "    #Create the csv files\n",
        "    with open(file_path1, \"w\", newline=\"\") as csvfile: #ActualPopulation\n",
        "      writer = csv.writer(csvfile)\n",
        "      writer.writerow([\"learning_rate\",\"batch_size\",\"num_epoch\",\"optimizer\",\"layer1\",\"layer2\",\"layer3\",\"layer4\",\"layer5\",\"layer6\",\"layer7\",\"layer8\",\"layer9\",\"layer10\",\"layer11\",\"layer12\",\"layer13\",\"layer14\",\"layer15\",\"layer16\",\"fitness_value\",\"accuracy\",\"precision\",\"recall\",\"f1\",\"evaluation\"])\n",
        "\n",
        "    with open(file_path2, \"w\", newline=\"\") as csvfile: #AllSolutions\n",
        "      writer = csv.writer(csvfile)\n",
        "      writer.writerow([\"learning_rate\",\"batch_size\",\"num_epoch\",\"optimizer\",\"layer1\",\"layer2\",\"layer3\",\"layer4\",\"layer5\",\"layer6\",\"layer7\",\"layer8\",\"layer9\",\"layer10\",\"layer11\",\"layer12\",\"layer13\",\"layer14\",\"layer15\",\"layer16\",\"fitness_value\",\"accuracy\",\"precision\",\"recall\",\"f1\",\"evaluation\"])\n",
        "\n",
        "    with open(file_path1, \"a\", newline=\"\") as csvfile:\n",
        "      writer = csv.writer(csvfile)\n",
        "\n",
        "      for solution in population_list:\n",
        "        temp_solution = solution.copy()\n",
        "        temp_solution.extend([None,None,None,None,None,None])\n",
        "        writer.writerow(temp_solution)\n",
        "\n",
        "    #Save checkpoint\n",
        "    run = mlflow.active_run()\n",
        "    experiment_id = run.info.experiment_id\n",
        "    with open(file_path3, \"w\", newline=\"\") as csvfile:\n",
        "      writer =csv.writer(csvfile)\n",
        "      writer.writerow([\"num_generation_step\",\"mlflow_experiment_id\"])\n",
        "      writer.writerow([step_value, experiment_id])\n",
        "  else:\n",
        "    #We have a checkpoint\n",
        "    step_value = num_step\n",
        "\n",
        "  #To track the solutions performance\n",
        "  i = 0\n",
        "  for solution in population_list:\n",
        "    print(\"Training the \",i+1,\" solution...\")\n",
        "    flag_to_train = True\n",
        "    learning_rate = float(solution[0])\n",
        "    batch_size = int(solution[1])\n",
        "    num_epoch = int(solution[2])\n",
        "    optimizer = int(solution[3])\n",
        "    layer1 = int(solution[4])\n",
        "    layer2 = int(solution[5])\n",
        "    layer3 = int(solution[6])\n",
        "    layer4 = int(solution[7])\n",
        "    layer5 = int(solution[8])\n",
        "    layer6 = int(solution[9])\n",
        "    layer7 = int(solution[10])\n",
        "    layer8 = int(solution[11])\n",
        "    layer9 = int(solution[12])\n",
        "    layer10 = int(solution[13])\n",
        "    layer11 = int(solution[14])\n",
        "    layer12 = int(solution[15])\n",
        "    layer13 = int(solution[16])\n",
        "    layer14 = int(solution[17])\n",
        "    layer15 = int(solution[18])\n",
        "    layer16 = int(solution[19])\n",
        "\n",
        "    #Check how many times the solution is in ActualPopulation\n",
        "    df = pd.read_csv(file_path1)\n",
        "    matching_rows = df.loc[(df[\"learning_rate\"] == learning_rate) & (df[\"batch_size\"] == batch_size) & (df[\"num_epoch\"] == num_epoch) & (df[\"optimizer\"] == optimizer) & (df[\"layer1\"] == layer1) & (df[\"layer2\"] == layer2) & (df[\"layer3\"] == layer3) & (df[\"layer4\"] == layer4) & (df[\"layer5\"] == layer5) & (df[\"layer6\"] == layer6) & (df[\"layer7\"] == layer7) & (df[\"layer8\"] == layer8) & (df[\"layer9\"] == layer9) & (df[\"layer10\"] == layer10) & (df[\"layer11\"] == layer11) & (df[\"layer12\"] == layer12) & (df[\"layer13\"] == layer13) & (df[\"layer14\"] == layer14) & (df[\"layer15\"] == layer15) & (df[\"layer16\"] == layer16)]\n",
        "    position = matching_rows.index[0]\n",
        "    if pd.isna(df.at[position, \"evaluation\"]):\n",
        "      #It is not trained\n",
        "\n",
        "      #Check if the solution already exists in AllSolutions\n",
        "      if step_value!=0:\n",
        "        df = pd.read_csv(file_path2)\n",
        "        matching_rows = df.loc[(df[\"learning_rate\"] == learning_rate) & (df[\"batch_size\"] == batch_size) & (df[\"num_epoch\"] == num_epoch) & (df[\"optimizer\"] == optimizer) & (df[\"layer1\"] == layer1) & (df[\"layer2\"] == layer2) & (df[\"layer3\"] == layer3) & (df[\"layer4\"] == layer4) & (df[\"layer5\"] == layer5) & (df[\"layer6\"] == layer6) & (df[\"layer7\"] == layer7) & (df[\"layer8\"] == layer8) & (df[\"layer9\"] == layer9) & (df[\"layer10\"] == layer10) & (df[\"layer11\"] == layer11) & (df[\"layer12\"] == layer12) & (df[\"layer13\"] == layer13) & (df[\"layer14\"] == layer14) & (df[\"layer15\"] == layer15) & (df[\"layer16\"] == layer16)]\n",
        "        if not matching_rows.empty:\n",
        "          #The solution already exists, therefore we do not re-train it\n",
        "          flag_to_train = False\n",
        "\n",
        "          position = matching_rows.index[0]\n",
        "          solution_in_all = df.loc[position]\n",
        "          acc = float(solution_in_all[\"accuracy\"])\n",
        "          pre = float(solution_in_all[\"precision\"])\n",
        "          rec = float(solution_in_all[\"recall\"])\n",
        "          f1 = float(solution_in_all[\"f1\"])\n",
        "          evaluation = float(solution_in_all[\"evaluation\"])\n",
        "\n",
        "          sum+=evaluation\n",
        "\n",
        "          #Update ActualPopulation\n",
        "          df = pd.read_csv(file_path1)\n",
        "          matching_rows = df.loc[(df[\"learning_rate\"] == learning_rate) & (df[\"batch_size\"] == batch_size) & (df[\"num_epoch\"] == num_epoch) & (df[\"optimizer\"] == optimizer) & (df[\"layer1\"] == layer1) & (df[\"layer2\"] == layer2) & (df[\"layer3\"] == layer3) & (df[\"layer4\"] == layer4) & (df[\"layer5\"] == layer5) & (df[\"layer6\"] == layer6) & (df[\"layer7\"] == layer7) & (df[\"layer8\"] == layer8) & (df[\"layer9\"] == layer9) & (df[\"layer10\"] == layer10) & (df[\"layer11\"] == layer11) & (df[\"layer12\"] == layer12) & (df[\"layer13\"] == layer13) & (df[\"layer14\"] == layer14) & (df[\"layer15\"] == layer15) & (df[\"layer16\"] == layer16)]\n",
        "\n",
        "          if not matching_rows.empty:\n",
        "            #Take the solution index\n",
        "            idx = matching_rows.index[0]\n",
        "            #Update the evaluation metrics\n",
        "            df.at[idx, \"accuracy\"] = acc\n",
        "            df.at[idx, \"precision\"] = pre\n",
        "            df.at[idx, \"recall\"] = rec\n",
        "            df.at[idx, \"f1\"] = f1\n",
        "            df.at[idx, \"evaluation\"] = evaluation\n",
        "\n",
        "            #save the updated ActualPopulation file\n",
        "            df.to_csv(file_path1, index=False)\n",
        "\n",
        "          #Copy the solution configuration (.pth)\n",
        "          individual = position % 8 #solution position in population\n",
        "          generation = int(position/8) #num generation where the solution was created\n",
        "          search_path = path_parameters+\"solution_\"+str(individual)+\"_\"+str(generation)+\".pth\"\n",
        "          if os.path.exists(search_path):\n",
        "            model_path = path_parameters+\"solution_\"+str(i)+\"_\"+str(step_value)+\".pth\"\n",
        "            shutil.copy(search_path, model_path)\n",
        "        else:\n",
        "          #The solution does not exists in AllSolution\n",
        "          #The solution was not trained, we will train it\n",
        "          flag_to_train = True\n",
        "    else:\n",
        "      #The solution was trained, therefore we do not re-train it\n",
        "      print(\"The solution \",solution,\" is already trained (initial polulation)\")\n",
        "      flag_to_train = False\n",
        "      row = df.loc[position]\n",
        "      eval = float(row[\"evaluation\"])\n",
        "      sum += eval\n",
        "\n",
        "    if flag_to_train:\n",
        "      #batch_size\n",
        "      size = 0\n",
        "      match batch_size:\n",
        "        case 1:\n",
        "          size = 32\n",
        "        case 2:\n",
        "          size = 64\n",
        "        case _:\n",
        "          size = 32\n",
        "\n",
        "      #num_epoch\n",
        "      epoch = 0\n",
        "      match num_epoch:\n",
        "        case 1:\n",
        "          epoch = 64\n",
        "        case 2:\n",
        "          epoch = 96\n",
        "        case 3:\n",
        "          epoch = 128\n",
        "        case _:\n",
        "          epoch = 64\n",
        "\n",
        "      #Take the model architecture from the solution\n",
        "      layers = solution[4:]\n",
        "\n",
        "      #Take the input size of the first linear layer\n",
        "      flag, layer_size = check_validity(layers)\n",
        "\n",
        "      #Train model\n",
        "      print(\"Evaluating the solution: \",solution,\" (initial population)\")\n",
        "      best_model_configuration, acc, pre, rec, f1 = start_process(model_type=2, architecture=layers, linear_size=layer_size, bool_mlflow=False, learning_rate=learning_rate, batch_size=size, num_epoch=epoch, opt=optimizer)\n",
        "      solution_evaluation = (0.20*acc)+(0.35*pre)+(0.45*rec)\n",
        "      sum+=solution_evaluation\n",
        "\n",
        "      #Store its configuration\n",
        "      model_path = path_parameters+\"solution_\"+str(i)+\"_\"+str(step_value)+\".pth\"\n",
        "      torch.save(best_model_configuration, model_path)\n",
        "\n",
        "      #Update ActualPopulation\n",
        "      df = pd.read_csv(file_path1)\n",
        "      matching_rows = df.loc[(df[\"learning_rate\"] == learning_rate) & (df[\"batch_size\"] == batch_size) & (df[\"num_epoch\"] == num_epoch) & (df[\"optimizer\"] == optimizer) & (df[\"layer1\"] == layer1) & (df[\"layer2\"] == layer2) & (df[\"layer3\"] == layer3) & (df[\"layer4\"] == layer4) & (df[\"layer5\"] == layer5) & (df[\"layer6\"] == layer6) & (df[\"layer7\"] == layer7) & (df[\"layer8\"] == layer8) & (df[\"layer9\"] == layer9) & (df[\"layer10\"] == layer10) & (df[\"layer11\"] == layer11) & (df[\"layer12\"] == layer12) & (df[\"layer13\"] == layer13) & (df[\"layer14\"] == layer14) & (df[\"layer15\"] == layer15) & (df[\"layer16\"] == layer16)]\n",
        "\n",
        "      if not matching_rows.empty:\n",
        "        #Take the solution index\n",
        "        idx = matching_rows.index[0]\n",
        "        #Update the evaluation metrics\n",
        "        df.at[idx, \"accuracy\"] = acc\n",
        "        df.at[idx, \"precision\"] = pre\n",
        "        df.at[idx, \"recall\"] = rec\n",
        "        df.at[idx, \"f1\"] = f1\n",
        "        df.at[idx, \"evaluation\"] = solution_evaluation\n",
        "\n",
        "        #save the updated ActualPopulation file\n",
        "        df.to_csv(file_path1, index=False)\n",
        "      else:\n",
        "        print(\"Row not found! (initial population, flag_to_train:True): \",solution)\n",
        "\n",
        "    i+=1\n",
        "\n",
        "  actual_population = list()\n",
        "  #Compute the fitness_value\n",
        "  with open(file_path1, \"r\", newline=\"\") as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    next(reader)\n",
        "    for row in reader:\n",
        "      evaluation = float(row[25])\n",
        "      row_copy = row.copy()\n",
        "      row_copy[20] = evaluation/(sum-evaluation)\n",
        "      actual_population.append(row_copy)\n",
        "\n",
        "  #If we start from a checkpoint\n",
        "  if step_value!=0:\n",
        "    #Update the max_fitness value with the fitness value of the last best individual\n",
        "    max_flag=False\n",
        "    for solution in actual_population:\n",
        "      learning_rate = float(solution[0])\n",
        "      batch_size = int(float(solution[1]))\n",
        "      num_epoch = int(float(solution[2]))\n",
        "      optimizer = int(float(solution[3]))\n",
        "      layer1 = int(float(solution[4]))\n",
        "      layer2 = int(float(solution[5]))\n",
        "      layer3 = int(float(solution[6]))\n",
        "      layer4 = int(float(solution[7]))\n",
        "      layer5 = int(float(solution[8]))\n",
        "      layer6 = int(float(solution[9]))\n",
        "      layer7 = int(float(solution[10]))\n",
        "      layer8 = int(float(solution[11]))\n",
        "      layer9 = int(float(solution[12]))\n",
        "      layer10 = int(float(solution[13]))\n",
        "      layer11 = int(float(solution[14]))\n",
        "      layer12 = int(float(solution[15]))\n",
        "      layer13 = int(float(solution[16]))\n",
        "      layer14 = int(float(solution[17]))\n",
        "      layer15 = int(float(solution[18]))\n",
        "      layer16 = int(float(solution[19]))\n",
        "\n",
        "      df = pd.read_csv(file_path2)\n",
        "      matching_rows = df.loc[(df[\"learning_rate\"] == learning_rate) & (df[\"batch_size\"] == batch_size) & (df[\"num_epoch\"] == num_epoch) & (df[\"optimizer\"] == optimizer) & (df[\"layer1\"] == layer1) & (df[\"layer2\"] == layer2) & (df[\"layer3\"] == layer3) & (df[\"layer4\"] == layer4) & (df[\"layer5\"] == layer5) & (df[\"layer6\"] == layer6) & (df[\"layer7\"] == layer7) & (df[\"layer8\"] == layer8) & (df[\"layer9\"] == layer9) & (df[\"layer10\"] == layer10) & (df[\"layer11\"] == layer11) & (df[\"layer12\"] == layer12) & (df[\"layer13\"] == layer13) & (df[\"layer14\"] == layer14) & (df[\"layer15\"] == layer15) & (df[\"layer16\"] == layer16)]\n",
        "\n",
        "      if not matching_rows.empty:\n",
        "        position = matching_rows.index[len(matching_rows)-1]\n",
        "        last_occurence = df.loc[position]\n",
        "        fitness = float(last_occurence[\"fitness_value\"])\n",
        "        if max_fitness == fitness:\n",
        "          max_flag=True\n",
        "          max_fitness = float(solution[20])\n",
        "          break\n",
        "\n",
        "    if not max_flag:\n",
        "      max_fitness=0 #Whether in the actual population we have not the best solution of the last population, we have not math in the previous for statement, therefore we have not a max_fitness in this generation\n",
        "\n",
        "  i=0\n",
        "  #Find the actual best solution\n",
        "  for solution in actual_population:\n",
        "    lr = float(solution[0])\n",
        "    batch = int(float(solution[1]))\n",
        "    epoch = int(float(solution[2]))\n",
        "    optimizer = int(float(solution[3]))\n",
        "    layer1 = int(float(solution[4]))\n",
        "    layer2 = int(float(solution[5]))\n",
        "    layer3 = int(float(solution[6]))\n",
        "    layer4 = int(float(solution[7]))\n",
        "    layer5 = int(float(solution[8]))\n",
        "    layer6 = int(float(solution[9]))\n",
        "    layer7 = int(float(solution[10]))\n",
        "    layer8 = int(float(solution[11]))\n",
        "    layer9 = int(float(solution[12]))\n",
        "    layer10 = int(float(solution[13]))\n",
        "    layer11 = int(float(solution[14]))\n",
        "    layer12 = int(float(solution[15]))\n",
        "    layer13 = int(float(solution[16]))\n",
        "    layer14 = int(float(solution[17]))\n",
        "    layer15 = int(float(solution[18]))\n",
        "    layer16 = int(float(solution[19]))\n",
        "\n",
        "    fitness_value = float(solution[20])\n",
        "    acc = float(solution[21])\n",
        "    pre = float(solution[22])\n",
        "    rec = float(solution[23])\n",
        "    f1 = float(solution[24])\n",
        "\n",
        "    #Check if it is the best solution\n",
        "    if fitness_value > max_fitness:\n",
        "      max_fitness = fitness_value\n",
        "      mlflow.log_metric(\"GA_learning_rate\", lr, step=step_value)\n",
        "      mlflow.log_metric(\"GA_batch_size\", batch, step=step_value)\n",
        "      mlflow.log_metric(\"GA_num_epoch\", epoch, step=step_value)\n",
        "      mlflow.log_metric(\"GA_optimizer\", optimizer, step=step_value)\n",
        "      mlflow.log_metric(\"layer1\", layer1, step=step_value)\n",
        "      mlflow.log_metric(\"layer2\", layer2, step=step_value)\n",
        "      mlflow.log_metric(\"layer3\", layer3, step=step_value)\n",
        "      mlflow.log_metric(\"layer4\", layer4, step=step_value)\n",
        "      mlflow.log_metric(\"layer5\", layer5, step=step_value)\n",
        "      mlflow.log_metric(\"layer6\", layer6, step=step_value)\n",
        "      mlflow.log_metric(\"layer7\", layer7, step=step_value)\n",
        "      mlflow.log_metric(\"layer8\", layer8, step=step_value)\n",
        "      mlflow.log_metric(\"layer9\", layer9, step=step_value)\n",
        "      mlflow.log_metric(\"layer10\", layer10, step=step_value)\n",
        "      mlflow.log_metric(\"layer11\", layer11, step=step_value)\n",
        "      mlflow.log_metric(\"layer12\", layer12, step=step_value)\n",
        "      mlflow.log_metric(\"layer13\", layer13, step=step_value)\n",
        "      mlflow.log_metric(\"layer14\", layer14, step=step_value)\n",
        "      mlflow.log_metric(\"layer15\", layer15, step=step_value)\n",
        "      mlflow.log_metric(\"layer16\", layer16, step=step_value)\n",
        "\n",
        "      mlflow.log_metric(\"GA_accuracy\", acc, step=step_value)\n",
        "      mlflow.log_metric(\"GA_precision\", pre, step=step_value)\n",
        "      mlflow.log_metric(\"GA_recall\", rec, step=step_value)\n",
        "      mlflow.log_metric(\"GA_f1\", f1, step=step_value)\n",
        "\n",
        "      #Take its configuration to copy it as the best solution\n",
        "      search_path = path_parameters+\"solution_\"+str(i)+\"_\"+str(step_value)+\".pth\"\n",
        "      if os.path.exists(search_path):\n",
        "        model_path = path_parameters+\"best_solution.pth\"\n",
        "        shutil.copy(search_path, model_path)\n",
        "\n",
        "    i+=1\n",
        "\n",
        "  #Update AllSolutions\n",
        "  with open(file_path2, \"a\", newline=\"\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerows(actual_population)\n",
        "\n",
        "  #Update ActualPopulation to write the fitness values\n",
        "  with open(file_path1, \"w\", newline=\"\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"learning_rate\",\"batch_size\",\"num_epoch\",\"optimizer\",\"layer1\",\"layer2\",\"layer3\",\"layer4\",\"layer5\",\"layer6\",\"layer7\",\"layer8\",\"layer9\",\"layer10\",\"layer11\",\"layer12\",\"layer13\",\"layer14\",\"layer15\",\"layer16\",\"fitness_value\",\"accuracy\",\"precision\",\"recall\",\"f1\",\"evaluation\"])\n",
        "    writer.writerows(actual_population)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9Oh9Hx4jAXT"
      },
      "source": [
        "# Tournament selection\n",
        "At each tournament, we will select K=4 solutions\n",
        "\n",
        "We will apply the tournament 4 times to obtain M=4 parents who will attend the crossover step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlIjDMhvj4ok"
      },
      "outputs": [],
      "source": [
        "def my_tournament_selection(fitness_values,required_number,ga_instance):\n",
        "  print(\"Started the Tournament\")\n",
        "  population = ga_instance.population\n",
        "  population_list = population.tolist()\n",
        "\n",
        "  winners = []\n",
        "  winners_index = []\n",
        "  for i in range(required_number):\n",
        "    selected_flag = False\n",
        "    selected_indices = None\n",
        "\n",
        "    while not selected_flag:\n",
        "      #Select random solution until there is not a solution already selected in the previous tournament\n",
        "      selected_indices = np.random.choice(np.arange(len(population_list)), size=4, replace=False) #replace=False -> in this way we don't select the same individual more then one time\n",
        "      flag = True\n",
        "      for index in selected_indices:\n",
        "        if index in winners_index:\n",
        "          flag = False\n",
        "          break\n",
        "\n",
        "      if flag:\n",
        "        selected_flag = True\n",
        "\n",
        "    winner = None #to store the selected individual\n",
        "    best_fitness = 0 #to store the relative fitness value\n",
        "    winner_position = None #to store the relative position in the population\n",
        "\n",
        "    for index in selected_indices:\n",
        "      solution = population_list[index]\n",
        "      solution_fitness = fitness_values[index]\n",
        "      if solution_fitness > best_fitness:\n",
        "        best_fitness = solution_fitness\n",
        "        winner = solution\n",
        "        winner_position = index\n",
        "\n",
        "\n",
        "    #Record the winner\n",
        "    winners.append(winner)\n",
        "\n",
        "    #Record its index in the population (required by PyGAD)\n",
        "    winners_index.append(winner_position)\n",
        "\n",
        "  #Transform them in numpy array because it is required by PyGAD\n",
        "  print(\"The winners are:\")\n",
        "  print(winners)\n",
        "  winners_numpy = np.array(winners)\n",
        "  winners_index_numpy = np.array(winners_index)\n",
        "\n",
        "  return winners_numpy, winners_index_numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAwx4Hl_GEn0"
      },
      "source": [
        "# Boundary function\n",
        "We will execute this function only if the genetic algorithm stops at the last generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RXK84fFGEn0"
      },
      "outputs": [],
      "source": [
        "#This function is called when Google stopped the GA in the last generation.\n",
        "def train_solutions_last_generation(actual_population_path, best_path, id):\n",
        "  sum = 0\n",
        "  solutions_list = list()\n",
        "  i = 0\n",
        "  global max_fitness\n",
        "  path_parameters = \"\"\n",
        "  if script_owner:\n",
        "    path_parameters = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGASecondApproach/ModelsConfigurations/\"\n",
        "    file_path2 = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGASecondApproach/AllSolutions.csv\"\n",
        "  else:\n",
        "    path_parameters = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGASecondApproach/ModelsConfigurations/\"\n",
        "    file_path2 = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGASecondApproach/AllSolutions.csv\"\n",
        "\n",
        "  with mlflow.start_run(experiment_id=id):\n",
        "    population_list = list()\n",
        "    with open(actual_population_path, \"r\", newline=\"\") as csvfile:\n",
        "      reader = csv.reader(csvfile)\n",
        "      next(reader) #To jump the file header\n",
        "      for row in reader:\n",
        "        lr = float(row[0])\n",
        "        batch = int(float(row[1]))\n",
        "        epoch = int(float(row[2]))\n",
        "        opt = int(float(row[3]))\n",
        "        layer1 = int(float(row[4]))\n",
        "        layer2 = int(float(row[5]))\n",
        "        layer3 = int(float(row[6]))\n",
        "        layer4 = int(float(row[7]))\n",
        "        layer5 = int(float(row[8]))\n",
        "        layer6 = int(float(row[9]))\n",
        "        layer7 = int(float(row[10]))\n",
        "        layer8 = int(float(row[11]))\n",
        "        layer9 = int(float(row[12]))\n",
        "        layer10 = int(float(row[13]))\n",
        "        layer11 = int(float(row[14]))\n",
        "        layer12 = int(float(row[15]))\n",
        "        layer13 = int(float(row[16]))\n",
        "        layer14 = int(float(row[17]))\n",
        "        layer15 = int(float(row[18]))\n",
        "        layer16 = int(float(row[19]))\n",
        "\n",
        "        acc = row[21]\n",
        "        pre = row[22]\n",
        "        rec = row[23]\n",
        "        f1 = row[24]\n",
        "        eval = row[25]\n",
        "        population_list.append([lr,batch,epoch,opt,layer1,layer2,layer3,layer4,layer5,layer6,layer7,layer8,layer9,layer10,layer11,layer12,layer13,layer14,layer15,layer16,None,acc,pre,rec,f1,eval])\n",
        "\n",
        "    for solution in population_list:\n",
        "      train_flag = True\n",
        "\n",
        "      learning_rate = solution[0]\n",
        "      batch_size = solution[1]\n",
        "      num_epoch = solution[2]\n",
        "      optimizer = solution[3]\n",
        "      layer1 = solution[4]\n",
        "      layer2 = solution[5]\n",
        "      layer3 = solution[6]\n",
        "      layer4 = solution[7]\n",
        "      layer5 = solution[8]\n",
        "      layer6 = solution[9]\n",
        "      layer7 = solution[10]\n",
        "      layer8 = solution[11]\n",
        "      layer9 = solution[12]\n",
        "      layer10 = solution[13]\n",
        "      layer11 = solution[14]\n",
        "      layer12 = solution[16]\n",
        "      layer13 = solution[16]\n",
        "      layer14 = solution[17]\n",
        "      layer15 = solution[18]\n",
        "      layer16 = solution[19]\n",
        "\n",
        "      if solution[25]==\"\":\n",
        "        train_flag = True\n",
        "      else:\n",
        "        train_flag = False\n",
        "        acc = float(solution[21])\n",
        "        pre = float(solution[22])\n",
        "        rec = float(solution[23])\n",
        "        f1 = float(solution[24])\n",
        "        eval = float(solution[25])\n",
        "        solutions_list.append([learning_rate,batch_size,num_epoch,optimizer,layer1,layer2,layer3,layer4,layer5,layer6,layer7,layer8,layer9,layer10,layer11,layer12,layer13,layer14,layer15,layer16,None,acc,pre,rec,f1,eval])\n",
        "        sum+=eval\n",
        "\n",
        "      if train_flag:\n",
        "        #Check if the solution already exists in AllSolutions\n",
        "        df = pd.read_csv(file_path2)\n",
        "        matching_rows = df.loc[(df[\"learning_rate\"] == learning_rate) & (df[\"batch_size\"] == batch_size) & (df[\"num_epoch\"] == num_epoch) & (df[\"optimizer\"] == optimizer) & (df[\"layer1\"] == layer1) & (df[\"layer2\"] == layer2) & (df[\"layer3\"] == layer3) & (df[\"layer4\"] == layer4) & (df[\"layer5\"] == layer5) & (df[\"layer6\"] == layer6) & (df[\"layer7\"] == layer7) & (df[\"layer8\"] == layer8) & (df[\"layer9\"] == layer9) & (df[\"layer10\"] == layer10) & (df[\"layer11\"] == layer11) & (df[\"layer12\"] == layer12) & (df[\"layer13\"] == layer13) & (df[\"layer14\"] == layer14) & (df[\"layer15\"] == layer15) & (df[\"layer16\"] == layer16)]\n",
        "        if not matching_rows.empty:\n",
        "          position = matching_rows.index[0]\n",
        "          solution_in_all = df.loc[position]\n",
        "          acc = float(solution_in_all[\"accuracy\"])\n",
        "          pre = float(solution_in_all[\"precision\"])\n",
        "          rec = float(solution_in_all[\"recall\"])\n",
        "          f1 = float(solution_in_all[\"f1\"])\n",
        "          evaluation = float(solution_in_all[\"evaluation\"])\n",
        "\n",
        "          sum+=evaluation\n",
        "\n",
        "          #Update ActualPopulation\n",
        "          df = pd.read_csv(actual_population_path)\n",
        "          matching_rows = df.loc[(df[\"learning_rate\"] == learning_rate) & (df[\"batch_size\"] == batch_size) & (df[\"num_epoch\"] == num_epoch) & (df[\"optimizer\"] == optimizer) & (df[\"layer1\"] == layer1) & (df[\"layer2\"] == layer2) & (df[\"layer3\"] == layer3) & (df[\"layer4\"] == layer4) & (df[\"layer5\"] == layer5) & (df[\"layer6\"] == layer6) & (df[\"layer7\"] == layer7) & (df[\"layer8\"] == layer8) & (df[\"layer9\"] == layer9) & (df[\"layer10\"] == layer10) & (df[\"layer11\"] == layer11) & (df[\"layer12\"] == layer12) & (df[\"layer13\"] == layer13) & (df[\"layer14\"] == layer14) & (df[\"layer15\"] == layer15) & (df[\"layer16\"] == layer16)]\n",
        "\n",
        "          if not matching_rows.empty:\n",
        "            #Take the solution index\n",
        "            idx = matching_rows.index[0]\n",
        "            #Update the evaluation metrics\n",
        "            df.at[idx, \"accuracy\"] = acc\n",
        "            df.at[idx, \"precision\"] = pre\n",
        "            df.at[idx, \"recall\"] = rec\n",
        "            df.at[idx, \"f1\"] = f1\n",
        "            df.at[idx, \"evaluation\"] = evaluation\n",
        "\n",
        "            #save the updated ActualPopulation file\n",
        "            df.to_csv(actual_population_path, index=False)\n",
        "\n",
        "          #Copy the solution configuration (.pth)\n",
        "          individual = position % 8 #solution position in population\n",
        "          generation = int(position/8) #num generation where the solution was created\n",
        "          search_path = path_parameters+\"solution_\"+str(individual)+\"_\"+str(generation)+\".pth\"\n",
        "          if os.path.exists(search_path):\n",
        "            model_path = path_parameters+\"solution_\"+str(i)+\"_10.pth\"\n",
        "            shutil.copy(search_path, model_path)\n",
        "\n",
        "          solutions_list.append([learning_rate,batch_size,num_epoch,optimizer,layer1,layer2,layer3,layer4,layer5,layer6,layer7,layer8,layer9,layer10,layer11,layer12,layer13,layer14,layer15,layer16,None,acc,pre,rec,f1,evaluation])\n",
        "        else:\n",
        "          #batch_size\n",
        "          size = 0\n",
        "          match batch_size:\n",
        "            case 1:\n",
        "              size = 32\n",
        "            case 2:\n",
        "              size = 64\n",
        "            case _:\n",
        "              size = 32\n",
        "\n",
        "          #num_epoch\n",
        "          epoch = 0\n",
        "          match num_epoch:\n",
        "            case 1:\n",
        "              epoch = 64\n",
        "            case 2:\n",
        "              epoch = 96\n",
        "            case 3:\n",
        "              epoch = 128\n",
        "            case _:\n",
        "              epoch = 64\n",
        "\n",
        "          #Train the model\n",
        "\n",
        "          #Take the model architecture\n",
        "          layers = [layer1, layer2, layer3, layer4, layer5, layer6, layer7, layer8, layer9, layer10, layer11, layer12, layer13, layer14, layer15, layer16]\n",
        "          #Take the input size of the first linear layer\n",
        "          _, layer_size = check_validity(layers)\n",
        "\n",
        "          print(\"Evaluating the solution: [\",learning_rate,\",\",batch_size,\",\",num_epoch,\",\",optimizer,\",\",layer1,\",\",layer2,\",\",layer3,\",\",layer4,\",\",layer5,\",\",layer6,\",\",layer7,\",\",layer8,\",\",layer9,\",\",layer10,\",\",layer11,\",\",layer12,\",\",layer13,\",\",layer14,\",\",layer15,\",\",layer16,\"]\")\n",
        "          best_model_configuration, acc, pre, rec, f1 = start_process(model_type=2, architecture=layers, linear_size=layer_size, bool_mlflow=False, learning_rate=learning_rate, batch_size=size, num_epoch=epoch, opt=optimizer)\n",
        "          solution_evaluation = (0.20*acc)+(0.35*pre)+(0.45*rec)\n",
        "          sum+=solution_evaluation\n",
        "\n",
        "          #Store its configuration\n",
        "          model_path = path_parameters+\"solution_\"+str(i)+\"_10.pth\"\n",
        "          torch.save(best_model_configuration, model_path)\n",
        "\n",
        "          solutions_list.append([learning_rate,batch_size,num_epoch,optimizer,layer1,layer2,layer3,layer4,layer5,layer6,layer7,layer8,layer9,layer10,layer11,layer12,layer13,layer14,layer15,layer16,None,acc,pre,rec,f1,solution_evaluation])\n",
        "\n",
        "          df = pd.read_csv(actual_population_path)\n",
        "          matching_rows = df.loc[(df[\"learning_rate\"] == learning_rate) & (df[\"batch_size\"] == batch_size) & (df[\"num_epoch\"] == num_epoch) & (df[\"optimizer\"] == optimizer) & (df[\"layer1\"] == layer1) & (df[\"layer2\"] == layer2) & (df[\"layer3\"] == layer3) & (df[\"layer4\"] == layer4) & (df[\"layer5\"] == layer5) & (df[\"layer6\"] == layer6) & (df[\"layer7\"] == layer7) & (df[\"layer8\"] == layer8) & (df[\"layer9\"] == layer9) & (df[\"layer10\"] == layer10) & (df[\"layer11\"] == layer11) & (df[\"layer12\"] == layer12) & (df[\"layer13\"] == layer13) & (df[\"layer14\"] == layer14) & (df[\"layer15\"] == layer15) & (df[\"layer16\"] == layer16)]\n",
        "          if not matching_rows.empty:\n",
        "            #Take the solution index\n",
        "            idx = matching_rows.index[0]\n",
        "            #Update the evaluation metrics\n",
        "            df.at[idx, \"accuracy\"] = acc\n",
        "            df.at[idx, \"precision\"] = pre\n",
        "            df.at[idx, \"recall\"] = rec\n",
        "            df.at[idx, \"f1\"] = f1\n",
        "            df.at[idx, \"evaluation\"] = solution_evaluation\n",
        "\n",
        "            #save the updated ActualPopulation file\n",
        "            df.to_csv(actual_population_path, index=False)\n",
        "          else:\n",
        "            print(\"Row not found! (boundary function, trained): [\",learning_rate,\",\",batch_size,\",\",num_epoch,\",\",optimizer,\",\",layer1,\",\",layer2,\",\",layer3,\",\",layer4,\",\",layer5,\",\",layer6,\",\",layer7,\",\",layer8,\",\",layer9,\",\",layer10,\",\",layer11,\",\",layer12,\",\",layer13,\",\",layer14,\",\",layer15,\",\",layer16,\"]\")\n",
        "\n",
        "      i+=1\n",
        "\n",
        "    #Define the fitness values\n",
        "    for solution in solutions_list:\n",
        "      fitness_value = solution[25]/(sum-solution[25])\n",
        "      solution[20] = fitness_value\n",
        "\n",
        "    #Update the max_fitness value with the fitness value of the last best individual\n",
        "    max_flag=False\n",
        "    for solution in solutions_list:\n",
        "      learning_rate = solution[0]\n",
        "      batch_size = solution[1]\n",
        "      num_epoch = solution[2]\n",
        "      optimizer = solution[3]\n",
        "      layer1 = solution[4]\n",
        "      layer2 = solution[5]\n",
        "      layer3 = solution[6]\n",
        "      layer4 = solution[7]\n",
        "      layer5 = solution[8]\n",
        "      layer6 = solution[9]\n",
        "      layer7 = solution[10]\n",
        "      layer8 = solution[11]\n",
        "      layer9 = solution[12]\n",
        "      layer10 = solution[13]\n",
        "      layer11 = solution[14]\n",
        "      layer12 = solution[16]\n",
        "      layer13 = solution[16]\n",
        "      layer14 = solution[17]\n",
        "      layer15 = solution[18]\n",
        "      layer16 = solution[19]\n",
        "\n",
        "      df = pd.read_csv(file_path2)\n",
        "      matching_rows = df.loc[(df[\"learning_rate\"] == learning_rate) & (df[\"batch_size\"] == batch_size) & (df[\"num_epoch\"] == num_epoch) & (df[\"optimizer\"] == optimizer) & (df[\"layer1\"] == layer1) & (df[\"layer2\"] == layer2) & (df[\"layer3\"] == layer3) & (df[\"layer4\"] == layer4) & (df[\"layer5\"] == layer5) & (df[\"layer6\"] == layer6) & (df[\"layer7\"] == layer7) & (df[\"layer8\"] == layer8) & (df[\"layer9\"] == layer9) & (df[\"layer10\"] == layer10) & (df[\"layer11\"] == layer11) & (df[\"layer12\"] == layer12) & (df[\"layer13\"] == layer13) & (df[\"layer14\"] == layer14) & (df[\"layer15\"] == layer15) & (df[\"layer16\"] == layer16)]\n",
        "\n",
        "      if not matching_rows.empty:\n",
        "        position = matching_rows.index[len(matching_rows)-1]\n",
        "        last_occurence = df.loc[position]\n",
        "        fitness = float(last_occurence[\"fitness_value\"])\n",
        "        if max_fitness == fitness:\n",
        "          max_flag=True\n",
        "          max_fitness = float(solution[20])\n",
        "          break\n",
        "\n",
        "    if not max_flag:\n",
        "      max_fitness=0 #Whether in the actual population we have not the best solution of the last population, we have not math in the previous for statement, therefore we have not a max_fitness in this generation\n",
        "\n",
        "    #Find the best solution\n",
        "    i=0\n",
        "    for solution in solutions_list:\n",
        "      fitness_value = solution[20]\n",
        "      if fitness_value > max_fitness:\n",
        "        max_fitness = fitness_value\n",
        "        mlflow.log_metric(\"GA_learning_rate\", solution[0], step=10)\n",
        "        mlflow.log_metric(\"GA_batch_size\", solution[1], step=10)\n",
        "        mlflow.log_metric(\"GA_num_epoch\", solution[2], step=10)\n",
        "        mlflow.log_metric(\"GA_optimizer\", solution[3], step=10)\n",
        "        mlflow.log_metric(\"layer1\", solution[4], step=10)\n",
        "        mlflow.log_metric(\"layer2\", solution[5], step=10)\n",
        "        mlflow.log_metric(\"layer3\", solution[6], step=10)\n",
        "        mlflow.log_metric(\"layer4\", solution[7], step=10)\n",
        "        mlflow.log_metric(\"layer5\", solution[8], step=10)\n",
        "        mlflow.log_metric(\"layer6\", solution[9], step=10)\n",
        "        mlflow.log_metric(\"layer7\", solution[10], step=10)\n",
        "        mlflow.log_metric(\"layer8\", solution[11], step=10)\n",
        "        mlflow.log_metric(\"layer9\", solution[12], step=10)\n",
        "        mlflow.log_metric(\"layer10\", solution[13], step=10)\n",
        "        mlflow.log_metric(\"layer11\", solution[14], step=10)\n",
        "        mlflow.log_metric(\"layer12\", solution[15], step=10)\n",
        "        mlflow.log_metric(\"layer13\", solution[16], step=10)\n",
        "        mlflow.log_metric(\"layer14\", solution[17], step=10)\n",
        "        mlflow.log_metric(\"layer15\", solution[18], step=10)\n",
        "        mlflow.log_metric(\"layer16\", solution[19], step=10)\n",
        "\n",
        "        mlflow.log_metric(\"GA_accuracy\", solution[21], step=10)\n",
        "        mlflow.log_metric(\"GA_precision\", solution[22], step=10)\n",
        "        mlflow.log_metric(\"GA_recall\", solution[23], step=10)\n",
        "        mlflow.log_metric(\"GA_f1\", solution[24], step=10)\n",
        "\n",
        "        #Take its configuration to copy it as the best solution\n",
        "        search_path = path_parameters+\"solution_\"+str(i)+\"_10.pth\"\n",
        "        if os.path.exists(search_path):\n",
        "          model_path = path_parameters+\"best_solution.pth\"\n",
        "          shutil.copy(search_path, model_path)\n",
        "\n",
        "      i+=1\n",
        "\n",
        "    with open(actual_population_path, \"w\", newline=\"\") as csvfile:\n",
        "      writer = csv.writer(csvfile)\n",
        "      writer.writerow([\"learning_rate\",\"batch_size\",\"num_epoch\",\"optimizer\",\"layer1\",\"layer2\",\"layer3\",\"layer4\",\"layer5\",\"layer6\",\"layer7\",\"layer8\",\"layer9\",\"layer10\",\"layer11\",\"layer12\",\"layer13\",\"layer14\",\"layer15\",\"layer16\",\"fitness_value\",\"accuracy\",\"precision\",\"recall\",\"f1\",\"evaluation\"])\n",
        "      writer.writerows(solutions_list)\n",
        "\n",
        "    df = pd.read_csv(actual_population_path)\n",
        "    max_value_index = df['fitness_value'].idxmax()\n",
        "\n",
        "    best_solution = df.loc[max_value_index]\n",
        "    best_solution = best_solution.to_list()\n",
        "    with open(best_path,\"w\", newline=\"\") as csvfile:\n",
        "      writer = csv.writer(csvfile)\n",
        "      writer.writerow([\"learning_rate\",\"batch_size\",\"num_epoch\",\"optimizer\",\"layer1\",\"layer2\",\"layer3\",\"layer4\",\"layer5\",\"layer6\",\"layer7\",\"layer8\",\"layer9\",\"layer10\",\"layer11\",\"layer12\",\"layer13\",\"layer14\",\"layer15\",\"layer16\",\"fitness_value\",\"accuracy\",\"precision\",\"recall\",\"f1\",\"evaluation\"])\n",
        "      writer.writerow(best_solution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR20NlRuo8dY"
      },
      "source": [
        "# Genetich Algorithm\n",
        "*   **Stop criteria**: We will stop the genetic algorithm after 10 generations or if there isn't a fitness function improvement after 8 consecutive steps.\n",
        "*   **Selection algorithm**: K-way Tournament Selection\n",
        "*   **Crossover algorithm**: Two-Point Crossover\n",
        "*   **Mutation algorithm**: Random Resetting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X565eTz-1N9w"
      },
      "outputs": [],
      "source": [
        "#Define dataset\n",
        "best_path = checkpoint_path = \"\"\n",
        "if script_owner:\n",
        "  initialize_dataset(\"/content/drive/MyDrive/SE4AI/Model/\")\n",
        "  checkpoint_path = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGASecondApproach/Checkpoint.csv\"\n",
        "  best_path = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGASecondApproach/BestSolutionGA2.csv\"\n",
        "else:\n",
        "  initialize_dataset(\"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/\")\n",
        "  checkpoint_path = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGASecondApproach/Checkpoint.csv\"\n",
        "  best_path = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGASecondApproach/BestSolutionGA2.csv\"\n",
        "\n",
        "\n",
        "max_num_generation = 10\n",
        "fitness = fitness_function_calculator\n",
        "M = 4 #number of parents to selection step\n",
        "population_size = 8\n",
        "chromosomes_size = 20 #learning rate, batch size, num epoch, optimizer, 10 layers\n",
        "# batch size: 1=32, 2=64\n",
        "# num epoch: 1=64, 2=96, 3=128\n",
        "# optimizer: 1=Adam, 2=Adadelta, 3=Nadam\n",
        "# 1=Conv2d and out_channels = 128,\n",
        "# 2=Conv2d and out_channels = 64,\n",
        "# 3=Conv2d and out_channels = 32,\n",
        "# 4=Conv2d and out_channels = 16,\n",
        "# 5=Conv2d and out_channels = 8,\n",
        "# 6=MaxPool2d and kernel = 3,\n",
        "# 7=MaxPool2d and kernel = 2,\n",
        "# 8=AvgPool2d and kernel = 3,\n",
        "# 9=AvgPool2d and kernel = 2,\n",
        "# 10=Dropout2d,\n",
        "# 11=BatchNormalization,\n",
        "# 12=ReLu,\n",
        "# 13=LeakyReLu\n",
        "\n",
        "genes_range = [{'low': 0.001, 'high': 0.01001},\n",
        "               {'low': 1, 'high': 3},\n",
        "               {'low': 1, 'high': 4},\n",
        "               {'low': 1, 'high': 4},\n",
        "               {'low': 1, 'high': 14},\n",
        "               {'low': 1, 'high': 14},\n",
        "               {'low': 1, 'high': 14},\n",
        "               {'low': 1, 'high': 14},\n",
        "               {'low': 1, 'high': 14},\n",
        "               {'low': 1, 'high': 14},\n",
        "               {'low': 1, 'high': 14},\n",
        "               {'low': 1, 'high': 14},\n",
        "               {'low': 1, 'high': 14},\n",
        "               {'low': 1, 'high': 14},\n",
        "               {'low': 1, 'high': 14},\n",
        "               {'low': 1, 'high': 14},\n",
        "               {'low': 1, 'high': 14},\n",
        "               {'low': 1, 'high': 14},\n",
        "               {'low': 1, 'high': 14},\n",
        "               {'low': 1, 'high': 14}\n",
        "               ]\n",
        "\n",
        "ga_instance = None\n",
        "mlflow_id = 0\n",
        "ga_flag=True\n",
        "\n",
        "if os.path.exists(checkpoint_path):\n",
        "  print(\"Started the GA from the last saved population\")\n",
        "  #This means that Google Colab stopped the Genetic Algorithm, therefore we restart the GA with an initial population equal to the last saved population\n",
        "  evolution_step = 0\n",
        "  with open(checkpoint_path, \"r\", newline=\"\") as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    next(reader) #To jump the file header\n",
        "    for row in reader:\n",
        "      evolution_step = int(row[0])\n",
        "      mlflow_id = int(row[1])\n",
        "\n",
        "  all_path = population_path = \"\"\n",
        "  if script_owner:\n",
        "    population_path = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGASecondApproach/ActualPopulation.csv\"\n",
        "    all_path = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGASecondApproach/AllSolutions.csv\"\n",
        "  else:\n",
        "    population_path = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGASecondApproach/ActualPopulation.csv\"\n",
        "    all_path = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGASecondApproach/AllSolutions.csv\"\n",
        "\n",
        "  #Refresh the max fitness value\n",
        "  df = pd.read_csv(all_path)\n",
        "  last_n_rows = df.tail(8)\n",
        "  df = last_n_rows\n",
        "  max_value = df[\"fitness_value\"].max()\n",
        "  global max_fitness\n",
        "  max_fitness = float(max_value)\n",
        "\n",
        "  max_num_generation = max_num_generation - evolution_step\n",
        "\n",
        "  #Load the last stored solutions\n",
        "  initial_population = []\n",
        "  check_flag = True\n",
        "  with open(population_path, \"r\", newline=\"\") as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    next(reader) #To jump the file header\n",
        "    for row in reader:\n",
        "      learning_rate = float(row[0])\n",
        "      batch_size = int(float(row[1]))\n",
        "      num_epoch = int(float(row[2]))\n",
        "      optimizer = int(float(row[3]))\n",
        "      layer1 = int(float(row[4]))\n",
        "      layer2 = int(float(row[5]))\n",
        "      layer3 = int(float(row[6]))\n",
        "      layer4 = int(float(row[7]))\n",
        "      layer5 = int(float(row[8]))\n",
        "      layer6 = int(float(row[9]))\n",
        "      layer7 = int(float(row[10]))\n",
        "      layer8 = int(float(row[11]))\n",
        "      layer9 = int(float(row[12]))\n",
        "      layer10 = int(float(row[13]))\n",
        "      layer11 = int(float(row[14]))\n",
        "      layer12 = int(float(row[15]))\n",
        "      layer13 = int(float(row[16]))\n",
        "      layer14 = int(float(row[17]))\n",
        "      layer15 = int(float(row[18]))\n",
        "      layer16 = int(float(row[19]))\n",
        "\n",
        "      eval = row[25]\n",
        "      if eval != \"\":\n",
        "        check_flag = False #If at least one individual was trained, the population doesn't contain clones and all solutions are valid\n",
        "\n",
        "      initial_population.append([learning_rate, batch_size, num_epoch, optimizer, layer1, layer2, layer3, layer4, layer5, layer6, layer7, layer8, layer9, layer10, layer11, layer12, layer13, layer14, layer15, layer16])\n",
        "\n",
        "  if check_flag: #Whether there were not any trained individuals, we must check if the population is valid or contains clones.\n",
        "    i = 0\n",
        "    copy_flag=False\n",
        "    #Check if the actual population is valid or contains clones\n",
        "    population_copy = initial_population.copy()\n",
        "    for solution in initial_population:\n",
        "      solution_app = solution.copy()\n",
        "      layers = solution_app[4:]\n",
        "      flag, layer_size = check_validity(layers) #check if the solution is valid\n",
        "      if not flag:\n",
        "        copy_flag = True\n",
        "        solution_app, layer_size = replace_solution(solution_app)\n",
        "        population_copy[i] = solution_app\n",
        "\n",
        "      if check_clone_presence(population_copy, solution_app): #check if the solution appears more than one time in the actual population\n",
        "        copy_flag = True\n",
        "        new_solution = replace_clone(population_copy)\n",
        "        population_copy[i] = new_solution\n",
        "\n",
        "      i+=1\n",
        "\n",
        "    #If we replaced some solution, we must replace the entire population\n",
        "    if copy_flag:\n",
        "      initial_population = population_copy.copy()\n",
        "      i = 0\n",
        "      for solution in initial_population:\n",
        "        temp_solution = solution.copy()\n",
        "        temp_solution.extend([None,None,None,None,None,None])\n",
        "        population_copy[i]=temp_solution\n",
        "        i+=1\n",
        "\n",
        "      df = pd.DataFrame(population_copy, columns=[\"learning_rate\",\"batch_size\",\"num_epoch\",\"optimizer\",\"layer1\",\"layer2\",\"layer3\",\"layer4\",\"layer5\",\"layer6\",\"layer7\",\"layer8\",\"layer9\",\"layer10\",\"layer11\",\"layer12\",\"layer13\",\"layer14\",\"layer15\",\"layer16\",\"fitness_value\",\"accuracy\",\"precision\",\"recall\",\"f1\",\"evaluation\"])\n",
        "      df.to_csv(population_path, index=False)\n",
        "      del population_copy\n",
        "\n",
        "  if max_num_generation == 0:\n",
        "    #Google stops the GA at the last generation, therefore we must train only the no trained solutions\n",
        "    ga_flag=False\n",
        "    train_solutions_last_generation(population_path, best_path, mlflow_id)\n",
        "  else:\n",
        "    global num_step\n",
        "    num_step = evolution_step\n",
        "\n",
        "    initial_population = np.array(initial_population)\n",
        "    ga_instance = pygad.GA(num_generations = max_num_generation,\n",
        "                        num_parents_mating = M,\n",
        "                        fitness_func = fitness,\n",
        "                        initial_population = initial_population,\n",
        "                        num_genes = chromosomes_size,\n",
        "                        gene_type =[[float, 5], int, int, int, int, int, int, int, int, int, int, int, int, int, int, int, int, int, int, int],\n",
        "                        gene_space = genes_range,\n",
        "                        parent_selection_type = my_tournament_selection,\n",
        "                        crossover_type = \"two_points\", #Two-Point Crossover\n",
        "                        mutation_type = \"random\", #Random Resetting -> set a random value within the range\n",
        "                        mutation_by_replacement = True, #replace the gene by the new randomly generated value\n",
        "                        mutation_probability = 0.2, #The probability that a gene must exceed in order to be modified (if probability is less then or equal to this value, the gene will be mutated)\n",
        "                        stop_criteria= \"saturate_8\", #Stop criteria: stop the GA if there isn't an improvement after 16 consecutive steps\n",
        "                        on_start = fun_on_start,\n",
        "                        save_solutions=True\n",
        "                        )\n",
        "else:\n",
        "  ga_instance = pygad.GA(num_generations = max_num_generation,\n",
        "                       num_parents_mating = M,\n",
        "                       fitness_func = fitness,\n",
        "                       sol_per_pop = population_size,\n",
        "                       num_genes = chromosomes_size,\n",
        "                       gene_type =[[float, 5], int, int, int, int, int, int, int, int, int, int, int, int, int, int, int, int, int, int, int],\n",
        "                       gene_space = genes_range,\n",
        "                       parent_selection_type = my_tournament_selection,\n",
        "                       crossover_type = \"two_points\", #Two-Point Crossover\n",
        "                       mutation_type = \"random\", #Random Resetting -> set a random value within the range\n",
        "                       mutation_by_replacement = True, #replace the gene by the new randomly generated value\n",
        "                       mutation_probability = 0.2, #The probability that a gene must exceed in order to be modified\n",
        "                       stop_criteria= \"saturate_8\", #Stop criteria: stop the GA if there isn't an improvement after 16 consecutive steps\n",
        "                       on_start = fun_on_start,\n",
        "                       save_solutions=True\n",
        "                       )\n",
        "\n",
        "if ga_flag:\n",
        "  print(\"***************************************************************\")\n",
        "  print(\"Started Genetich Algorithm!\")\n",
        "  if not os.path.exists(checkpoint_path):\n",
        "    experiment_name = str(input(\"Insert the experiment name for GA SECOND approach:\"))\n",
        "    mlflow_id = get_experiment_id(experiment_name)\n",
        "\n",
        "  #Start to track the model with MlFlow\n",
        "  with mlflow.start_run(experiment_id=mlflow_id):\n",
        "    ga_instance.run()\n",
        "    print(\"GA finished!\")\n",
        "    print(\"***************************************************************\")\n",
        "\n",
        "\n",
        "  #Save the best solution\n",
        "  solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
        "  print(\"Parameters of the best solution: \", solution)\n",
        "  print(\"Fitness value of the best solution = \", solution_fitness)\n",
        "\n",
        "  to_write = []\n",
        "  to_write.extend(solution)\n",
        "  to_write.append(solution_fitness)\n",
        "  with open(best_path, \"w\", newline=\"\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"learning_rate\",\"batch_size\",\"num_epoch\",\"optimizer\",\"layer1\",\"layer2\",\"layer3\",\"layer4\",\"layer5\",\"layer6\",\"layer7\",\"layer8\",\"layer9\",\"layer10\",\"layer11\",\"layer12\",\"layer13\",\"layer14\",\"layer15\",\"layer16\",\"fitness_value\",\"accuracy\",\"precision\",\"recall\",\"f1\",\"evaluation\"])\n",
        "    writer.writerow(to_write)\n",
        "\n",
        "  #Plot the fitness values, genes, and the explored solutions\n",
        "  if script_owner:\n",
        "    ga_instance.plot_fitness(save_dir='/content/drive/MyDrive/SE4AI/Model/EvaluationGASecondApproach/PlotFitnessGA2Approach.png')\n",
        "    ga_instance.plot_genes(save_dir='/content/drive/MyDrive/SE4AI/Model/EvaluationGASecondApproach/PlotGenesGA2Approach.png')\n",
        "    ga_instance.plot_new_solution_rate(save_dir='/content/drive/MyDrive/SE4AI/Model/EvaluationGASecondApproach/PlotExploredSolutionsGA2Approach.png')\n",
        "  else:\n",
        "    ga_instance.plot_fitness(save_dir='/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGASecondApproach/PlotFitnessGA2Approach.png')\n",
        "    ga_instance.plot_genes(save_dir='/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGASecondApproach/PlotGenesGA2Approach.png')\n",
        "    ga_instance.plot_new_solution_rate(save_dir='/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGASecondApproach/PlotExploredSolutionsGA2Approach.png')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}