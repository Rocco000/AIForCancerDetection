{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rocco000/OncoVision/blob/main/Scripts/ModelArchitecture2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ot7OiZPjx6Jq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.nn.modules.pooling import MaxPool2d\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive') #Connect to Google Drive\n",
        "\n",
        "def choose_layer(layer_type, channels=8):\n",
        "  match layer_type:\n",
        "    case 1:\n",
        "      return nn.Conv2d(in_channels=channels, out_channels=128, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "    case 2:\n",
        "      return nn.Conv2d(in_channels=channels, out_channels=64, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "    case 3:\n",
        "      return nn.Conv2d(in_channels=channels, out_channels=32, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "    case 4:\n",
        "      return nn.Conv2d(in_channels=channels, out_channels=16, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "    case 5:\n",
        "      return nn.Conv2d(in_channels=channels, out_channels=8, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "    case 6:\n",
        "      return nn.MaxPool2d(kernel_size=3, stride=3)\n",
        "    case 7:\n",
        "      return nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    case 8:\n",
        "      return nn.AvgPool2d(kernel_size=3, stride=3)\n",
        "    case 9:\n",
        "      return nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "    case 10:\n",
        "      return nn.Dropout2d(p=0.2)\n",
        "    case 11:\n",
        "      return nn.BatchNorm2d(channels)\n",
        "    case 12:\n",
        "      return nn.ReLU()\n",
        "    case 13:\n",
        "      return nn.LeakyReLU()\n",
        "    case _:\n",
        "      print(\"Value error\")\n",
        "      return None\n",
        "\n",
        "def size_nn_linear_calculator(layer_type, width, height, channels):\n",
        "  \"\"\"\n",
        "    1: cnn-128;\n",
        "    2: cnn-64;\n",
        "    3: cnn-32;\n",
        "    4: cnn-16;\n",
        "    5: cnn-8;\n",
        "    6: max-3;\n",
        "    7: max-2;\n",
        "    8: avg-3;\n",
        "    9: avg-2;\n",
        "    10: dropout;\n",
        "    11: batch-norm;\n",
        "    12: ReLu;\n",
        "    13: LeakyReLu\n",
        "  \"\"\"\n",
        "  new_width=new_height=size = 0\n",
        "  match layer_type:\n",
        "    case 1:\n",
        "      #cnn-128\n",
        "      new_width = ((width - 3 + 2)/1)+1 # [(W-F+2P)/S]+1\n",
        "      new_height = ((height - 3 + 2)/1)+1 # [(H-F+2P)/S]+1\n",
        "      size = new_width * new_height * 128\n",
        "    case 2:\n",
        "      #cnn-64\n",
        "      new_width = ((width - 3 + 2)/1)+1 # [(W-F+2P)/S]+1\n",
        "      new_height = ((height - 3 + 2)/1)+1 # [(H-F+2P)/S]+1\n",
        "      size = new_width * new_height * 64\n",
        "    case 3:\n",
        "      #cnn-32\n",
        "      new_width = ((width - 3 + 2)/1)+1 # [(W-F+2P)/S]+1\n",
        "      new_height = ((height - 3 + 2)/1)+1 # [(H-F+2P)/S]+1\n",
        "      size = new_width * new_height * 32\n",
        "    case 4:\n",
        "      #cnn-16\n",
        "      new_width = ((width - 3 + 2)/1)+1 # [(W-F+2P)/S]+1\n",
        "      new_height = ((height - 3 + 2)/1)+1 # [(H-F+2P)/S]+1\n",
        "      size = new_width * new_height * 16\n",
        "    case 5:\n",
        "      #cnn-8\n",
        "      new_width = ((width - 3 + 2)/1)+1 # [(W-F+2P)/S]+1\n",
        "      new_height = ((height - 3 + 2)/1)+1 # [(H-F+2P)/S]+1\n",
        "      size = new_width * new_height * 8\n",
        "    case 6:\n",
        "      #max-3\n",
        "      frac_value = int((width-3)/3)\n",
        "      new_width = frac_value+1 # Wout = [(Win - F)/S]+1\n",
        "      frac_value = int((height-3)/3)\n",
        "      new_height = frac_value+1 # Hout = [(Hin - F)/S]+1\n",
        "      size = new_width * new_height * channels\n",
        "    case 7:\n",
        "      #max-2\n",
        "      frac_value = int((width-2)/2)\n",
        "      new_width = frac_value+1\n",
        "      frac_value = int((height-2)/2)\n",
        "      new_height = frac_value+1\n",
        "      size = new_width * new_height * channels\n",
        "    case 8:\n",
        "      #avg-3\n",
        "      frac_value = int((width-3)/3)\n",
        "      new_width = frac_value+1\n",
        "      frac_value = int((height-3)/3)\n",
        "      new_height = frac_value+1\n",
        "      size = new_width * new_height * channels\n",
        "    case 9:\n",
        "      #avg-2\n",
        "      frac_value = int((width-2)/2)\n",
        "      new_width = frac_value+1\n",
        "      frac_value = int((height-2)/2)\n",
        "      new_height = frac_value+1\n",
        "      size = new_width * new_height * channels\n",
        "    case _:\n",
        "      print(\"Value error!\")\n",
        "\n",
        "  return new_width, new_height, size\n",
        "\n",
        "\n",
        "\n",
        "class ConvModel2(nn.Module):\n",
        "  def __init__(self, architecture, size):\n",
        "    super(ConvModel2, self).__init__()\n",
        "    self.layer0 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "    self.layer1 = None\n",
        "    self.layer2 = None\n",
        "    self.layer3 = None\n",
        "    self.layer4 = None\n",
        "    self.layer5 = None\n",
        "    self.layer6 = None\n",
        "    self.layer7 = None\n",
        "    self.layer8 = None\n",
        "    self.layer9 = None\n",
        "    self.layer10 = None\n",
        "    self.layer11 = None\n",
        "    self.layer12 = None\n",
        "    self.layer13 = None\n",
        "    self.layer14 = None\n",
        "    self.layer15 = None\n",
        "    self.layer16 = None\n",
        "    self.flatter = nn.Flatten()\n",
        "\n",
        "    #Build the netwrok\n",
        "    for i in range(len(architecture)):\n",
        "      match i:\n",
        "        case 0:\n",
        "          self.layer1 = choose_layer(architecture[i])\n",
        "        case 1:\n",
        "          #layer2\n",
        "          if (architecture[i]>=1 and architecture[i]<=5) or architecture[i]==11: #if it is a convolutional layer or a batchnorm layer, we must set its in_channels value to the out_channels of the last convolutional layer\n",
        "            if isinstance(self.layer1, nn.Conv2d):\n",
        "              self.layer2 = choose_layer(architecture[i], self.layer1.out_channels)\n",
        "            else:\n",
        "              self.layer2 = choose_layer(architecture[i])\n",
        "          else:\n",
        "            self.layer2 = choose_layer(architecture[i])\n",
        "\n",
        "        case 2:\n",
        "          #layer3\n",
        "          if (architecture[i]>=1 and architecture[i]<=5) or architecture[i]==11: #if it is a convolutional layer or a batchnorm layer, we must set its in_channels value to the out_channels of the last convolutional layer\n",
        "            if isinstance(self.layer2, nn.Conv2d):\n",
        "              self.layer3 = choose_layer(architecture[i], self.layer2.out_channels)\n",
        "            elif isinstance(self.layer1, nn.Conv2d):\n",
        "              self.layer3 = choose_layer(architecture[i], self.layer1.out_channels)\n",
        "            else:\n",
        "              self.layer3 = choose_layer(architecture[i])\n",
        "          else:\n",
        "            self.layer3 = choose_layer(architecture[i])\n",
        "\n",
        "        case 3:\n",
        "          #layer4\n",
        "          if (architecture[i]>=1 and architecture[i]<=5) or architecture[i]==11: #if it is a convolutional layer or a batchnorm layer, we must set its in_channels value to the out_channels of the last convolutional layer\n",
        "            if isinstance(self.layer3, nn.Conv2d):\n",
        "              self.layer4 = choose_layer(architecture[i], self.layer3.out_channels)\n",
        "            elif isinstance(self.layer2, nn.Conv2d):\n",
        "              self.layer4 = choose_layer(architecture[i], self.layer2.out_channels)\n",
        "            elif isinstance(self.layer1, nn.Conv2d):\n",
        "              self.layer4 = choose_layer(architecture[i], self.layer1.out_channels)\n",
        "            else:\n",
        "              self.layer4 = choose_layer(architecture[i])\n",
        "          else:\n",
        "            self.layer4 = choose_layer(architecture[i])\n",
        "        case 4:\n",
        "          #layer5\n",
        "          if (architecture[i]>=1 and architecture[i]<=5) or architecture[i]==11: #if it is a convolutional layer or a batchnorm layer, we must set its in_channels value to the out_channels of the last convolutional layer\n",
        "            if isinstance(self.layer4, nn.Conv2d):\n",
        "              self.layer5 = choose_layer(architecture[i], self.layer4.out_channels)\n",
        "            elif isinstance(self.layer3, nn.Conv2d):\n",
        "              self.layer5 = choose_layer(architecture[i], self.layer3.out_channels)\n",
        "            elif isinstance(self.layer2, nn.Conv2d):\n",
        "              self.layer5 = choose_layer(architecture[i], self.layer2.out_channels)\n",
        "            elif isinstance(self.layer1, nn.Conv2d):\n",
        "              self.layer5 = choose_layer(architecture[i], self.layer1.out_channels)\n",
        "            else:\n",
        "              self.layer5 = choose_layer(architecture[i])\n",
        "          else:\n",
        "            self.layer5 = choose_layer(architecture[i])\n",
        "        case 5:\n",
        "          #layer6\n",
        "          if (architecture[i]>=1 and architecture[i]<=5) or architecture[i]==11: #if it is a convolutional layer or a batchnorm layer, we must set its in_channels value to the out_channels of the last convolutional layer\n",
        "            if isinstance(self.layer5, nn.Conv2d):\n",
        "              self.layer6 = choose_layer(architecture[i], self.layer5.out_channels)\n",
        "            elif isinstance(self.layer4, nn.Conv2d):\n",
        "              self.layer6 = choose_layer(architecture[i], self.layer4.out_channels)\n",
        "            elif isinstance(self.layer3, nn.Conv2d):\n",
        "              self.layer6 = choose_layer(architecture[i], self.layer3.out_channels)\n",
        "            elif isinstance(self.layer2, nn.Conv2d):\n",
        "              self.layer6 = choose_layer(architecture[i], self.layer2.out_channels)\n",
        "            elif isinstance(self.layer1, nn.Conv2d):\n",
        "              self.layer6 = choose_layer(architecture[i], self.layer1.out_channels)\n",
        "            else:\n",
        "              self.layer6 = choose_layer(architecture[i])\n",
        "          else:\n",
        "            self.layer6 = choose_layer(architecture[i])\n",
        "        case 6:\n",
        "          #layer7\n",
        "          if (architecture[i]>=1 and architecture[i]<=5) or architecture[i]==11: #if it is a convolutional layer or a batchnorm layer, we must set its in_channels value to the out_channels of the last convolutional layer\n",
        "            if isinstance(self.layer6, nn.Conv2d):\n",
        "              self.layer7 = choose_layer(architecture[i], self.layer6.out_channels)\n",
        "            elif isinstance(self.layer5, nn.Conv2d):\n",
        "              self.layer7 = choose_layer(architecture[i], self.layer5.out_channels)\n",
        "            elif isinstance(self.layer4, nn.Conv2d):\n",
        "              self.layer7 = choose_layer(architecture[i], self.layer4.out_channels)\n",
        "            elif isinstance(self.layer3, nn.Conv2d):\n",
        "              self.layer7 = choose_layer(architecture[i], self.layer3.out_channels)\n",
        "            elif isinstance(self.layer2, nn.Conv2d):\n",
        "              self.layer7 = choose_layer(architecture[i], self.layer2.out_channels)\n",
        "            elif isinstance(self.layer1, nn.Conv2d):\n",
        "              self.layer7 = choose_layer(architecture[i], self.layer1.out_channels)\n",
        "            else:\n",
        "              self.layer7 = choose_layer(architecture[i])\n",
        "          else:\n",
        "            self.layer7 = choose_layer(architecture[i])\n",
        "        case 7:\n",
        "          #layer8\n",
        "          if (architecture[i]>=1 and architecture[i]<=5) or architecture[i]==11: #if it is a convolutional layer or a batchnorm layer, we must set its in_channels value to the out_channels of the last convolutional layer\n",
        "            if isinstance(self.layer7, nn.Conv2d):\n",
        "              self.layer8 = choose_layer(architecture[i], self.layer7.out_channels)\n",
        "            elif isinstance(self.layer6, nn.Conv2d):\n",
        "              self.layer8 = choose_layer(architecture[i], self.layer6.out_channels)\n",
        "            elif isinstance(self.layer5, nn.Conv2d):\n",
        "              self.layer8 = choose_layer(architecture[i], self.layer5.out_channels)\n",
        "            elif isinstance(self.layer4, nn.Conv2d):\n",
        "              self.layer8 = choose_layer(architecture[i], self.layer4.out_channels)\n",
        "            elif isinstance(self.layer3, nn.Conv2d):\n",
        "              self.layer8 = choose_layer(architecture[i], self.layer3.out_channels)\n",
        "            elif isinstance(self.layer2, nn.Conv2d):\n",
        "              self.layer8 = choose_layer(architecture[i], self.layer2.out_channels)\n",
        "            elif isinstance(self.layer1, nn.Conv2d):\n",
        "              self.layer8 = choose_layer(architecture[i], self.layer1.out_channels)\n",
        "            else:\n",
        "              self.layer8 = choose_layer(architecture[i])\n",
        "          else:\n",
        "            self.layer8 = choose_layer(architecture[i])\n",
        "        case 8:\n",
        "          #layer9\n",
        "          if (architecture[i]>=1 and architecture[i]<=5) or architecture[i]==11: #if it is a convolutional layer or a batchnorm layer, we must set its in_channels value to the out_channels of the last convolutional layer\n",
        "            if isinstance(self.layer8, nn.Conv2d):\n",
        "              self.layer9 = choose_layer(architecture[i], self.layer8.out_channels)\n",
        "            elif isinstance(self.layer7, nn.Conv2d):\n",
        "              self.layer9 = choose_layer(architecture[i], self.layer7.out_channels)\n",
        "            elif isinstance(self.layer6, nn.Conv2d):\n",
        "              self.layer9 = choose_layer(architecture[i], self.layer6.out_channels)\n",
        "            elif isinstance(self.layer5, nn.Conv2d):\n",
        "              self.layer9 = choose_layer(architecture[i], self.layer5.out_channels)\n",
        "            elif isinstance(self.layer4, nn.Conv2d):\n",
        "              self.layer9 = choose_layer(architecture[i], self.layer4.out_channels)\n",
        "            elif isinstance(self.layer3, nn.Conv2d):\n",
        "              self.layer9 = choose_layer(architecture[i], self.layer3.out_channels)\n",
        "            elif isinstance(self.layer2, nn.Conv2d):\n",
        "              self.layer9 = choose_layer(architecture[i], self.layer2.out_channels)\n",
        "            elif isinstance(self.layer1, nn.Conv2d):\n",
        "              self.layer9 = choose_layer(architecture[i], self.layer1.out_channels)\n",
        "            else:\n",
        "              self.layer9 = choose_layer(architecture[i])\n",
        "          else:\n",
        "            self.layer9 = choose_layer(architecture[i])\n",
        "        case 9:\n",
        "          #layer10\n",
        "          if (architecture[i]>=1 and architecture[i]<=5) or architecture[i]==11: #if it is a convolutional layer or a batchnorm layer, we must set its in_channels value to the out_channels of the last convolutional layer\n",
        "            if isinstance(self.layer9, nn.Conv2d):\n",
        "              self.layer10 = choose_layer(architecture[i], self.layer9.out_channels)\n",
        "            elif isinstance(self.layer8, nn.Conv2d):\n",
        "              self.layer10 = choose_layer(architecture[i], self.layer8.out_channels)\n",
        "            elif isinstance(self.layer7, nn.Conv2d):\n",
        "              self.layer10 = choose_layer(architecture[i], self.layer7.out_channels)\n",
        "            elif isinstance(self.layer6, nn.Conv2d):\n",
        "              self.layer10 = choose_layer(architecture[i], self.layer6.out_channels)\n",
        "            elif isinstance(self.layer5, nn.Conv2d):\n",
        "              self.layer10 = choose_layer(architecture[i], self.layer5.out_channels)\n",
        "            elif isinstance(self.layer4, nn.Conv2d):\n",
        "              self.layer10 = choose_layer(architecture[i], self.layer4.out_channels)\n",
        "            elif isinstance(self.layer3, nn.Conv2d):\n",
        "              self.layer10 = choose_layer(architecture[i], self.layer3.out_channels)\n",
        "            elif isinstance(self.layer2, nn.Conv2d):\n",
        "              self.layer10 = choose_layer(architecture[i], self.layer2.out_channels)\n",
        "            elif isinstance(self.layer1, nn.Conv2d):\n",
        "              self.layer10 = choose_layer(architecture[i], self.layer1.out_channels)\n",
        "            else:\n",
        "              self.layer10 = choose_layer(architecture[i])\n",
        "          else:\n",
        "            self.layer10 = choose_layer(architecture[i])\n",
        "        case 10:\n",
        "          #layer11\n",
        "          if (architecture[i]>=1 and architecture[i]<=5) or architecture[i]==11: #if it is a convolutional layer or a batchnorm layer, we must set its in_channels value to the out_channels of the last convolutional layer\n",
        "            if isinstance(self.layer10, nn.Conv2d):\n",
        "              self.layer11 = choose_layer(architecture[i], self.layer10.out_channels)\n",
        "            elif isinstance(self.layer9, nn.Conv2d):\n",
        "              self.layer11 = choose_layer(architecture[i], self.layer9.out_channels)\n",
        "            elif isinstance(self.layer8, nn.Conv2d):\n",
        "              self.layer11 = choose_layer(architecture[i], self.layer8.out_channels)\n",
        "            elif isinstance(self.layer7, nn.Conv2d):\n",
        "              self.layer11 = choose_layer(architecture[i], self.layer7.out_channels)\n",
        "            elif isinstance(self.layer6, nn.Conv2d):\n",
        "              self.layer11 = choose_layer(architecture[i], self.layer6.out_channels)\n",
        "            elif isinstance(self.layer5, nn.Conv2d):\n",
        "              self.layer11 = choose_layer(architecture[i], self.layer5.out_channels)\n",
        "            elif isinstance(self.layer4, nn.Conv2d):\n",
        "              self.layer11 = choose_layer(architecture[i], self.layer4.out_channels)\n",
        "            elif isinstance(self.layer3, nn.Conv2d):\n",
        "              self.layer11 = choose_layer(architecture[i], self.layer3.out_channels)\n",
        "            elif isinstance(self.layer2, nn.Conv2d):\n",
        "              self.layer11 = choose_layer(architecture[i], self.layer2.out_channels)\n",
        "            elif isinstance(self.layer1, nn.Conv2d):\n",
        "              self.layer11 = choose_layer(architecture[i], self.layer1.out_channels)\n",
        "            else:\n",
        "              self.layer11 = choose_layer(architecture[i])\n",
        "          else:\n",
        "            self.layer11 = choose_layer(architecture[i])\n",
        "        case 11:\n",
        "          #layer12\n",
        "          if (architecture[i]>=1 and architecture[i]<=5) or architecture[i]==11: #if it is a convolutional layer or a batchnorm layer, we must set its in_channels value to the out_channels of the last convolutional layer\n",
        "            if isinstance(self.layer11, nn.Conv2d):\n",
        "              self.layer12 = choose_layer(architecture[i], self.layer11.out_channels)\n",
        "            elif isinstance(self.layer10, nn.Conv2d):\n",
        "              self.layer12 = choose_layer(architecture[i], self.layer10.out_channels)\n",
        "            elif isinstance(self.layer9, nn.Conv2d):\n",
        "              self.layer12 = choose_layer(architecture[i], self.layer9.out_channels)\n",
        "            elif isinstance(self.layer8, nn.Conv2d):\n",
        "              self.layer12 = choose_layer(architecture[i], self.layer8.out_channels)\n",
        "            elif isinstance(self.layer7, nn.Conv2d):\n",
        "              self.layer12 = choose_layer(architecture[i], self.layer7.out_channels)\n",
        "            elif isinstance(self.layer6, nn.Conv2d):\n",
        "              self.layer12 = choose_layer(architecture[i], self.layer6.out_channels)\n",
        "            elif isinstance(self.layer5, nn.Conv2d):\n",
        "              self.layer12 = choose_layer(architecture[i], self.layer5.out_channels)\n",
        "            elif isinstance(self.layer4, nn.Conv2d):\n",
        "              self.layer12 = choose_layer(architecture[i], self.layer4.out_channels)\n",
        "            elif isinstance(self.layer3, nn.Conv2d):\n",
        "              self.layer12 = choose_layer(architecture[i], self.layer3.out_channels)\n",
        "            elif isinstance(self.layer2, nn.Conv2d):\n",
        "              self.layer12 = choose_layer(architecture[i], self.layer2.out_channels)\n",
        "            elif isinstance(self.layer1, nn.Conv2d):\n",
        "              self.layer12 = choose_layer(architecture[i], self.layer1.out_channels)\n",
        "            else:\n",
        "              self.layer12 = choose_layer(architecture[i])\n",
        "          else:\n",
        "            self.layer12 = choose_layer(architecture[i])\n",
        "        case 12:\n",
        "          #layer13\n",
        "          if (architecture[i]>=1 and architecture[i]<=5) or architecture[i]==11: #if it is a convolutional layer or a batchnorm layer, we must set its in_channels value to the out_channels of the last convolutional layer\n",
        "            if isinstance(self.layer12, nn.Conv2d):\n",
        "              self.layer13 = choose_layer(architecture[i], self.layer12.out_channels)\n",
        "            elif isinstance(self.layer11, nn.Conv2d):\n",
        "              self.layer13 = choose_layer(architecture[i], self.layer11.out_channels)\n",
        "            elif isinstance(self.layer10, nn.Conv2d):\n",
        "              self.layer13 = choose_layer(architecture[i], self.layer10.out_channels)\n",
        "            elif isinstance(self.layer9, nn.Conv2d):\n",
        "              self.layer13 = choose_layer(architecture[i], self.layer9.out_channels)\n",
        "            elif isinstance(self.layer8, nn.Conv2d):\n",
        "              self.layer13 = choose_layer(architecture[i], self.layer8.out_channels)\n",
        "            elif isinstance(self.layer7, nn.Conv2d):\n",
        "              self.layer13 = choose_layer(architecture[i], self.layer7.out_channels)\n",
        "            elif isinstance(self.layer6, nn.Conv2d):\n",
        "              self.layer13 = choose_layer(architecture[i], self.layer6.out_channels)\n",
        "            elif isinstance(self.layer5, nn.Conv2d):\n",
        "              self.layer13 = choose_layer(architecture[i], self.layer5.out_channels)\n",
        "            elif isinstance(self.layer4, nn.Conv2d):\n",
        "              self.layer13 = choose_layer(architecture[i], self.layer4.out_channels)\n",
        "            elif isinstance(self.layer3, nn.Conv2d):\n",
        "              self.layer13 = choose_layer(architecture[i], self.layer3.out_channels)\n",
        "            elif isinstance(self.layer2, nn.Conv2d):\n",
        "              self.layer13 = choose_layer(architecture[i], self.layer2.out_channels)\n",
        "            elif isinstance(self.layer1, nn.Conv2d):\n",
        "              self.layer13 = choose_layer(architecture[i], self.layer1.out_channels)\n",
        "            else:\n",
        "              self.layer13 = choose_layer(architecture[i])\n",
        "          else:\n",
        "            self.layer13 = choose_layer(architecture[i])\n",
        "        case 13:\n",
        "          #layer14\n",
        "          if (architecture[i]>=1 and architecture[i]<=5) or architecture[i]==11: #if it is a convolutional layer or a batchnorm layer, we must set its in_channels value to the out_channels of the last convolutional layer\n",
        "            if isinstance(self.layer13, nn.Conv2d):\n",
        "              self.layer14 = choose_layer(architecture[i], self.layer13.out_channels)\n",
        "            elif isinstance(self.layer12, nn.Conv2d):\n",
        "              self.layer14 = choose_layer(architecture[i], self.layer12.out_channels)\n",
        "            elif isinstance(self.layer11, nn.Conv2d):\n",
        "              self.layer14 = choose_layer(architecture[i], self.layer11.out_channels)\n",
        "            elif isinstance(self.layer10, nn.Conv2d):\n",
        "              self.layer14 = choose_layer(architecture[i], self.layer10.out_channels)\n",
        "            elif isinstance(self.layer9, nn.Conv2d):\n",
        "              self.layer14 = choose_layer(architecture[i], self.layer9.out_channels)\n",
        "            elif isinstance(self.layer8, nn.Conv2d):\n",
        "              self.layer14 = choose_layer(architecture[i], self.layer8.out_channels)\n",
        "            elif isinstance(self.layer7, nn.Conv2d):\n",
        "              self.layer14 = choose_layer(architecture[i], self.layer7.out_channels)\n",
        "            elif isinstance(self.layer6, nn.Conv2d):\n",
        "              self.layer14 = choose_layer(architecture[i], self.layer6.out_channels)\n",
        "            elif isinstance(self.layer5, nn.Conv2d):\n",
        "              self.layer14 = choose_layer(architecture[i], self.layer5.out_channels)\n",
        "            elif isinstance(self.layer4, nn.Conv2d):\n",
        "              self.layer14 = choose_layer(architecture[i], self.layer4.out_channels)\n",
        "            elif isinstance(self.layer3, nn.Conv2d):\n",
        "              self.layer14 = choose_layer(architecture[i], self.layer3.out_channels)\n",
        "            elif isinstance(self.layer2, nn.Conv2d):\n",
        "              self.layer14 = choose_layer(architecture[i], self.layer2.out_channels)\n",
        "            elif isinstance(self.layer1, nn.Conv2d):\n",
        "              self.layer14 = choose_layer(architecture[i], self.layer1.out_channels)\n",
        "            else:\n",
        "              self.layer14 = choose_layer(architecture[i])\n",
        "          else:\n",
        "            self.layer14 = choose_layer(architecture[i])\n",
        "        case 14:\n",
        "          #layer15\n",
        "          if (architecture[i]>=1 and architecture[i]<=5) or architecture[i]==11: #if it is a convolutional layer or a batchnorm layer, we must set its in_channels value to the out_channels of the last convolutional layer\n",
        "            if isinstance(self.layer14, nn.Conv2d):\n",
        "              self.layer15 = choose_layer(architecture[i], self.layer14.out_channels)\n",
        "            elif isinstance(self.layer13, nn.Conv2d):\n",
        "              self.layer15 = choose_layer(architecture[i], self.layer13.out_channels)\n",
        "            elif isinstance(self.layer12, nn.Conv2d):\n",
        "              self.layer15 = choose_layer(architecture[i], self.layer12.out_channels)\n",
        "            elif isinstance(self.layer11, nn.Conv2d):\n",
        "              self.layer15 = choose_layer(architecture[i], self.layer11.out_channels)\n",
        "            elif isinstance(self.layer10, nn.Conv2d):\n",
        "              self.layer15 = choose_layer(architecture[i], self.layer10.out_channels)\n",
        "            elif isinstance(self.layer9, nn.Conv2d):\n",
        "              self.layer15 = choose_layer(architecture[i], self.layer9.out_channels)\n",
        "            elif isinstance(self.layer8, nn.Conv2d):\n",
        "              self.layer15 = choose_layer(architecture[i], self.layer8.out_channels)\n",
        "            elif isinstance(self.layer7, nn.Conv2d):\n",
        "              self.layer15 = choose_layer(architecture[i], self.layer7.out_channels)\n",
        "            elif isinstance(self.layer6, nn.Conv2d):\n",
        "              self.layer15 = choose_layer(architecture[i], self.layer6.out_channels)\n",
        "            elif isinstance(self.layer5, nn.Conv2d):\n",
        "              self.layer15 = choose_layer(architecture[i], self.layer5.out_channels)\n",
        "            elif isinstance(self.layer4, nn.Conv2d):\n",
        "              self.layer15 = choose_layer(architecture[i], self.layer4.out_channels)\n",
        "            elif isinstance(self.layer3, nn.Conv2d):\n",
        "              self.layer15 = choose_layer(architecture[i], self.layer3.out_channels)\n",
        "            elif isinstance(self.layer2, nn.Conv2d):\n",
        "              self.layer15 = choose_layer(architecture[i], self.layer2.out_channels)\n",
        "            elif isinstance(self.layer1, nn.Conv2d):\n",
        "              self.layer15 = choose_layer(architecture[i], self.layer1.out_channels)\n",
        "            else:\n",
        "              self.layer15 = choose_layer(architecture[i])\n",
        "          else:\n",
        "            self.layer15 = choose_layer(architecture[i])\n",
        "        case 15:\n",
        "          #layer16\n",
        "          if (architecture[i]>=1 and architecture[i]<=5) or architecture[i]==11: #if it is a convolutional layer or a batchnorm layer, we must set its in_channels value to the out_channels of the last convolutional layer\n",
        "            if isinstance(self.layer15, nn.Conv2d):\n",
        "              self.layer16 = choose_layer(architecture[i], self.layer15.out_channels)\n",
        "            elif isinstance(self.layer14, nn.Conv2d):\n",
        "              self.layer16 = choose_layer(architecture[i], self.layer14.out_channels)\n",
        "            elif isinstance(self.layer13, nn.Conv2d):\n",
        "              self.layer16 = choose_layer(architecture[i], self.layer13.out_channels)\n",
        "            elif isinstance(self.layer12, nn.Conv2d):\n",
        "              self.layer16 = choose_layer(architecture[i], self.layer12.out_channels)\n",
        "            elif isinstance(self.layer11, nn.Conv2d):\n",
        "              self.layer16 = choose_layer(architecture[i], self.layer11.out_channels)\n",
        "            elif isinstance(self.layer10, nn.Conv2d):\n",
        "              self.layer16 = choose_layer(architecture[i], self.layer10.out_channels)\n",
        "            elif isinstance(self.layer9, nn.Conv2d):\n",
        "              self.layer16 = choose_layer(architecture[i], self.layer9.out_channels)\n",
        "            elif isinstance(self.layer8, nn.Conv2d):\n",
        "              self.layer16 = choose_layer(architecture[i], self.layer8.out_channels)\n",
        "            elif isinstance(self.layer7, nn.Conv2d):\n",
        "              self.layer16 = choose_layer(architecture[i], self.layer7.out_channels)\n",
        "            elif isinstance(self.layer6, nn.Conv2d):\n",
        "              self.layer16 = choose_layer(architecture[i], self.layer6.out_channels)\n",
        "            elif isinstance(self.layer5, nn.Conv2d):\n",
        "              self.layer16 = choose_layer(architecture[i], self.layer5.out_channels)\n",
        "            elif isinstance(self.layer4, nn.Conv2d):\n",
        "              self.layer16 = choose_layer(architecture[i], self.layer4.out_channels)\n",
        "            elif isinstance(self.layer3, nn.Conv2d):\n",
        "              self.layer16 = choose_layer(architecture[i], self.layer3.out_channels)\n",
        "            elif isinstance(self.layer2, nn.Conv2d):\n",
        "              self.layer16 = choose_layer(architecture[i], self.layer2.out_channels)\n",
        "            elif isinstance(self.layer1, nn.Conv2d):\n",
        "              self.layer16 = choose_layer(architecture[i], self.layer1.out_channels)\n",
        "            else:\n",
        "              self.layer16 = choose_layer(architecture[i])\n",
        "          else:\n",
        "            self.layer16 = choose_layer(architecture[i])\n",
        "        case _:\n",
        "          print(\"Error\")\n",
        "\n",
        "    #Define the input size of linear layer\n",
        "    print(\"The input size for the first nn.Linear layer is: \", size)\n",
        "\n",
        "    size2 = int(size/2)\n",
        "    self.layer17 = nn.Sequential(\n",
        "        nn.Dropout(p=0.2),\n",
        "        nn.Linear(in_features=size, out_features=size2),\n",
        "        nn.Linear(in_features=size2, out_features=2)\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self, image):\n",
        "    x = self.layer0(image)\n",
        "    #print(\"LAYER 0: \", x.shape)\n",
        "    x = self.layer1(x)\n",
        "    #print(\"LAYER 1: \", x.shape)\n",
        "    x = self.layer2(x)\n",
        "    #print(\"LAYER 2: \", x.shape)\n",
        "    x = self.layer3(x)\n",
        "    #print(\"LAYER 3: \", x.shape)\n",
        "    x = self.layer4(x)\n",
        "    #print(\"LAYER 4: \", x.shape)\n",
        "    x = self.layer5(x)\n",
        "    #print(\"LAYER 5: \", x.shape)\n",
        "    x = self.layer6(x)\n",
        "    #print(\"LAYER 6: \", x.shape)\n",
        "    x = self.layer7(x)\n",
        "    #print(\"LAYER 7: \", x.shape)\n",
        "    x = self.layer8(x)\n",
        "    #print(\"LAYER 8: \", x.shape)\n",
        "    x = self.layer9(x)\n",
        "    #print(\"LAYER 9: \", x.shape)\n",
        "    x = self.layer10(x)\n",
        "    #print(\"LAYER 10: \", x.shape)\n",
        "    x = self.layer11(x)\n",
        "    x = self.layer12(x)\n",
        "    x = self.layer13(x)\n",
        "    x = self.layer14(x)\n",
        "    x = self.layer15(x)\n",
        "    x = self.layer16(x)\n",
        "    x = self.flatter(x)\n",
        "    #print(\"LAYER FLATTER: \", x.shape)\n",
        "    x = self.layer17(x)\n",
        "    #print(\"LAYER 11: \", x.shape)\n",
        "    return x\n",
        "\n",
        "#from PIL import Image\n",
        "#import torchvision.transforms as transforms\n",
        "#file_path = '/content/drive/MyDrive/LinkToOncoVision/SE4AI/Data/Datasets/FinalDataset/benign/ISIC_0000000.jpg'\n",
        "#image = image = Image.open(file_path)\n",
        "##Transform the image in tensor\n",
        "#transform = transforms.ToTensor()\n",
        "#img_tensor = transform(image)\n",
        "#img_tensor = torch.unsqueeze(img_tensor, 0)\n",
        "#\n",
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#print(\"Device: \",device)\n",
        "#img_tensor = img_tensor.to(device)\n",
        "#model = ConvModel2([2,5,10,9,3,8,11,9,4,6],50*37*4).to(device)\n",
        "#print(model)\n",
        "#model.forward(img_tensor)"
      ]
    }
  ]
}