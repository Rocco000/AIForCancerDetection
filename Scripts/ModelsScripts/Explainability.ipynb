{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rocco000/OncoVision/blob/main/Scripts/ModelsScripts/Explainability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the necessary libraries"
      ],
      "metadata": {
        "id": "yUNkBOK1JFDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install grad-cam\n",
        "from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "qM471g0jJ1N_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code to obtain the size of the first linear layer in GA2"
      ],
      "metadata": {
        "id": "fYrMZgHyDkV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_last_convolutional_layer(model, layers):\n",
        "  last = model.layer0\n",
        "  i = len(layers)\n",
        "\n",
        "  while i>0:\n",
        "    match i:\n",
        "      case 16:\n",
        "        if isinstance(model.layer16, torch.nn.Conv2d):\n",
        "          last = model.layer16\n",
        "          break\n",
        "      case 15:\n",
        "        if isinstance(model.layer15, torch.nn.Conv2d):\n",
        "          last = model.layer15\n",
        "          break\n",
        "      case 14:\n",
        "        if isinstance(model.layer14, torch.nn.Conv2d):\n",
        "          last = model.layer14\n",
        "          break\n",
        "      case 13:\n",
        "        if isinstance(model.layer13, torch.nn.Conv2d):\n",
        "          last = model.layer13\n",
        "          break\n",
        "      case 12:\n",
        "        if isinstance(model.layer12, torch.nn.Conv2d):\n",
        "          last = model.layer12\n",
        "          break\n",
        "      case 11:\n",
        "        if isinstance(model.layer11, torch.nn.Conv2d):\n",
        "          last = model.layer11\n",
        "          break\n",
        "      case 10:\n",
        "        if isinstance(model.layer10, torch.nn.Conv2d):\n",
        "          last = model.layer10\n",
        "          break\n",
        "      case 9:\n",
        "        if isinstance(model.layer9, torch.nn.Conv2d):\n",
        "          last = model.layer9\n",
        "          break\n",
        "      case 8:\n",
        "        if isinstance(model.layer8, torch.nn.Conv2d):\n",
        "          last = model.layer8\n",
        "          break\n",
        "      case 7:\n",
        "        if isinstance(model.layer7, torch.nn.Conv2d):\n",
        "          last = model.layer7\n",
        "          break\n",
        "      case 6:\n",
        "        if isinstance(model.layer6, torch.nn.Conv2d):\n",
        "          last = model.layer6\n",
        "          break\n",
        "      case 5:\n",
        "        if isinstance(model.layer5, torch.nn.Conv2d):\n",
        "          last = model.layer5\n",
        "          break\n",
        "      case 4:\n",
        "        if isinstance(model.layer4, torch.nn.Conv2d):\n",
        "          last = model.layer4\n",
        "          break\n",
        "      case 3:\n",
        "        if isinstance(model.layer3, torch.nn.Conv2d):\n",
        "          last = model.layer3\n",
        "          break\n",
        "      case 2:\n",
        "        if isinstance(model.layer2, torch.nn.Conv2d):\n",
        "          last = model.layer2\n",
        "          break\n",
        "      case 1:\n",
        "        if isinstance(model.layer1, torch.nn.Conv2d):\n",
        "          last = model.layer1\n",
        "          break\n",
        "\n",
        "    i = i-1\n",
        "\n",
        "  return last"
      ],
      "metadata": {
        "id": "02UeAIgRB1aS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to conduct explainability"
      ],
      "metadata": {
        "id": "dw4u_RTYD5j_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def explain_prediction(model, images, predictions, prediction_type, path_prefix, layers=None):\n",
        "  #Set the model in evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  #Take the last convolutional layer\n",
        "  target_layers = None\n",
        "  if layers is None:\n",
        "    #GA1 and base model\n",
        "    target_layers=[model.layer5[0]]\n",
        "  else:\n",
        "    #Find the last convolutional layer of GA2 solution\n",
        "    last_layer = find_last_convolutional_layer(model, layers)\n",
        "    target_layers=[last_layer]\n",
        "    print(\"Last convolutiona layer GA2: \")\n",
        "    print(target_layers)\n",
        "\n",
        "\n",
        "  #Construct the CAM object\n",
        "  cam = GradCAM(model=model, target_layers=target_layers, use_cuda=True if device==\"cuda\" else False)\n",
        "\n",
        "  targets = [ClassifierOutputTarget(1)]\n",
        "\n",
        "  i = 0\n",
        "  for img in images:\n",
        "    if prediction_type == 1:\n",
        "      print(\"Explainability on \",i+1,\"-th image on which the model wrong!\")\n",
        "    elif prediction_type == 2:\n",
        "      print(\"Explainability on \",i+1,\"-th image\")\n",
        "    else:\n",
        "      print(\"Explainability on \",i+1,\"-th image on which the model predicts correct!\")\n",
        "\n",
        "    if prediction_type != 2:\n",
        "      print(\"Model predicted: \",predictions[i][1],\", the true label is: \",predictions[i][0])\n",
        "    else:\n",
        "      print(\"Model predicted: \",predictions[i])\n",
        "\n",
        "    img = img.unsqueeze(0)\n",
        "    img = img.to(\"cuda\")\n",
        "\n",
        "    grayscale_cam = cam(input_tensor=img, targets=targets)\n",
        "    grayscale_cam = grayscale_cam[0, :]\n",
        "\n",
        "    img = img.cpu()\n",
        "    #Convert the tensor in the original image\n",
        "    rgb_img = img.numpy()[0]\n",
        "\n",
        "    visualization = show_cam_on_image(rgb_img.transpose(1,2,0), grayscale_cam, use_rgb=False)\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(rgb_img.transpose(1,2,0))\n",
        "    plt.title(\"Original image\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(visualization)\n",
        "    plt.title(\"Explainability\")\n",
        "    plt.axis('off')\n",
        "    if prediction_type == 1:\n",
        "      plt.savefig(path_prefix+\"Wrong\"+str(i)+\".png\")\n",
        "    elif prediction_type == 2:\n",
        "      plt.savefig(path_prefix+\"Image\"+str(i)+\".png\")\n",
        "    else:\n",
        "      plt.savefig(path_prefix+\"Correct\"+str(i)+\".png\")\n",
        "    plt.show()\n",
        "\n",
        "    i+=1"
      ],
      "metadata": {
        "id": "_1GeqT5PD_kM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}