{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMCrUFF86OXXZEwhSylKdP2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rocco000/OncoVision/blob/main/Scripts/ModelsScripts/Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the required libraries"
      ],
      "metadata": {
        "id": "LnOaaEZB8-Bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#To take the real time image\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "#To authenticate the user\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device: \",device)"
      ],
      "metadata": {
        "id": "nuXV0Zd3886o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the correct paths"
      ],
      "metadata": {
        "id": "SyCGj8h0DYPm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVeE_ZN44bap"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') #Connect to Google Drive\n",
        "\n",
        "#To authenticate the user that run the script in order to use the correct path\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "#Get user information\n",
        "about = drive_service.about().get(fields='user').execute()\n",
        "user_email = about['user']['emailAddress']\n",
        "\n",
        "path_prefix = \"\"\n",
        "path_base_model = path_ga1_model = path_ga2_model = path_ga2_solution = \"\"\n",
        "\n",
        "if user_email ==\"rocco.iul2000@gmail.com\":\n",
        "  path_prefix = \"/content/drive/MyDrive/SE4AI/Model/\"\n",
        "  path_base_model = \"/content/drive/MyDrive/SE4AI/Model/EvaluationFirstApproach/model_parameters.pth\"\n",
        "  path_ga1_model = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGAFirstApproach/ModelsConfigurations/best_solution.pth\"\n",
        "  path_ga2_model = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGASecondApproach/ModelsConfigurations/best_solution.pth\"\n",
        "  path_ga2_solution = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGASecondApproach/BestSolutionGA2.csv\"\n",
        "\n",
        "  %run '/content/drive/MyDrive/SE4AI/Scripts/ModelArchitecture1.ipynb'\n",
        "  %run '/content/drive/MyDrive/SE4AI/Scripts/ModelArchitecture2.ipynb'\n",
        "  %run '/content/drive/MyDrive/SE4AI/Scripts/Explainability.ipynb'\n",
        "else:\n",
        "  path_prefix = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/\"\n",
        "  path_base_model = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationFirstApproach/model_parameters.pth\"\n",
        "  path_ga1_model = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGAFirstApproach/ModelsConfigurations/best_solution.pth\"\n",
        "  path_ga2_model = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGASecondApproach/ModelsConfigurations/best_solution.pth\"\n",
        "  path_ga2_solution = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGASecondApproach/BestSolutionGA2.csv\"\n",
        "\n",
        "  %run '/content/drive/MyDrive/LinkToOncoVision/SE4AI/Scripts/ModelArchitecture1.ipynb'\n",
        "  %run '/content/drive/MyDrive/LinkToOncoVision/SE4AI/Scripts/ModelArchitecture2.ipynb'\n",
        "  %run '/content/drive/MyDrive/LinkToOncoVision/SE4AI/Scripts/Explainability.ipynb'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To obtain the input size of the first linear layer in GA2"
      ],
      "metadata": {
        "id": "kE-sGzqJ8Dq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_validity(solution):\n",
        "  #Computing the input size of the first nn.Linear\n",
        "\n",
        "  width_in, height_in, size = size_nn_linear_calculator(layer_type=5, width=450, height=600, channels=None) # first conv2d\n",
        "  i = 0\n",
        "  for element in solution:\n",
        "    if element == 1:\n",
        "      #conv-128\n",
        "      #To avoid the presence of 4 consecutive conv0 layers (loss.backward() out of memory)\n",
        "      if i>2:\n",
        "        if (solution[i-1]>=1 and solution[i-1]<=5) and (solution[i-2]>=1 and solution[i-2]<=5) and (solution[i-3]>=1 and solution[i-3]<=5):\n",
        "          return False,0\n",
        "      elif i==2:\n",
        "        if (solution[i-1]>=1 and solution[i-1]<=5) and (solution[i-2]>=1 and solution[i-2]<=5):\n",
        "          return False,0\n",
        "\n",
        "      if (i-1)>=0:\n",
        "        j=i-1\n",
        "        flag=False\n",
        "        while j>=0 and (not flag):\n",
        "          if solution[j]==6 or solution[j]==7 or solution[j]==8 or solution[j]==9: #Due to Cuda out of memory, we can't have two conv-128 without a pooling layer\n",
        "            flag=True\n",
        "          j=j-1\n",
        "        if not flag:\n",
        "          return False,0\n",
        "\n",
        "      width_in, height_in, size = size_nn_linear_calculator(layer_type=1, width=width_in, height=height_in, channels=None)\n",
        "    elif element == 2:\n",
        "      #conv-64\n",
        "      #To avoid the presence of 4 consecutive conv0 layers (loss.backward() out of memory)\n",
        "      if i>2:\n",
        "        if (solution[i-1]>=1 and solution[i-1]<=5) and (solution[i-2]>=1 and solution[i-2]<=5) and (solution[i-3]>=1 and solution[i-3]<=5):\n",
        "          return False,0\n",
        "      elif i==2:\n",
        "        if (solution[i-1]>=1 and solution[i-1]<=5) and (solution[i-2]>=1 and solution[i-2]<=5):\n",
        "          return False,0\n",
        "\n",
        "      width_in, height_in, size = size_nn_linear_calculator(layer_type=2, width=width_in, height=height_in, channels=None)\n",
        "    elif element == 3:\n",
        "      #conv-32\n",
        "      #To avoid the presence of 4 consecutive conv0 layers (loss.backward() out of memory)\n",
        "      if i>2:\n",
        "        if (solution[i-1]>=1 and solution[i-1]<=5) and (solution[i-2]>=1 and solution[i-2]<=5) and (solution[i-3]>=1 and solution[i-3]<=5):\n",
        "          return False,0\n",
        "      elif i==2:\n",
        "        if (solution[i-1]>=1 and solution[i-1]<=5) and (solution[i-2]>=1 and solution[i-2]<=5):\n",
        "          return False,0\n",
        "\n",
        "      width_in, height_in, size = size_nn_linear_calculator(layer_type=3, width=width_in, height=height_in, channels=None)\n",
        "    elif element == 4:\n",
        "      #conv-16\n",
        "      #To avoid the presence of 4 consecutive conv0 layers (loss.backward() out of memory)\n",
        "      if i>2:\n",
        "        if (solution[i-1]>=1 and solution[i-1]<=5) and (solution[i-2]>=1 and solution[i-2]<=5) and (solution[i-3]>=1 and solution[i-3]<=5):\n",
        "          return False,0\n",
        "      elif i==2:\n",
        "        if (solution[i-1]>=1 and solution[i-1]<=5) and (solution[i-2]>=1 and solution[i-2]<=5):\n",
        "          return False,0\n",
        "\n",
        "      width_in, height_in, size = size_nn_linear_calculator(layer_type=4, width=width_in, height=height_in, channels=None)\n",
        "    elif element == 5:\n",
        "      #conv-8\n",
        "      #To avoid the presence of 4 consecutive conv0 layers (loss.backward() out of memory)\n",
        "      if i>2:\n",
        "        if (solution[i-1]>=1 and solution[i-1]<=5) and (solution[i-2]>=1 and solution[i-2]<=5) and (solution[i-3]>=1 and solution[i-3]<=5):\n",
        "          return False,0\n",
        "      elif i==2:\n",
        "        if (solution[i-1]>=1 and solution[i-1]<=5) and (solution[i-2]>=1 and solution[i-2]<=5):\n",
        "          return False,0\n",
        "\n",
        "      width_in, height_in, size = size_nn_linear_calculator(layer_type=5, width=width_in, height=height_in, channels=None)\n",
        "    elif element == 6:\n",
        "      #max-3\n",
        "      if (i-1)>=0:\n",
        "        if solution[i-1]!=12 and solution[i-1]!=13 and solution[i-1]!=1 and solution[i-1]!=2 and solution[i-1]!=3 and solution[i-1]!=4 and solution[i-1]!=5: #if before the pooling layer there isn't a activation layer or a convolutional layer\n",
        "          return False, 0\n",
        "\n",
        "      #Find the last convolutional layer before the actual layer to define the number of output channels\n",
        "      j = i-1\n",
        "      num_channels = 8 #because our first layer is a conv-8\n",
        "      flag = False\n",
        "      while j>=0 and (not flag):\n",
        "        if solution[j] == 1:\n",
        "          num_channels = 128\n",
        "          flag = True\n",
        "        elif solution[j] == 2:\n",
        "          num_channels = 64\n",
        "          flag = True\n",
        "        elif solution[j] == 3:\n",
        "          num_channels = 32\n",
        "          flag = True\n",
        "        elif solution[j] == 4:\n",
        "          num_channels = 16\n",
        "          flag = True\n",
        "        elif solution[j] == 5:\n",
        "          num_channels = 8\n",
        "          flag = True\n",
        "        j = j-1\n",
        "      width_in, height_in, size = size_nn_linear_calculator(layer_type=6, width=width_in, height=height_in, channels=num_channels)\n",
        "    elif element == 7:\n",
        "      #max-2\n",
        "      if (i-1)>=0:\n",
        "        if solution[i-1]!=12 and solution[i-1]!=13 and solution[i-1]!=1 and solution[i-1]!=2 and solution[i-1]!=3 and solution[i-1]!=4 and solution[i-1]!=5: #if before the pooling layer there isn't a activation layer or a convolutional layer\n",
        "          return False, 0\n",
        "\n",
        "      #Find the last convolutional layer before the actual layer to define the number of output channels\n",
        "      j = i-1\n",
        "      num_channels = 8 #because our first layer is a conv-8\n",
        "      flag = False\n",
        "      while j>=0 and (not flag):\n",
        "        if solution[j] == 1:\n",
        "          num_channels = 128\n",
        "          flag = True\n",
        "        elif solution[j] == 2:\n",
        "          num_channels = 64\n",
        "          flag = True\n",
        "        elif solution[j] == 3:\n",
        "          num_channels = 32\n",
        "          flag = True\n",
        "        elif solution[j] == 4:\n",
        "          num_channels = 16\n",
        "          flag = True\n",
        "        elif solution[j] == 5:\n",
        "          num_channels = 8\n",
        "          flag = True\n",
        "        j = j-1\n",
        "      width_in, height_in, size = size_nn_linear_calculator(layer_type=7, width=width_in, height=height_in, channels=num_channels)\n",
        "    elif element == 8:\n",
        "      #avg-3\n",
        "      if (i-1)>=0:\n",
        "        if solution[i-1]!=12 and solution[i-1]!=13 and solution[i-1]!=1 and solution[i-1]!=2 and solution[i-1]!=3 and solution[i-1]!=4 and solution[i-1]!=5: #if before the pooling layer there isn't a activation layer or a convolutional layer\n",
        "          return False, 0\n",
        "\n",
        "      #Find the last convolutional layer before the actual layer to define the number of output channels\n",
        "      j = i-1\n",
        "      num_channels = 8 #because our first layer is a conv-8\n",
        "      flag = False\n",
        "      while j>=0 and (not flag):\n",
        "        if solution[j] == 1:\n",
        "          num_channels = 128\n",
        "          flag = True\n",
        "        elif solution[j] == 2:\n",
        "          num_channels = 64\n",
        "          flag = True\n",
        "        elif solution[j] == 3:\n",
        "          num_channels = 32\n",
        "          flag = True\n",
        "        elif solution[j] == 4:\n",
        "          num_channels = 16\n",
        "          flag = True\n",
        "        elif solution[j] == 5:\n",
        "          num_channels = 8\n",
        "          flag = True\n",
        "        j = j-1\n",
        "      width_in, height_in, size = size_nn_linear_calculator(layer_type=8, width=width_in, height=height_in, channels=num_channels)\n",
        "    elif element == 9:\n",
        "      #avg-2\n",
        "      if (i-1)>=0:\n",
        "        if solution[i-1]!=12 and solution[i-1]!=13 and solution[i-1]!=1 and solution[i-1]!=2 and solution[i-1]!=3 and solution[i-1]!=4 and solution[i-1]!=5: #if before the pooling layer there isn't a activation layer or a convolutional layer\n",
        "          return False, 0\n",
        "\n",
        "      #Find the last convolutional layer before the actual layer to define the number of output channels\n",
        "      j = i-1\n",
        "      num_channels = 8 #because our first layer is a conv-8\n",
        "      flag = False\n",
        "      while j>=0 and (not flag):\n",
        "        if solution[j] == 1:\n",
        "          num_channels = 128\n",
        "          flag = True\n",
        "        elif solution[j] == 2:\n",
        "          num_channels = 64\n",
        "          flag = True\n",
        "        elif solution[j] == 3:\n",
        "          num_channels = 32\n",
        "          flag = True\n",
        "        elif solution[j] == 4:\n",
        "          num_channels = 16\n",
        "          flag = True\n",
        "        elif solution[j] == 5:\n",
        "          num_channels = 8\n",
        "          flag = True\n",
        "        j = j-1\n",
        "      width_in, height_in, size = size_nn_linear_calculator(layer_type=9, width=width_in, height=height_in, channels=num_channels)\n",
        "    elif element == 10:\n",
        "      #Dropout2d\n",
        "      if (i-1)>=0:\n",
        "        if solution[i-1]!=6 and solution[i-1]!=7 and solution[i-1]!=8 and solution[i-1]!=9: #If before the dropout layer there isn't a pooling layer.\n",
        "          return False, 0\n",
        "      else:\n",
        "        return False, 0\n",
        "    elif element == 11:\n",
        "      #BatchNorm\n",
        "      if (i-1)>=0:\n",
        "        if solution[i-1]!=1 and solution[i-1]!=2 and solution[i-1]!=3 and solution[i-1]!=4 and solution[i-1]!=5:\n",
        "          return False, 0\n",
        "    elif element == 12 or element == 13:\n",
        "      #ReLU and LeakyReLU\n",
        "      if (i-1)>=0:\n",
        "        if solution[i-1]!=1 and solution[i-1]!=2 and solution[i-1]!=3 and solution[i-1]!=4 and solution[i-1]!=5 and solution[i-1]!=11: #if before the activation layer there isn't a convolutional layer\n",
        "          return False, 0\n",
        "\n",
        "    i = i+1\n",
        "\n",
        "  size = int(size)\n",
        "  if size<8 or size>25000:\n",
        "    return False, 0\n",
        "  else:\n",
        "    return True, size"
      ],
      "metadata": {
        "id": "JLCk7L-88D6L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the model"
      ],
      "metadata": {
        "id": "EguCMPDc8TVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "choose = int(input(\"On which model do you want to demo? (1 = base model, 2 = GA1, 3 = GA2)\\n\"))\n",
        "\n",
        "path_demo = \"\"\n",
        "\n",
        "my_model = None\n",
        "layers = list() #To store the architecture of ga2 solution\n",
        "\n",
        "match(choose):\n",
        "  case 1:\n",
        "    #Base model\n",
        "    print(\"Demo with BASE model\")\n",
        "    my_model = ConvModel1()\n",
        "    my_model.load_state_dict(torch.load(path_base_model))\n",
        "    my_model = my_model.to(device)\n",
        "    my_model.eval()\n",
        "\n",
        "    path_demo = \"EvaluationFirstApproach/Explainability/RealTime/\"\n",
        "  case 2:\n",
        "    #Best solution GA1\n",
        "    print(\"Demo with GA1 best solution\")\n",
        "    my_model = ConvModel1()\n",
        "    my_model.load_state_dict(torch.load(path_ga1_model))\n",
        "    my_model = my_model.to(device)\n",
        "    my_model.eval()\n",
        "\n",
        "    path_demo = \"EvaluationGAFirstApproach/Explainability/RealTime/\"\n",
        "  case 3:\n",
        "    #Best solution GA2\n",
        "    print(\"Demo with GA2 best solution\")\n",
        "\n",
        "    #Take the architecture of ga2 best solution\n",
        "    with open(path_ga2_solution, \"r\", newline=\"\") as csvfile:\n",
        "      reader = csv.reader(csvfile)\n",
        "      next(reader) #Jump the header\n",
        "      i = 0\n",
        "      for row in reader:\n",
        "        for element in row:\n",
        "          if i>=4 and i<=19:\n",
        "            layers.append(int(float(element)))\n",
        "\n",
        "          i+=1\n",
        "\n",
        "    print(\"GA2 best solution layers: \",layers)\n",
        "    flag, size = check_validity(layers)\n",
        "    print(\"Flag: \",flag)\n",
        "    print(\"Input size of the output linear layer: \",size)\n",
        "    my_model = ConvModel2(layers,size)\n",
        "    my_model.load_state_dict(torch.load(path_ga2_model))\n",
        "    my_model = my_model.to(device)\n",
        "    my_model.eval()\n",
        "\n",
        "    path_demo = \"EvaluationGASecondApproach/Explainability/RealTime/\"\n",
        "  case _:\n",
        "    print(\"Input error\")"
      ],
      "metadata": {
        "id": "JuleImgQ5E52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction in Real-Time"
      ],
      "metadata": {
        "id": "z1i3aSnb8hom"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To take the photo"
      ],
      "metadata": {
        "id": "tGl4jq4_8nbH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-Qwf4gUVFcHV"
      },
      "outputs": [],
      "source": [
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  # get OpenCV format image\n",
        "  img = js_to_image(data)\n",
        "  #binary = b64decode(data.split(',')[1])\n",
        "  #with open(filename, 'wb') as f:\n",
        "  #  f.write(binary)\n",
        "  return img\n",
        "\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  #Transform the BGR image in a RGB image\n",
        "  rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  #Transform the image in a PIL image\n",
        "  pil_image = transforms.ToPILImage()(rgb_img)\n",
        "\n",
        "  return pil_image\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction on input image"
      ],
      "metadata": {
        "id": "Ax79twBiDlcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "      transforms.Resize((600, 450)),  # Resize the images to 600x450\n",
        "      transforms.ToTensor()  # Convert the images to tensors\n",
        "  ])\n",
        "\n",
        "try:\n",
        "  img = take_photo()\n",
        "\n",
        "  print(\"Captured image:\")\n",
        "  plt.imshow(img)\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  img = transform(img)\n",
        "  img = img.unsqueeze(0)\n",
        "  img = img.to(device)\n",
        "\n",
        "  prediction = my_model(img)\n",
        "  prediction = F.softmax(prediction, dim=1) #Apply the Softmax function\n",
        "\n",
        "  class_probabilities = prediction[0]\n",
        "  for class_idx, probability in enumerate(class_probabilities):\n",
        "    print(f\"Class {class_idx}: Probability = {probability.item():.4f}\")\n",
        "\n",
        "  _, prediction = torch.max(prediction, 1) #Take the predicted class (class with high probability)\n",
        "  prediction = prediction.cpu().numpy()\n",
        "  if prediction[0] == 0:\n",
        "    print(\"Model prediction is: BENIGN\")\n",
        "  else:\n",
        "    print(\"Model prediction is: MELANOMA\")\n",
        "\n",
        "  img = img.cpu()\n",
        "  img = img.squeeze(0)\n",
        "  images = [img]\n",
        "  if choose == 3:\n",
        "    explain_prediction(my_model, images, prediction, 2, path_prefix+path_demo, layers)\n",
        "  else:\n",
        "    explain_prediction(my_model, images, prediction, 2, path_prefix+path_demo, None)\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(\"Error\")\n",
        "  print(str(err))"
      ],
      "metadata": {
        "id": "8vAQ8A_K8rLZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}