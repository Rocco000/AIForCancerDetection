{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rocco000/OncoVision/blob/main/Scripts/GAapproach1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utSQBFhb_kI0"
      },
      "source": [
        "Link to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49LQG4ba_jGB",
        "outputId": "5e6630f4-cf39-4575-eddc-b6dfe594706d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') #Connect to Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1QLq2ok_2XN"
      },
      "source": [
        "Run the required scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLavubHlAB49",
        "outputId": "6780e79c-5538-4ac7-bb77-2cc29e559ef7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device:  cuda\n",
            "Insert your DagsHub username:sudo-poweroff\n",
            "Insert your DagsHub mail:sdellaporta34@gmail.com\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.5/191.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.4/238.4 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fusepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "                      \u001b[1m❗❗❗ AUTHORIZATION REQUIRED ❗❗❗\u001b[0m                      \n",
            "\n",
            "\n",
            "Open the following link in your browser to authorize the client:\n",
            "https://dagshub.com/login/oauth/authorize?state=e652e032-c123-43f2-b02c-59c55bd5c72a&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=84af5a7c348b2d39785597da72975a1aaac1b4560dfcd0b00ef99a96a4e48e1b\n",
            "\n",
            "\n",
            "\u001b[2K\u001b[32m⠙\u001b[0m Waiting for authorization\n",
            "\u001b[1A\u001b[2K✅ OAuth token added\n",
            "/content\n",
            "Cloning into 'OncoVision'...\n",
            "remote: Enumerating objects: 673, done.\u001b[K\n",
            "remote: Counting objects: 100% (673/673), done.\u001b[K\n",
            "remote: Compressing objects: 100% (610/610), done.\u001b[K\n",
            "remote: Total 673 (delta 323), reused 106 (delta 20), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (673/673), 12.70 MiB | 5.38 MiB/s, done.\n",
            "Resolving deltas: 100% (323/323), done.\n",
            "/content/OncoVision\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "#To authenticate the user that run the script in order to use the correct path\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "#Get user information\n",
        "about = drive_service.about().get(fields='user').execute()\n",
        "user_email = about['user']['emailAddress']\n",
        "script_owner = False\n",
        "\n",
        "if user_email ==\"rocco.iul2000@gmail.com\":\n",
        "  script_owner = True\n",
        "  #Run the .ipynb file\n",
        "  %run '/content/drive/MyDrive/SE4AI/Scripts/DatasetLoader.ipynb'\n",
        "  %run '/content/drive/MyDrive/SE4AI/Scripts/ModelArchitecture1.ipynb'\n",
        "  %run '/content/drive/MyDrive/SE4AI/Scripts/TrainModel.ipynb'\n",
        "else:\n",
        "  %run '/content/drive/MyDrive/LinkToOncoVision/SE4AI/Scripts/DatasetLoader.ipynb'\n",
        "  %run '/content/drive/MyDrive/LinkToOncoVision/SE4AI/Scripts/ModelArchitecture1.ipynb'\n",
        "  %run '/content/drive/MyDrive/LinkToOncoVision/SE4AI/Scripts/TrainModel.ipynb'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUNkBOK1JFDR"
      },
      "source": [
        "Import the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZ9WTcozJEVJ",
        "outputId": "48c49a8b-8a43-4f6a-b5dc-b969c69ff431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pygad\n",
            "  Downloading pygad-3.1.0-py3-none-any.whl (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.0/73.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from pygad) (2.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from pygad) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pygad) (1.22.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pygad) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pygad) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pygad) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pygad) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pygad) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pygad) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pygad) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pygad) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->pygad) (1.16.0)\n",
            "Installing collected packages: pygad\n",
            "Successfully installed pygad-3.1.0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "!pip install pygad\n",
        "import pygad\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZTx136CvqDQ"
      },
      "source": [
        "# Genetic Algorithm (1° approach)\n",
        "Our **objective function**:\n",
        "> max w * accuracy+(1-w) * recall where w=0.4\n",
        "\n",
        "Our **valuation function** is equal to the objective function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFIsg9nrmXuT"
      },
      "source": [
        "# Assessment of solutions\n",
        "**At each generation**, we will evaluate the solutions and store them in a csv file.\n",
        "\n",
        "If we obtain a solution that has the same configuration of another solution stored in \"AllSolutions.csv\", we do not retrain the model as there is a high probability that it has the same performance (in this way, we reduce the time consumption)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-plEjl3o4bQ"
      },
      "outputs": [],
      "source": [
        "max_fitness = 0\n",
        "num_step = None\n",
        "solution_number=0\n",
        "\n",
        "def evaluate_solutions(num_generation, population):\n",
        "  population_list = population.tolist()\n",
        "  global max_fitness\n",
        "  global num_step\n",
        "  step_value = 0\n",
        "  sum = 0\n",
        "\n",
        "  if num_step is None:\n",
        "    step_value = num_generation\n",
        "  else:\n",
        "    step_value = num_step + num_generation\n",
        "\n",
        "  print(\"***************************************************************\")\n",
        "  print(\"We are at the \",step_value,\" generation step\")\n",
        "\n",
        "  #Define the files path to check if this solution already exists (less time consumption) and to store the model configuration of the best solution\n",
        "  path_parameters = \"\"\n",
        "  file_path1 = file_path2 = file_path3 = \"\"\n",
        "  if script_owner:\n",
        "    path_parameters = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGAFirstApproach/ModelsConfigurations/\"\n",
        "    file_path1 = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGAFirstApproach/ActualPopulation.csv\"\n",
        "    file_path2 = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGAFirstApproach/AllSolutions.csv\"\n",
        "    file_path3 = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGAFirstApproach/Checkpoint.csv\"\n",
        "  else:\n",
        "    path_parameters = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGAFirstApproach/ModelsConfigurations/\"\n",
        "    file_path1 = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGAFirstApproach/ActualPopulation.csv\"\n",
        "    file_path2 = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGAFirstApproach/AllSolutions.csv\"\n",
        "    file_path3 = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGAFirstApproach/Checkpoint.csv\"\n",
        "\n",
        "\n",
        "  #Deprive the ActualPopulation file\n",
        "  with open(file_path1, \"w\", newline=\"\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"learning_rate\",\"batch_size\",\"num_epoch\",\"optimizer\",\"fitness_value\",\"accuracy\",\"precision\",\"recall\",\"f1\",\"evaluation\"])\n",
        "\n",
        "  #Store the actual solutions\n",
        "  for solution in population_list:\n",
        "    with open(file_path1, \"a\", newline=\"\") as csvfile:\n",
        "      writer = csv.writer(csvfile)\n",
        "      temp_list = solution.copy()\n",
        "      temp_list.extend([None,None,None,None,None,None])\n",
        "      writer.writerow(solution)\n",
        "\n",
        "  #Store the checkpoint\n",
        "  run = mlflow.active_run()\n",
        "  experiment_id = run.info.experiment_id\n",
        "  with open(file_path3, \"w\", newline=\"\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"num_generation_step\",\"mlflow_experiment_id\"])\n",
        "    writer.writerow([step_value, experiment_id])\n",
        "\n",
        "  #To track the new solution\n",
        "  i = 0\n",
        "  for solution in population_list:\n",
        "\n",
        "    flag = False\n",
        "    learning_rate = float(solution[0])\n",
        "    batch_size = int(solution[1])\n",
        "    num_epoch = int(solution[2])\n",
        "    optimizer = int(solution[3])\n",
        "    evaluation = acc = pre = rec = f1 = 0\n",
        "    position_in_all = 0\n",
        "\n",
        "    #Check if the solution already exists\n",
        "    with open(file_path2, \"r\", newline=\"\") as csvfile:\n",
        "      reader = csv.reader(csvfile)\n",
        "      next(reader) #Jump the first row (contains the file header)\n",
        "      index = 0\n",
        "      for row in reader:\n",
        "        #Convert the values in the correct format\n",
        "        lr_row = float(row[0])\n",
        "        batch_row = int(float(row[1]))\n",
        "        epoch_row = int(float(row[2]))\n",
        "        optimizer_row = int(float(row[3]))\n",
        "        acc = float(row[5])\n",
        "        pre = float(row[6])\n",
        "        rec = float(row[7])\n",
        "        f1 = float(row[8])\n",
        "        evaluation = float(row[9])\n",
        "\n",
        "        if learning_rate==lr_row and batch_size==batch_row and num_epoch==epoch_row and optimizer==optimizer_row:\n",
        "          print(\"The solution: \",solution,\" acc:\",acc,\" pre:\",pre,\" rec:\",rec,\" f1:\",f1,\" already exists! (it will not train)\")\n",
        "          flag = True\n",
        "          position_in_all = index\n",
        "          break\n",
        "\n",
        "        index+=1\n",
        "\n",
        "    if flag:\n",
        "      #We have already this solution, therefore we store the configuration in ActualPopulation.csv\n",
        "      sum += evaluation\n",
        "      #Update ActualPopulation\n",
        "      df = pd.read_csv(file_path1)\n",
        "      matching_rows = df.loc[(df[\"learning_rate\"] == learning_rate) & (df[\"batch_size\"] == batch_size) & (df[\"num_epoch\"] == num_epoch) & (df[\"optimizer\"] == optimizer)]\n",
        "\n",
        "      if not matching_rows.empty:\n",
        "        #Take the solution index\n",
        "        indices = matching_rows.index\n",
        "        for idx in indices:\n",
        "          #Update the evaluation metrics\n",
        "          df.at[idx, \"accuracy\"] = acc\n",
        "          df.at[idx, \"precision\"] = pre\n",
        "          df.at[idx, \"recall\"] = rec\n",
        "          df.at[idx, \"f1\"] = f1\n",
        "          df.at[idx, \"evaluation\"] = evaluation\n",
        "\n",
        "        #save the updated ActualPopulation file\n",
        "        df.to_csv(file_path1, index=False)\n",
        "\n",
        "        #Take the solution configuration\n",
        "        individual = position_in_all % 8 #solution position in population\n",
        "        generation = int(position_in_all/8) #num generation where the solution was created\n",
        "\n",
        "        search_path = path_parameters+\"solution_\"+str(individual)+\"_\"+str(generation)+\".pth\"\n",
        "        if os.path.exists(search_path):\n",
        "          model_path = path_parameters+\"solution_\"+str(i)+\"_\"+str(step_value)+\".pth\"\n",
        "          shutil.copy(search_path, model_path)\n",
        "      else:\n",
        "        print(\"Row not found! (assesment solution- flag:True): \",solution)\n",
        "    else:\n",
        "      train_flag = True\n",
        "\n",
        "      #Check how many times the solution is in ActualPopulation\n",
        "      df = pd.read_csv(file_path1)\n",
        "      matching_rows = df.loc[(df[\"learning_rate\"] == learning_rate) & (df[\"batch_size\"] == batch_size) & (df[\"num_epoch\"] == num_epoch) & (df[\"optimizer\"] == optimizer)]\n",
        "      if len(matching_rows)>1:\n",
        "        #There is more than one equal individual\n",
        "        clone_position = matching_rows.index[0]\n",
        "        if pd.isna(df.at[clone_position, \"evaluation\"]):\n",
        "          #if the first solution was not trained, we will train it\n",
        "          train_flag = True\n",
        "        else:\n",
        "          #the first solution was trained, therefore we do not re-train the clone solution\n",
        "          train_flag = False\n",
        "\n",
        "          search_path = path_parameters+\"solution_\"+str(clone_position)+\"_\"+str(step_value)+\".pth\"\n",
        "          if os.path.exists(search_path):\n",
        "            model_path = path_parameters+\"solution_\"+str(i)+\"_\"+str(step_value)+\".pth\"\n",
        "            shutil.copy(search_path, model_path)\n",
        "\n",
        "          eval = df.loc[clone_position]\n",
        "          eval = float(eval[\"evaluation\"])\n",
        "          sum += eval\n",
        "\n",
        "      if train_flag:\n",
        "        #It's a new solution, therefore we must define and train a model\n",
        "        #batch_size\n",
        "        size = 0\n",
        "        match batch_size:\n",
        "          case 1:\n",
        "            size = 32\n",
        "          case 2:\n",
        "            size = 64\n",
        "          case _:\n",
        "            size = 32\n",
        "\n",
        "        #num_epoch\n",
        "        epoch = 0\n",
        "        match num_epoch:\n",
        "          case 1:\n",
        "            epoch = 64\n",
        "          case 2:\n",
        "            epoch = 96\n",
        "          case 3:\n",
        "            epoch = 128\n",
        "          case _:\n",
        "            epoch = 64\n",
        "\n",
        "        print(\"Evaluating the solution: \",solution)\n",
        "        best_model_configuration, acc, pre, rec, f1 = start_process(model_type=1, architecture=None, linear_size=None, bool_mlflow=False, learning_rate=learning_rate, batch_size=size, num_epoch=epoch, opt=optimizer)\n",
        "        solution_evaluation = (0.4*acc)+(0.6*rec)\n",
        "        sum += solution_evaluation\n",
        "\n",
        "        #Store its configuration\n",
        "        model_path = path_parameters+\"solution_\"+str(i)+\"_\"+str(step_value)+\".pth\"\n",
        "        torch.save(best_model_configuration, model_path)\n",
        "\n",
        "        #Update ActualPopulation\n",
        "        df = pd.read_csv(file_path1)\n",
        "        matching_rows = df.loc[(df[\"learning_rate\"] == learning_rate) & (df[\"batch_size\"] == batch_size) & (df[\"num_epoch\"] == num_epoch) & (df[\"optimizer\"] == optimizer)]\n",
        "\n",
        "        if not matching_rows.empty:\n",
        "          #Take the solution index\n",
        "          indices = matching_rows.index\n",
        "          for idx in indices:\n",
        "            #Update the evaluation metrics\n",
        "            df.at[idx, \"accuracy\"] = acc\n",
        "            df.at[idx, \"precision\"] = pre\n",
        "            df.at[idx, \"recall\"] = rec\n",
        "            df.at[idx, \"f1\"] = f1\n",
        "            df.at[idx, \"evaluation\"] = solution_evaluation\n",
        "\n",
        "          #save the updated ActualPopulation file\n",
        "          df.to_csv(file_path1, index=False)\n",
        "        else:\n",
        "          print(\"Row not found! (assesment solution- flag:False): \",solution)\n",
        "\n",
        "    i += 1\n",
        "\n",
        "  actual_population = list()\n",
        "  #Compute the fitness_value\n",
        "  with open(file_path1, \"r\", newline=\"\") as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    next(reader)\n",
        "    for row in reader:\n",
        "      evaluation = float(row[9])\n",
        "      row_copy = row.copy()\n",
        "      row_copy[4] = evaluation/(sum-evaluation) #Define the fitness value\n",
        "      actual_population.append(row_copy)\n",
        "\n",
        "  #Update the max_fitness value with the current fitness value of the last best individual\n",
        "  for solution in actual_population:\n",
        "    lr = float(solution[0])\n",
        "    batch = int(float(solution[1]))\n",
        "    epoch = int(float(solution[2]))\n",
        "    opt = int(float(solution[3]))\n",
        "    df = pd.read_csv(file_path2)\n",
        "    matching_rows = df.loc[(df[\"learning_rate\"] == lr) & (df[\"batch_size\"] == batch) & (df[\"num_epoch\"] == epoch) & (df[\"optimizer\"] == opt)]\n",
        "\n",
        "    if not matching_rows.empty:\n",
        "      position = matching_rows.index[len(matching_rows)-1]\n",
        "      last_occurence = df.loc[position]\n",
        "      eval = float(last_occurence[\"fitness_value\"])\n",
        "      if max_fitness == eval:\n",
        "        fitness_value = float(solution[4])\n",
        "        max_fitness = fitness_value\n",
        "        break\n",
        "\n",
        "  i=0\n",
        "  #Find the actual best solution\n",
        "  for solution in actual_population:\n",
        "    lr = float(solution[0])\n",
        "    batch = int(float(solution[1]))\n",
        "    epoch = int(float(solution[2]))\n",
        "    opt = int(float(solution[3]))\n",
        "    fitness_value = float(solution[4])\n",
        "    acc = float(solution[5])\n",
        "    pre = float(solution[6])\n",
        "    rec = float(solution[7])\n",
        "    f1 = float(solution[8])\n",
        "\n",
        "    #Update AllSolutions\n",
        "    with open(file_path2, \"a\", newline=\"\") as csvfile:\n",
        "      writer = csv.writer(csvfile)\n",
        "      writer.writerow(solution)\n",
        "\n",
        "    #Check if it is the best solution\n",
        "    if fitness_value > max_fitness:\n",
        "      max_fitness = fitness_value\n",
        "      mlflow.log_metric(\"GA_learning_rate\", lr, step=step_value)\n",
        "      mlflow.log_metric(\"GA_batch_size\", batch, step=step_value)\n",
        "      mlflow.log_metric(\"GA_num_epoch\", epoch, step=step_value)\n",
        "      mlflow.log_metric(\"GA_optimizer\", opt, step=step_value)\n",
        "      mlflow.log_metric(\"GA_accuracy\", acc, step=step_value)\n",
        "      mlflow.log_metric(\"GA_precision\", pre, step=step_value)\n",
        "      mlflow.log_metric(\"GA_recall\", rec, step=step_value)\n",
        "      mlflow.log_metric(\"GA_f1\", f1, step=step_value)\n",
        "\n",
        "      #Take its configuration to copy it as the best solution\n",
        "      search_path = path_parameters+\"solution_\"+str(i)+\"_\"+str(step_value)+\".pth\"\n",
        "      if os.path.exists(search_path):\n",
        "        model_path = path_parameters+\"best_solution.pth\"\n",
        "        shutil.copy(search_path, model_path)\n",
        "\n",
        "    i+=1\n",
        "\n",
        "  #Update ActualSolution to write the fitness values\n",
        "  with open(file_path1, \"w\", newline=\"\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"learning_rate\",\"batch_size\",\"num_epoch\",\"optimizer\",\"fitness_value\",\"accuracy\",\"precision\",\"recall\",\"f1\",\"evaluation\"])\n",
        "    writer.writerows(actual_population)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSYuAD7tiUMZ"
      },
      "source": [
        "# Fitness function\n",
        "Our **fitness function** is:\n",
        "> fitness(x) = f(x)/∑ f(j) where j ∈ P-{x} and P represents the population\n",
        "\n",
        "We get the fitness value from a csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQsj6Xc9irlm"
      },
      "outputs": [],
      "source": [
        "#This parameters are required by PyGAD\n",
        "def fitness_function_calculator(ga_instance, solution, solution_idx):\n",
        "  global solution_number\n",
        "  solution_number+=1\n",
        "\n",
        "  #We call the evaluation function only if we are not in the initial population step\n",
        "  if ga_instance.generations_completed != 0 and solution_number==1:\n",
        "    evaluate_solutions(ga_instance.generations_completed, ga_instance.population)\n",
        "\n",
        "  file_path = \"\"\n",
        "  if script_owner:\n",
        "    file_path = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGAFirstApproach/ActualPopulation.csv\"\n",
        "  else:\n",
        "    file_path = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGAFirstApproach/ActualPopulation.csv\"\n",
        "\n",
        "  flag = False\n",
        "  fitness_value = 0\n",
        "  learning_rate = float(solution[0])\n",
        "  batch_size = int(solution[1])\n",
        "  num_epoch = int(solution[2])\n",
        "  optimizer = int(solution[3])\n",
        "\n",
        "  with open(file_path, \"r\", newline=\"\") as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    next(reader) #Jump the first row (contains the file header)\n",
        "    for row in reader:\n",
        "      #Convert the values in the correct format\n",
        "      lr_row = float(row[0])\n",
        "      batch_row = int(float(row[1]))\n",
        "      epoch_row = int(float(row[2]))\n",
        "      optimizer_row = int(float(row[3]))\n",
        "      value = float(row[4])\n",
        "\n",
        "      if learning_rate==lr_row and batch_size==batch_row and num_epoch==epoch_row and optimizer==optimizer_row:\n",
        "        flag = True\n",
        "        fitness_value = value\n",
        "        break\n",
        "\n",
        "  #To plot the ga data\n",
        "  if solution_number == 8:\n",
        "    solution_number = 0\n",
        "    if ga_instance.generations_completed != 0:\n",
        "      step_value = 0\n",
        "      global num_step\n",
        "      if num_step is None:\n",
        "        step_value = ga_instance.generations_completed\n",
        "      else:\n",
        "        step_value = ga_instance.generations_completed + num_step\n",
        "\n",
        "      if script_owner:\n",
        "        ga_instance.plot_fitness(save_dir='/content/drive/MyDrive/SE4AI/Model/EvaluationGAFirstApproach/PlotFitnessGA1Approach_'+step_value+\".png\")\n",
        "        ga_instance.plot_genes(save_dir='/content/drive/MyDrive/SE4AI/Model/EvaluationGAFirstApproach/PlotGenesGA1Approach_'+step_value+\".png\")\n",
        "        ga_instance.plot_new_solution_rate(save_dir='/content/drive/MyDrive/SE4AI/Model/EvaluationGAFirstApproach/PlotExploredSolutionsGA1Approach_'+step_value+\".png\")\n",
        "      else:\n",
        "        ga_instance.plot_fitness(save_dir='/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGAFirstApproach/PlotFitnessGA1Approach_'+step_value+\".png\")\n",
        "        ga_instance.plot_genes(save_dir='/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGAFirstApproach/PlotGenesGA1Approach_'+step_value+\".png\")\n",
        "        ga_instance.plot_new_solution_rate(save_dir='/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGAFirstApproach/PlotExploredSolutionsGA1Approach_'+step_value+\".png\")\n",
        "\n",
        "\n",
        "  if flag:\n",
        "    return fitness_value\n",
        "  else:\n",
        "    print(\"Row not found! (fitness function) \",solution)\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye1mBaYYkDni"
      },
      "source": [
        "# Initial population\n",
        "The initial population is composed of 30 random solutions.\n",
        "Each individual has this configuration:\n",
        "\n",
        "[ learning-rate, batch-size, number-of-epoch, optimizer-type ]\n",
        "\n",
        "We evaluate the initial population and store them in a csv file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMhN15VblW_l"
      },
      "outputs": [],
      "source": [
        "def fun_on_start(ga_instance):\n",
        "  print(\"Initialize the population\")\n",
        "  population = ga_instance.population\n",
        "  population_list = population.tolist()\n",
        "\n",
        "  global max_fitness\n",
        "  global num_step\n",
        "  step_value = 0\n",
        "  sum = 0\n",
        "\n",
        "  path_parameters = \"\"\n",
        "  file_path1 = file_path2 = file_path3 = \"\"\n",
        "  if script_owner:\n",
        "    path_parameters = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGAFirstApproach/ModelsConfigurations/\"\n",
        "    file_path1 = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGAFirstApproach/ActualPopulation.csv\"\n",
        "    file_path2 = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGAFirstApproach/AllSolutions.csv\"\n",
        "    file_path3 = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGAFirstApproach/Checkpoint.csv\"\n",
        "  else:\n",
        "    path_parameters = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGAFirstApproach/ModelsConfigurations/\"\n",
        "    file_path1 = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGAFirstApproach/ActualPopulation.csv\"\n",
        "    file_path2 = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGAFirstApproach/AllSolutions.csv\"\n",
        "    file_path3 = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGAFirstApproach/Checkpoint.csv\"\n",
        "\n",
        "  if num_step is None:\n",
        "    #Create the csv files\n",
        "    with open(file_path1, \"w\", newline=\"\") as csvfile: #ActualPopulation\n",
        "      writer = csv.writer(csvfile)\n",
        "      writer.writerow([\"learning_rate\",\"batch_size\",\"num_epoch\",\"optimizer\",\"fitness_value\",\"accuracy\",\"precision\",\"recall\",\"f1\",\"evaluation\"])\n",
        "    with open(file_path2, \"w\", newline=\"\") as csvfile: #AllSolutions\n",
        "      writer = csv.writer(csvfile)\n",
        "      writer.writerow([\"learning_rate\",\"batch_size\",\"num_epoch\",\"optimizer\",\"fitness_value\",\"accuracy\",\"precision\",\"recall\",\"f1\",\"evaluation\"])\n",
        "\n",
        "    for solution in population_list:\n",
        "      temp_solution = solution.copy()\n",
        "      temp_solution.extend([None,None,None,None,None,None])\n",
        "\n",
        "      with open(file_path1, \"a\", newline=\"\") as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(temp_solution)\n",
        "\n",
        "    #Save checkpoint\n",
        "    run = mlflow.active_run()\n",
        "    experiment_id = run.info.experiment_id\n",
        "    with open(file_path3, \"w\", newline=\"\") as csvfile:\n",
        "      writer =csv.writer(csvfile)\n",
        "      writer.writerow([\"num_generation_step\",\"mlflow_experiment_id\"])\n",
        "      writer.writerow([step_value, experiment_id])\n",
        "  else:\n",
        "    #We have a checkpoint\n",
        "    step_value = num_step\n",
        "\n",
        "\n",
        "  i = 0\n",
        "  for solution in population_list:\n",
        "    print(\"Training the \",i+1,\" solution...\")\n",
        "    flag_to_train = True\n",
        "    learning_rate = float(solution[0])\n",
        "    batch_size = int(solution[1])\n",
        "    num_epoch = int(solution[2])\n",
        "    optimizer = int(solution[3])\n",
        "\n",
        "    #Check how many times the solution is in ActualPopulation\n",
        "    df = pd.read_csv(file_path1)\n",
        "    matching_rows = df.loc[(df[\"learning_rate\"] == learning_rate) & (df[\"batch_size\"] == batch_size) & (df[\"num_epoch\"] == num_epoch) & (df[\"optimizer\"] == optimizer)]\n",
        "    if len(matching_rows)>1:\n",
        "      #There is more than one equal individual\n",
        "      clone_position = matching_rows.index[0]\n",
        "      if pd.isna(df.at[clone_position, \"evaluation\"]):\n",
        "\n",
        "        #Check if the solution already exists in AllSolutions\n",
        "        if step_value!=0:\n",
        "          df = pd.read_csv(file_path2)\n",
        "          matching_rows = df.loc[(df[\"learning_rate\"] == learning_rate) & (df[\"batch_size\"] == batch_size) & (df[\"num_epoch\"] == num_epoch) & (df[\"optimizer\"] == optimizer)]\n",
        "          if not matching_rows.empty:\n",
        "            #The solution already exists, therefore we do not re-train it\n",
        "            flag_to_train = False\n",
        "\n",
        "            position = matching_rows.index[0]\n",
        "            solution_in_all = df.loc[position]\n",
        "            acc = float(solution_in_all[\"accuracy\"])\n",
        "            pre = float(solution_in_all[\"precision\"])\n",
        "            rec = float(solution_in_all[\"recall\"])\n",
        "            f1 = float(solution_in_all[\"f1\"])\n",
        "            evaluation = float(solution_in_all[\"evaluation\"])\n",
        "\n",
        "            sum+=evaluation\n",
        "\n",
        "            #Update ActualPopulation\n",
        "            df = pd.read_csv(file_path1)\n",
        "            matching_rows = df.loc[(df[\"learning_rate\"] == learning_rate) & (df[\"batch_size\"] == batch_size) & (df[\"num_epoch\"] == num_epoch) & (df[\"optimizer\"] == optimizer)]\n",
        "\n",
        "            if not matching_rows.empty:\n",
        "              #Take the solution index\n",
        "              indices = matching_rows.index\n",
        "              for idx in indices:\n",
        "                #Update the evaluation metrics\n",
        "                df.at[idx, \"accuracy\"] = acc\n",
        "                df.at[idx, \"precision\"] = pre\n",
        "                df.at[idx, \"recall\"] = rec\n",
        "                df.at[idx, \"f1\"] = f1\n",
        "                df.at[idx, \"evaluation\"] = evaluation\n",
        "\n",
        "              #save the updated ActualPopulation file\n",
        "              df.to_csv(file_path1, index=False)\n",
        "\n",
        "            #Copy the solution configuration (.pth)\n",
        "            individual = position % 8 #solution position in population\n",
        "            generation = int(position_in_all/8) #num generation where the solution was created\n",
        "            search_path = path_parameters+\"solution_\"+str(individual)+\"_\"+str(generation)+\".pth\"\n",
        "            if os.path.exists(search_path):\n",
        "              model_path = path_parameters+\"solution_\"str(i)+\"_\"+str(step_value)+\".pth\"\n",
        "              shutil.copy(search_path, model_path)\n",
        "          else:\n",
        "            #The solution does not exists in AllSolution\n",
        "            #The first solution was not trained, we will train it\n",
        "            flag_to_train = True\n",
        "      else:\n",
        "        #The first solution was trained, therefore we do not re-train the clone solution\n",
        "        print(\"The solution \",solution,\" is already trained (initial polulation)\")\n",
        "        flag_to_train = False\n",
        "\n",
        "        search_path = path_parameters+\"solution_\"+str(clone_position)+\"_\"+str(step_value)+\".pth\"\n",
        "        if os.path.exists(search_path):\n",
        "          model_path = path_parameters+\"solution_\"+str(i)+\"_\"+str(step_value)+\".pth\"\n",
        "          if not os.path.exists(model_path):\n",
        "            shutil.copy(search_path, model_path)\n",
        "\n",
        "        eval = df.loc[clone_position]\n",
        "        eval = float(eval[\"evaluation\"])\n",
        "        sum += eval\n",
        "    else:\n",
        "      position = matching_rows.index[0]\n",
        "      if pd.isna(df.at[position, \"evaluation\"]):\n",
        "        #It is not trained\n",
        "\n",
        "        #Check if the solution already exists in AllSolutions\n",
        "        if step_value!=0:\n",
        "          df = pd.read_csv(file_path2)\n",
        "          matching_rows = df.loc[(df[\"learning_rate\"] == learning_rate) & (df[\"batch_size\"] == batch_size) & (df[\"num_epoch\"] == num_epoch) & (df[\"optimizer\"] == optimizer)]\n",
        "          if not matching_rows.empty:\n",
        "            #The solution already exists, therefore we do not re-train it\n",
        "            flag_to_train = False\n",
        "\n",
        "            position = matching_rows.index[0]\n",
        "            solution_in_all = df.loc[position]\n",
        "            acc = float(solution_in_all[\"accuracy\"])\n",
        "            pre = float(solution_in_all[\"precision\"])\n",
        "            rec = float(solution_in_all[\"recall\"])\n",
        "            f1 = float(solution_in_all[\"f1\"])\n",
        "            evaluation = float(solution_in_all[\"evaluation\"])\n",
        "\n",
        "            sum+=evaluation\n",
        "\n",
        "            #Update ActualPopulation\n",
        "            df = pd.read_csv(file_path1)\n",
        "            matching_rows = df.loc[(df[\"learning_rate\"] == learning_rate) & (df[\"batch_size\"] == batch_size) & (df[\"num_epoch\"] == num_epoch) & (df[\"optimizer\"] == optimizer)]\n",
        "\n",
        "            if not matching_rows.empty:\n",
        "              #Take the solution index\n",
        "              indices = matching_rows.index\n",
        "              for idx in indices:\n",
        "                #Update the evaluation metrics\n",
        "                df.at[idx, \"accuracy\"] = acc\n",
        "                df.at[idx, \"precision\"] = pre\n",
        "                df.at[idx, \"recall\"] = rec\n",
        "                df.at[idx, \"f1\"] = f1\n",
        "                df.at[idx, \"evaluation\"] = evaluation\n",
        "\n",
        "              #save the updated ActualPopulation file\n",
        "              df.to_csv(file_path1, index=False)\n",
        "\n",
        "            #Copy the solution configuration (.pth)\n",
        "            individual = position % 8 #solution position in population\n",
        "            generation = int(position_in_all/8) #num generation where the solution was created\n",
        "            search_path = path_parameters+\"solution_\"+str(individual)+\"_\"+str(generation)+\".pth\"\n",
        "            if os.path.exists(search_path):\n",
        "              model_path = path_parameters+\"solution_\"str(i)+\"_\"+str(step_value)+\".pth\"\n",
        "              shutil.copy(search_path, model_path)\n",
        "          else:\n",
        "            #The solution does not exists in AllSolution\n",
        "            #The solution was not trained, we will train it\n",
        "            flag_to_train = True\n",
        "      else:\n",
        "        #The solution was trained, therefore we do not re-train it\n",
        "        print(\"The solution \",solution,\" is already trained (initial polulation)\")\n",
        "        flag_to_train = False\n",
        "        eval = df.loc[position]\n",
        "        eval = float(eval[\"evaluation\"])\n",
        "        sum += eval\n",
        "\n",
        "    if flag_to_train:\n",
        "      #batch_size\n",
        "      size = 0\n",
        "      match batch_size:\n",
        "        case 1:\n",
        "          size = 32\n",
        "        case 2:\n",
        "          size = 64\n",
        "        case _:\n",
        "          size = 32\n",
        "\n",
        "      #num_epoch\n",
        "      epoch = 0\n",
        "      match num_epoch:\n",
        "        case 1:\n",
        "          epoch = 64\n",
        "        case 2:\n",
        "          epoch = 96\n",
        "        case 3:\n",
        "          epoch = 128\n",
        "        case _:\n",
        "          epoch = 64\n",
        "\n",
        "      #Train the model\n",
        "      print(\"Evaluating the solution: \",solution,\" (initial population)\")\n",
        "      best_model_configuration, acc, pre, rec, f1 = start_process(model_type=1, architecture=None, linear_size=None, bool_mlflow=False, learning_rate=learning_rate, batch_size=size, num_epoch=epoch, opt=optimizer)\n",
        "      solution_evaluation = (0.4*acc)+(0.6*rec)\n",
        "      sum+=solution_evaluation\n",
        "\n",
        "      #Store its configuration\n",
        "      model_path = path_parameters+\"solution_\"+str(i)+\"_\"+str(step_value)+\".pth\"\n",
        "      torch.save(best_model_configuration, model_path)\n",
        "\n",
        "      #Update ActualPopulation\n",
        "      df = pd.read_csv(file_path1)\n",
        "      matching_rows = df.loc[(df[\"learning_rate\"] == learning_rate) & (df[\"batch_size\"] == batch_size) & (df[\"num_epoch\"] == num_epoch) & (df[\"optimizer\"] == optimizer)]\n",
        "\n",
        "      if not matching_rows.empty:\n",
        "        #Take the solution index\n",
        "        indices = matching_rows.index\n",
        "        for idx in indices:\n",
        "          #Update the evaluation metrics\n",
        "          df.at[idx, \"accuracy\"] = acc\n",
        "          df.at[idx, \"precision\"] = pre\n",
        "          df.at[idx, \"recall\"] = rec\n",
        "          df.at[idx, \"f1\"] = f1\n",
        "          df.at[idx, \"evaluation\"] = solution_evaluation\n",
        "\n",
        "        #save the updated ActualPopulation file\n",
        "        df.to_csv(file_path1, index=False)\n",
        "      else:\n",
        "        print(\"Row not found! (initial population, flag_to_train:True): \",solution)\n",
        "\n",
        "    i+=1\n",
        "\n",
        "  actual_population = list()\n",
        "  #Compute the fitness_value\n",
        "  with open(file_path1, \"r\", newline=\"\") as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    next(reader)\n",
        "    for row in reader:\n",
        "      evaluation = float(row[9])\n",
        "      row_copy = row.copy()\n",
        "      row_copy[4] = evaluation/(sum-evaluation) #Define the fitness value\n",
        "      actual_population.append(row_copy)\n",
        "\n",
        "  #If we start from a checkpoint\n",
        "  if step_value!=0:\n",
        "    #Update the max_fitness value with the fitness value of the last best individual\n",
        "    for solution in actual_population:\n",
        "      lr = float(solution[0])\n",
        "      batch = int(float(solution[1]))\n",
        "      epoch = int(float(solution[2]))\n",
        "      opt = int(float(solution[3]))\n",
        "      df = pd.read_csv(file_path2)\n",
        "      matching_rows = df.loc[(df[\"learning_rate\"] == lr) & (df[\"batch_size\"] == batch) & (df[\"num_epoch\"] == epoch) & (df[\"optimizer\"] == opt)]\n",
        "\n",
        "      if not matching_rows.empty:\n",
        "        position = matching_rows.index[len(matching_rows)-1]\n",
        "        last_occurence = df.loc[position]\n",
        "        eval = float(last_occurence[\"fitness_value\"])\n",
        "        if max_fitness == eval:\n",
        "          fitness_value = float(solution[4])\n",
        "          max_fitness = fitness_value\n",
        "          break\n",
        "\n",
        "  i=0\n",
        "  #Find the actual best solution\n",
        "  for solution in actual_population:\n",
        "    lr = float(solution[0])\n",
        "    batch = int(float(solution[1]))\n",
        "    epoch = int(float(solution[2]))\n",
        "    opt = int(float(solution[3]))\n",
        "    fitness_value = float(solution[4])\n",
        "    acc = float(solution[5])\n",
        "    pre = float(solution[6])\n",
        "    rec = float(solution[7])\n",
        "    f1 = float(solution[8])\n",
        "\n",
        "    #Update AllSolutions\n",
        "    with open(file_path2, \"a\", newline=\"\") as csvfile:\n",
        "      writer = csv.writer(csvfile)\n",
        "      writer.writerow(solution)\n",
        "\n",
        "    #Check if it is the best solution\n",
        "    if fitness_value >= max_fitness: #*****************\n",
        "      max_fitness = fitness_value\n",
        "      mlflow.log_metric(\"GA_learning_rate\", lr, step=step_value)\n",
        "      mlflow.log_metric(\"GA_batch_size\", batch, step=step_value)\n",
        "      mlflow.log_metric(\"GA_num_epoch\", epoch, step=step_value)\n",
        "      mlflow.log_metric(\"GA_optimizer\", opt, step=step_value)\n",
        "      mlflow.log_metric(\"GA_accuracy\", acc, step=step_value)\n",
        "      mlflow.log_metric(\"GA_precision\", pre, step=step_value)\n",
        "      mlflow.log_metric(\"GA_recall\", rec, step=step_value)\n",
        "      mlflow.log_metric(\"GA_f1\", f1, step=step_value)\n",
        "\n",
        "      #Take its configuration to copy it as the best solution\n",
        "      search_path = path_parameters+\"solution_\"+str(i)+\"_\"+str(step_value)+\".pth\"\n",
        "      if os.path.exists(search_path):\n",
        "        model_path = path_parameters+\"best_solution.pth\"\n",
        "        shutil.copy(search_path, model_path)\n",
        "\n",
        "    i+=1\n",
        "\n",
        "  #Update ActualPopulation to write the fitness values\n",
        "  with open(file_path1, \"w\", newline=\"\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"learning_rate\",\"batch_size\",\"num_epoch\",\"optimizer\",\"fitness_value\",\"accuracy\",\"precision\",\"recall\",\"f1\",\"evaluation\"])\n",
        "    writer.writerows(actual_population)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9Oh9Hx4jAXT"
      },
      "source": [
        "# Tournament selection\n",
        "K=10 solutions will participate at each tournament.\n",
        "\n",
        "We will apply the tournament 20 times to obtain M=20 parents who will take part the crossover step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlIjDMhvj4ok"
      },
      "outputs": [],
      "source": [
        "def my_tournament_selection(fitness_values,required_number,ga_instance):\n",
        "  print(\"Started the Tournament\")\n",
        "  population = ga_instance.population\n",
        "  population_list = population.tolist()\n",
        "\n",
        "  winners = []\n",
        "  winners_index = [] #To track the selected parents in order to do not select it more than one time\n",
        "  for i in range(required_number):\n",
        "\n",
        "    selected_flag = False\n",
        "    selected_indices = None\n",
        "\n",
        "    while not selected_flag:\n",
        "      #Select random solution until there is not a solution already selected in the previous tournament\n",
        "      selected_indices = np.random.choice(np.arange(len(population_list)), size=4, replace=False) #replace=False -> in this way we don't select the same individual more then one time\n",
        "      flag = True\n",
        "      for index in selected_indices:\n",
        "        if index in winners_index:\n",
        "          flag = False\n",
        "          break\n",
        "\n",
        "      if flag:\n",
        "        selected_flag = True\n",
        "\n",
        "\n",
        "    winner = None #to store the selected individual\n",
        "    best_fitness = 0 #to store the relative fitness value\n",
        "    winner_position = None #to store the relative position in the population\n",
        "\n",
        "    for index in selected_indices:\n",
        "      solution = population_list[index]\n",
        "      solution_fitness = fitness_values[index]\n",
        "      if solution_fitness > best_fitness:\n",
        "        best_fitness = solution_fitness\n",
        "        winner = solution\n",
        "        winner_position = index\n",
        "\n",
        "    #Record the winner\n",
        "    winners.append(winner)\n",
        "\n",
        "    #Record its index in the population (required by PyGAD)\n",
        "    winners_index.append(winner_position)\n",
        "\n",
        "  #Transform them in numpy array because it is required by PyGAD\n",
        "  print(\"The winners are:\")\n",
        "  print(winners)\n",
        "  winners_numpy = np.array(winners)\n",
        "  winners_index_numpy = np.array(winners_index)\n",
        "\n",
        "  return winners_numpy, winners_index_numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_wSvkLIBHZ7"
      },
      "source": [
        "# Boundary function\n",
        "We will execute this function only if the genetic algorithm stops at the last generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vHY1FhpBK2q"
      },
      "outputs": [],
      "source": [
        "#This function is called when Google stopped the GA in the last generation.\n",
        "def train_solutions_last_generation(actual_population_path, best_path, id):\n",
        "  sum = 0\n",
        "  solutions_list = list()\n",
        "  i = 0\n",
        "  global max_fitness\n",
        "  path_parameters = \"\"\n",
        "  if script_owner:\n",
        "    path_parameters = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGAFirstApproach/ModelsConfigurations/\"\n",
        "    file_path2 = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGAFirstApproach/AllSolutions.csv\"\n",
        "  else:\n",
        "    path_parameters = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGAFirstApproach/ModelsConfigurations/\"\n",
        "    file_path2 = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGAFirstApproach/AllSolutions.csv\"\n",
        "\n",
        "  with mlflow.start_run(experiment_id=id):\n",
        "    with open(actual_population_path, \"r\", newline=\"\") as csvfile:\n",
        "        reader = csv.reader(csvfile)\n",
        "        next(reader) #To jump the file header\n",
        "        for row in reader:\n",
        "          train_flag = True\n",
        "\n",
        "          learning_rate = float(row[0])\n",
        "          batch_size = int(float(row[1]))\n",
        "          num_epoch = int(float(row[2]))\n",
        "          optimizer = int(float(row[3]))\n",
        "          acc = pre = rec = f1 = 0\n",
        "\n",
        "          #Check how many times the solution is in ActualPopulation\n",
        "          df = pd.read_csv(actual_population_path)\n",
        "          matching_rows = df.loc[(df[\"learning_rate\"] == learning_rate) & (df[\"batch_size\"] == batch_size) & (df[\"num_epoch\"] == num_epoch) & (df[\"optimizer\"] == optimizer)]\n",
        "          if len(matching_rows)>1:\n",
        "            #There is more than one equal individual\n",
        "            clone_position = matching_rows.index[0]\n",
        "            if pd.isna(df.at[clone_position, \"evaluation\"]):\n",
        "              #if the first solution was not trained, we will train it\n",
        "              train_flag = True\n",
        "            else:\n",
        "              #the first solution was trained, therefore we do not re-train the clone solution\n",
        "              train_flag = False\n",
        "\n",
        "              search_path = path_parameters+\"solution_\"+str(clone_position)+\"_10.pth\"\n",
        "              if os.path.exists(search_path):\n",
        "                model_path = path_parameters+\"solution_\"+str(i)+\"_10.pth\"\n",
        "                shutil.copy(search_path, model_path)\n",
        "\n",
        "              eval = df.loc[clone_position]\n",
        "              acc = float(eval[\"accuracy\"])\n",
        "              pre = float(eval[\"precision\"])\n",
        "              rec = float(eval[\"recall\"])\n",
        "              f1 = float(eval[\"f1\"])\n",
        "              eval = float(eval[\"evaluation\"])\n",
        "              sum += eval\n",
        "\n",
        "              solutions_list.append([learning_rate,batch_size,num_epoch,optimizer,None,acc,pre,rec,f1,eval])\n",
        "          else:\n",
        "            #The solution appears only one time\n",
        "            if row[9]==\"\":\n",
        "              train_flag = True\n",
        "            else:\n",
        "              train_flag = False\n",
        "              acc = float(row[5])\n",
        "              pre = float(row[6])\n",
        "              rec = float(row[7])\n",
        "              f1 = float(row[8])\n",
        "              eval = float(row[9])\n",
        "              solutions_list.append([learning_rate,batch_size,num_epoch,optimizer,None,acc,pre,rec,f1,eval])\n",
        "              sum+=eval\n",
        "\n",
        "          if train_flag:\n",
        "            #Check if the solution already exists in AllSolutions\n",
        "            df = pd.read_csv(file_path2)\n",
        "            matching_rows = df.loc[(df[\"learning_rate\"] == learning_rate) & (df[\"batch_size\"] == batch_size) & (df[\"num_epoch\"] == num_epoch) & (df[\"optimizer\"] == optimizer)]\n",
        "            if not matching_rows.empty:\n",
        "              position = matching_rows.index[0]\n",
        "              solution_in_all = df.loc[position]\n",
        "              acc = float(solution_in_all[\"accuracy\"])\n",
        "              pre = float(solution_in_all[\"precision\"])\n",
        "              rec = float(solution_in_all[\"recall\"])\n",
        "              f1 = float(solution_in_all[\"f1\"])\n",
        "              evaluation = float(solution_in_all[\"evaluation\"])\n",
        "\n",
        "              sum+=evaluation\n",
        "\n",
        "              #Update ActualPopulation\n",
        "              df = pd.read_csv(actual_population_path)\n",
        "              matching_rows = df.loc[(df[\"learning_rate\"] == learning_rate) & (df[\"batch_size\"] == batch_size) & (df[\"num_epoch\"] == num_epoch) & (df[\"optimizer\"] == optimizer)]\n",
        "\n",
        "              if not matching_rows.empty:\n",
        "                #Take the solution index\n",
        "                indices = matching_rows.index\n",
        "                for idx in indices:\n",
        "                  #Update the evaluation metrics\n",
        "                  df.at[idx, \"accuracy\"] = acc\n",
        "                  df.at[idx, \"precision\"] = pre\n",
        "                  df.at[idx, \"recall\"] = rec\n",
        "                  df.at[idx, \"f1\"] = f1\n",
        "                  df.at[idx, \"evaluation\"] = evaluation\n",
        "\n",
        "                #save the updated ActualPopulation file\n",
        "                df.to_csv(actual_population_path, index=False)\n",
        "\n",
        "              #Copy the solution configuration (.pth)\n",
        "              individual = position % 8 #solution position in population\n",
        "              generation = int(position_in_all/8) #num generation where the solution was created\n",
        "              search_path = path_parameters+\"solution_\"+str(individual)+\"_\"+str(generation)+\".pth\"\n",
        "              if os.path.exists(search_path):\n",
        "                model_path = path_parameters+\"solution_\"str(i)+\"_10.pth\"\n",
        "                shutil.copy(search_path, model_path)\n",
        "\n",
        "              solutions_list.append([learning_rate,batch_size,num_epoch,optimizer,None,acc,pre,rec,f1,evaluation])\n",
        "            else:\n",
        "              #batch_size\n",
        "              size = 0\n",
        "              match batch_size:\n",
        "                case 1:\n",
        "                  size = 32\n",
        "                case 2:\n",
        "                  size = 64\n",
        "                case _:\n",
        "                  size = 32\n",
        "\n",
        "              #num_epoch\n",
        "              epoch = 0\n",
        "              match num_epoch:\n",
        "                case 1:\n",
        "                  epoch = 64\n",
        "                case 2:\n",
        "                  epoch = 96\n",
        "                case 3:\n",
        "                  epoch = 128\n",
        "                case _:\n",
        "                  epoch = 64\n",
        "\n",
        "              #Train the model\n",
        "              print(\"Evaluating the solution: [\",learning_rate,\",\",batch_size,\",\",num_epoch,\",\",optimizer,\"]\")\n",
        "              best_model_configuration, acc, pre, rec, f1 = start_process(model_type=1, architecture=None, linear_size=None, bool_mlflow=False, learning_rate=learning_rate, batch_size=batch_size, num_epoch=num_epoch, opt=optimizer)\n",
        "              solution_evaluation = (0.4*acc)+(0.6*rec)\n",
        "              sum+=solution_evaluation\n",
        "\n",
        "              #Store its configuration\n",
        "              model_path = path_parameters+\"solution_\"+str(i)+\"_10.pth\"\n",
        "              torch.save(best_model_configuration, model_path)\n",
        "\n",
        "              solutions_list.append([learning_rate,batch_size,num_epoch,optimizer,None,acc,pre,rec,f1,solution_evaluation])\n",
        "\n",
        "              df = pd.read_csv(actual_population_path)\n",
        "              matching_rows = df.loc[(df[\"learning_rate\"] == learning_rate) & (df[\"batch_size\"] == batch_size) & (df[\"num_epoch\"] == num_epoch) & (df[\"optimizer\"] == optimizer)]\n",
        "              if not matching_rows.empty:\n",
        "                #Take the solution index\n",
        "                indices = matching_rows.index\n",
        "                for idx in indices:\n",
        "                  #Update the evaluation metrics\n",
        "                  df.at[idx, \"accuracy\"] = acc\n",
        "                  df.at[idx, \"precision\"] = pre\n",
        "                  df.at[idx, \"recall\"] = rec\n",
        "                  df.at[idx, \"f1\"] = f1\n",
        "                  df.at[idx, \"evaluation\"] = solution_evaluation\n",
        "\n",
        "                #save the updated ActualPopulation file\n",
        "                df.to_csv(file_path1, index=False)\n",
        "              else:\n",
        "                print(\"Row not found! (boundary function, trained): [\",learning_rate,\",\",batch_size,\",\",num_epoch,\",\",optimizer,\"]\")\n",
        "\n",
        "          i+=1\n",
        "\n",
        "\n",
        "    #Define the fitness values\n",
        "    for solution in solutions_list:\n",
        "      fitness_value = solution[9]/(sum-solution[9])\n",
        "      solution[4] = fitness_value\n",
        "\n",
        "    #Update the max_fitness value with the current fitness value of the last best individual\n",
        "    for solution in solutions_list:\n",
        "      lr = float(solution[0])\n",
        "      batch = int(float(solution[1]))\n",
        "      epoch = int(float(solution[2]))\n",
        "      opt = int(float(solution[3]))\n",
        "      df = pd.read_csv(file_path2)\n",
        "      matching_rows = df.loc[(df[\"learning_rate\"] == lr) & (df[\"batch_size\"] == batch) & (df[\"num_epoch\"] == epoch) & (df[\"optimizer\"] == opt)]\n",
        "\n",
        "      if not matching_rows.empty:\n",
        "        position = matching_rows.index[len(matching_rows)-1]\n",
        "        last_occurence = df.loc[position]\n",
        "        eval = float(last_occurence[\"fitness_value\"])\n",
        "        if max_fitness == eval:\n",
        "          fitness_value = float(solution[4])\n",
        "          max_fitness = fitness_value\n",
        "          break\n",
        "\n",
        "    #Find the best solution\n",
        "    i=0\n",
        "    for solution in solutions_list:\n",
        "      fitness_value = solution[4]\n",
        "      if fitness_value > max_fitness:\n",
        "        max_fitness = fitness_value\n",
        "        mlflow.log_metric(\"GA_learning_rate\", solution[0], step=step_value)\n",
        "        mlflow.log_metric(\"GA_batch_size\", solution[1], step=step_value)\n",
        "        mlflow.log_metric(\"GA_num_epoch\", solution[2], step=step_value)\n",
        "        mlflow.log_metric(\"GA_optimizer\", solution[3], step=step_value)\n",
        "        mlflow.log_metric(\"GA_accuracy\", solution[5], step=step_value)\n",
        "        mlflow.log_metric(\"GA_precision\", solution[6], step=step_value)\n",
        "        mlflow.log_metric(\"GA_recall\", solution[7], step=step_value)\n",
        "        mlflow.log_metric(\"GA_f1\", solution[8], step=step_value)\n",
        "\n",
        "        #Take its configuration to copy it as the best solution\n",
        "        search_path = path_parameters+\"solution_\"+str(i)+\"_10.pth\"\n",
        "        if os.path.exists(search_path):\n",
        "          model_path = path_parameters+\"best_solution.pth\"\n",
        "          shutil.copy(search_path, model_path)\n",
        "\n",
        "      i+=1\n",
        "\n",
        "\n",
        "    with open(actual_population_path, \"w\", newline=\"\") as csvfile:\n",
        "      writer = csv.writer(csvfile)\n",
        "      writer.writerow([\"learning_rate\",\"batch_size\",\"num_epoch\",\"optimizer\",\"fitness_value\",\"accuracy\",\"precision\",\"recall\",\"f1\",\"evaluation\"])\n",
        "      writer.writerows(solutions_list)\n",
        "\n",
        "    df = pd.read_csv(actual_population_path)\n",
        "    max_value_index = df['fitness_value'].idxmax()\n",
        "\n",
        "    best_solution = df.loc[max_value_index]\n",
        "    best_solution = best_solution.to_list()\n",
        "    with open(best_path,\"w\", newline=\"\") as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow([\"learning_rate\",\"batch_size\",\"num_epoch\",\"optimizer\",\"fitness_value\",\"accuracy\",\"precision\",\"recall\",\"f1\",\"evaluation\"])\n",
        "        writer.writerow(best_solution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR20NlRuo8dY"
      },
      "source": [
        "# Genetich Algorithm\n",
        "*   **Stop criteria**: We will stop the genetic algorithm after 32 generations or if there isn't a fitness function improvement after 16 consecutive steps.\n",
        "*   **Selection algorithm**: K-way Tournament Selection\n",
        "*   **Crossover algorithm**: One-Point Crossover\n",
        "*   **Mutation algorithm**: Random Resetting\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "id": "VRwlLxO4dFH8",
        "outputId": "66d35c6d-ea40-4167-92aa-65556b043faa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset is already splitted\n",
            "Started the GA from the last saved population\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pygad/pygad.py:1146: UserWarning: Use the 'save_solutions' parameter with caution as it may cause memory overflow when either the number of generations, number of genes, or number of solutions in population is large.\n",
            "  warnings.warn(\"Use the 'save_solutions' parameter with caution as it may cause memory overflow when either the number of generations, number of genes, or number of solutions in population is large.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***************************************************************\n",
            "Started Genetich Algorithm!\n",
            "Initialize the population\n",
            "0.1959925454745953\n",
            "Training the  1  solution...\n",
            "The solution is already trained (initial polulation)\n",
            "Training the  2  solution...\n",
            "The solution is already trained (initial polulation)\n",
            "Training the  3  solution...\n",
            "The solution is already trained (initial polulation)\n",
            "Training the  4  solution...\n",
            "The solution is already trained (initial polulation)\n",
            "Training the  5  solution...\n",
            "Evaluating the solution:  [0.05423, 2, 3, 2]  (initial population)\n",
            "START TRAINING STEP\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-f3b4db87bb32>\u001b[0m in \u001b[0;36m<cell line: 119>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m   \u001b[0;31m#Start to track the model with MlFlow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlflow_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mga_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GA finished!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"***************************************************************\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pygad/pygad.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1832\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_start\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1833\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1835\u001b[0m             \u001b[0mstop_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-1c6b63872d4b>\u001b[0m in \u001b[0;36mfun_on_start\u001b[0;34m(ga_instance)\u001b[0m\n\u001b[1;32m    139\u001b[0m       \u001b[0;31m#Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluating the solution: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msolution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" (initial population)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m       \u001b[0mbest_model_configuration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marchitecture\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool_mlflow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m       \u001b[0msolution_evaluation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m       \u001b[0msum\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0msolution_evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-fecd2679f9ef>\u001b[0m in \u001b[0;36mstart_process\u001b[0;34m(model_type, architecture, linear_size, bool_mlflow, learning_rate, batch_size, num_epoch, opt)\u001b[0m\n\u001b[1;32m    131\u001b[0m       \u001b[0mbest_model_configuration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_optimizer_configuration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool_mlflow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool_mlflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m       \u001b[0mbest_model_configuration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_optimizer_configuration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool_mlflow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool_mlflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m       \u001b[0mbest_model_configuration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_optimizer_configuration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool_mlflow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool_mlflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-c6b1c009a2a9>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, data_loader, valid_loader, num_epoch, criterion, optimizer, bool_mlflow)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0msum_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Set the gradient to zero for each batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1295\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Define dataset\n",
        "best_path = checkpoint_path = \"\"\n",
        "if script_owner:\n",
        "  initialize_dataset(\"/content/drive/MyDrive/SE4AI/Model/\")\n",
        "  checkpoint_path = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGAFirstApproach/Checkpoint.csv\"\n",
        "  best_path = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGAFirstApproach/BestSolutionGA1.csv\"\n",
        "else:\n",
        "  initialize_dataset(\"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/\")\n",
        "  checkpoint_path = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGAFirstApproach/Checkpoint.csv\"\n",
        "  best_path = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGAFirstApproach/BestSolutionGA1.csv\"\n",
        "\n",
        "max_num_generation = 10\n",
        "fitness = fitness_function_calculator\n",
        "M = 4 #number of parents to selection step\n",
        "population_size = 8\n",
        "chromosomes_size = 4 #learning rate, batch size, num epoch, optimizer\n",
        "# batch size: 1=32, 2=64;\n",
        "# num epoch: 1=64, 2=96, 3=128\n",
        "# optimizer: 1=Adam, 2=Adadelta, 3=Nadam\n",
        "\n",
        "genes_range = [{'low': 0.001, 'high': 0.10001}, {'low': 1, 'high': 3}, {'low': 1, 'high': 4}, {'low': 1, 'high': 4}] #the range is evaluated as [low,high)\n",
        "\n",
        "ga_instance = None\n",
        "mlflow_id = 0\n",
        "ga_flag=True\n",
        "\n",
        "if os.path.exists(checkpoint_path):\n",
        "  print(\"Started the GA from the last saved population\")\n",
        "  #This means that Google Colab stopped the Genetic Algorithm, therefore we restart the GA with an initial population equal to the last saved population\n",
        "  evolution_step = 0\n",
        "  with open(checkpoint_path, \"r\", newline=\"\") as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    next(reader) #To jump the file header\n",
        "    for row in reader:\n",
        "      evolution_step = int(row[0])\n",
        "      mlflow_id = int(row[1])\n",
        "\n",
        "  all_path = population_path = \"\"\n",
        "  if script_owner:\n",
        "    population_path = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGAFirstApproach/ActualPopulation.csv\"\n",
        "    all_path = \"/content/drive/MyDrive/SE4AI/Model/EvaluationGAFirstApproach/AllSolutions.csv\"\n",
        "  else:\n",
        "    population_path = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGAFirstApproach/ActualPopulation.csv\"\n",
        "    all_path = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGAFirstApproach/AllSolutions.csv\"\n",
        "\n",
        "  #Refresh the max fitness value\n",
        "  df = pd.read_csv(all_path)\n",
        "  last_n_rows = df.tail(8)\n",
        "  df = last_n_rows\n",
        "  max_value = df[\"fitness_value\"].max()\n",
        "  global max_fitness\n",
        "  max_fitness = float(max_value)\n",
        "\n",
        "  max_num_generation = max_num_generation - evolution_step\n",
        "\n",
        "  if max_num_generation == 0:\n",
        "    #Google stops the GA at the last generation, therefore we must train only the no trained solutions\n",
        "    ga_flag=False\n",
        "    train_solutions_last_generation(population_path, best_path, mlflow_id)\n",
        "  else:\n",
        "    global num_step\n",
        "    num_step = evolution_step\n",
        "\n",
        "    #Load the last stored solutions\n",
        "    initial_population = []\n",
        "    with open(population_path, \"r\", newline=\"\") as csvfile:\n",
        "      reader = csv.reader(csvfile)\n",
        "      next(reader) #To jump the file header\n",
        "      for row in reader:\n",
        "        learning_rate = float(row[0])\n",
        "        batch_size = int(float(row[1]))\n",
        "        num_epoch = int(float(row[2]))\n",
        "        optimizer = int(float(row[3]))\n",
        "        initial_population.append([learning_rate, batch_size, num_epoch, optimizer])\n",
        "\n",
        "    initial_population = np.array(initial_population)\n",
        "    ga_instance = pygad.GA(num_generations = max_num_generation,\n",
        "                        num_parents_mating = M,\n",
        "                        fitness_func = fitness,\n",
        "                        initial_population = initial_population,\n",
        "                        num_genes = chromosomes_size,\n",
        "                        gene_type =[[float, 5], int, int, int],\n",
        "                        gene_space = genes_range,\n",
        "                        parent_selection_type = my_tournament_selection,\n",
        "                        crossover_type = \"single_point\", #One-Point Crossover\n",
        "                        mutation_type = \"random\", #Random Resetting -> set a random value within the range\n",
        "                        mutation_by_replacement = True, #replace the gene by the new randomly generated value\n",
        "                        mutation_probability = 0.2, #The probability that a gene must exceed in order to be modified (if probability is less then or equal to this value, the gene will be mutated)\n",
        "                        stop_criteria= \"saturate_8\", #Stop criteria: stop the GA if there isn't an improvement after 16 consecutive steps\n",
        "                        on_start = fun_on_start,\n",
        "                        save_solutions=True\n",
        "                        )\n",
        "else:\n",
        "  base_model_path = None\n",
        "  if script_owner:\n",
        "    base_model_path = \"/content/drive/MyDrive/SE4AI/Model/EvaluationFirstApproach/confusion_matrix.png\"\n",
        "  else:\n",
        "    base_model_path = \"/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationFirstApproach/confusion_matrix.png\"\n",
        "\n",
        "  if not os.path.exists(base_model_path):\n",
        "    #Define and train our based model\n",
        "    print(\"Train our model without the GA (to check its performance)\")\n",
        "    start_process(model_type=1, architecture=None, linear_size=None, bool_mlflow=True, learning_rate=0.001, batch_size=64, num_epoch=64, opt=1)\n",
        "\n",
        "  ga_instance = pygad.GA(num_generations = max_num_generation,\n",
        "                       num_parents_mating = M,\n",
        "                       fitness_func = fitness,\n",
        "                       sol_per_pop = population_size,\n",
        "                       num_genes = chromosomes_size,\n",
        "                       gene_type =[[float, 5], int, int, int],\n",
        "                       gene_space = genes_range,\n",
        "                       parent_selection_type = my_tournament_selection,\n",
        "                       crossover_type = \"single_point\", #One-Point Crossover\n",
        "                       mutation_type = \"random\", #Random Resetting -> set a random value within the range\n",
        "                       mutation_by_replacement = True, #replace the gene by the new randomly generated value\n",
        "                       mutation_probability = 0.2, #The probability that a gene must exceed in order to be modified (if probability is less then or equal to this value, the gene will be mutated)\n",
        "                       stop_criteria= \"saturate_8\", #Stop criteria: stop the GA if there isn't an improvement after 16 consecutive steps\n",
        "                       on_start = fun_on_start,\n",
        "                       save_solutions=True\n",
        "                       )\n",
        "if ga_flag:\n",
        "  print(\"***************************************************************\")\n",
        "  print(\"Started Genetich Algorithm!\")\n",
        "  if not os.path.exists(checkpoint_path):\n",
        "    experiment_name = str(input(\"Insert the experiment name for GA first approach:\"))\n",
        "    mlflow_id = get_experiment_id(experiment_name)\n",
        "\n",
        "  #Start to track the model with MlFlow\n",
        "  with mlflow.start_run(experiment_id=mlflow_id):\n",
        "    ga_instance.run()\n",
        "    print(\"GA finished!\")\n",
        "    print(\"***************************************************************\")\n",
        "\n",
        "  #Save the best solution\n",
        "  solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
        "  print(\"Parameters of the best solution: \", solution)\n",
        "  print(\"Fitness value of the best solution = \", solution_fitness)\n",
        "\n",
        "  to_write = []\n",
        "  to_write.extend(solution)\n",
        "  to_write.append(solution_fitness)\n",
        "  with open(best_path, \"w\", newline=\"\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"learning_rate\",\"batch_size\",\"num_epoch\",\"optimizer\",\"fitness_value\"])\n",
        "    writer.writerow(to_write)\n",
        "\n",
        "  #Plot the fitness values, genes, and the explored solutions\n",
        "  if script_owner:\n",
        "    ga_instance.plot_fitness(save_dir='/content/drive/MyDrive/SE4AI/Model/EvaluationGAFirstApproach/PlotFitnessGA1Approach.png')\n",
        "    ga_instance.plot_genes(save_dir='/content/drive/MyDrive/SE4AI/Model/EvaluationGAFirstApproach/PlotGenesGA1Approach.png')\n",
        "    ga_instance.plot_new_solution_rate(save_dir='/content/drive/MyDrive/SE4AI/Model/EvaluationGAFirstApproach/PlotExploredSolutionsGA1Approach.png')\n",
        "  else:\n",
        "    ga_instance.plot_fitness(save_dir='/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGAFirstApproach/PlotFitnessGA1Approach.png')\n",
        "    ga_instance.plot_genes(save_dir='/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGAFirstApproach/PlotGenesGA1Approach.png')\n",
        "    ga_instance.plot_new_solution_rate(save_dir='/content/drive/MyDrive/LinkToOncoVision/SE4AI/Model/EvaluationGAFirstApproach/PlotExploredSolutionsGA1Approach.png')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}